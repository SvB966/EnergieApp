{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53db67e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_imports'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcommon_imports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m show_home_button()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdb_connection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_engine\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'common_imports'"
     ]
    }
   ],
   "source": [
    "from common_imports import *\n",
    "show_home_button()\n",
    "from db_connection import get_engine\n",
    "engine = get_engine()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from frequency_utils import (\n",
    "    get_freq_minutes,\n",
    "    get_freq_seconds,\n",
    "    get_pandas_freq,\n",
    "    check_max_rows,\n",
    "    round_datetime_to_freq,\n",
    "    detect_auto_frequency,\n",
    "    resample_dataframe,\n",
    ")\n",
    "\n",
    "from progress_bar_widget import ProgressBarWidget\n",
    "progress_widget = ProgressBarWidget()\n",
    "\n",
    "from caching import TTLCache  # <-- CACHE IMPORT\n",
    "\n",
    "min_max_cache = TTLCache(ttl=300)\n",
    "full_data_cache = TTLCache(ttl=300)\n",
    "\n",
    "from mappings import get_typeids, validate_unique_ids, group_typeid_mapping\n",
    "validate_unique_ids()\n",
    "\n",
    "MAX_ROWS = 8000\n",
    "\n",
    "def parse_user_datetime(dt_str: str) -> Optional[datetime]:\n",
    "    try:\n",
    "        return datetime.strptime(dt_str, '%d/%m/%Y %H:%M')\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def generate_insights(df: pd.DataFrame) -> str:\n",
    "    insights_df = get_insights_df(df)\n",
    "    if insights_df.empty:\n",
    "        return \"Geen inzichten beschikbaar.\"\n",
    "    return insights_df.to_html(classes=\"dataframe\", border=0)\n",
    "\n",
    "def get_insights_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame()\n",
    "    time_col = None\n",
    "    if \"UTC Period\" in df.columns:\n",
    "        time_col = \"UTC Period\"\n",
    "    elif \"utcperiod\" in df.columns:\n",
    "        time_col = \"utcperiod\"\n",
    "    status_cols = [col for col in df.columns if 'status' in col.lower()]\n",
    "    if not status_cols:\n",
    "        return pd.DataFrame()\n",
    "    rows = []\n",
    "    for col in status_cols:\n",
    "        for stat in [\"P\", \"T\"]:\n",
    "            count = (df[col] == stat).sum()\n",
    "            if count > 0 and time_col is not None:\n",
    "                dates = pd.to_datetime(df.loc[df[col] == stat, time_col], errors='coerce')\n",
    "                start_date = dates.min()\n",
    "                end_date = dates.max()\n",
    "            else:\n",
    "                start_date = None\n",
    "                end_date = None\n",
    "            rows.append({\n",
    "                \"Kanaal\": col,\n",
    "                \"Status\": stat,\n",
    "                \"Count\": count,\n",
    "                \"Van datum\": start_date,\n",
    "                \"Tot datum\": end_date\n",
    "            })\n",
    "    insights_df = pd.DataFrame(rows)\n",
    "    insights_df.set_index([\"Kanaal\", \"Status\"], inplace=True)\n",
    "    return insights_df\n",
    "\n",
    "def group_columns_by_typeid(df: pd.DataFrame, engine, group_mapping: dict) -> pd.DataFrame:\n",
    "    import re\n",
    "    registerid_pattern = re.compile(r'\\((\\d+)\\)')\n",
    "    col_to_registerid = {}\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ['utcperiod', 'utc period']:\n",
    "            continue\n",
    "        match = registerid_pattern.search(col)\n",
    "        if match:\n",
    "            reg_id = int(match.group(1))\n",
    "            col_to_registerid[col] = reg_id\n",
    "    if not col_to_registerid:\n",
    "        raise ValueError(\"Geen register-ID's gevonden in de DataFrame kolomnamen.\")\n",
    "    query = \"SELECT ID, TypeId FROM dbo.TBL_Register WHERE ID IN ({})\".format(\n",
    "        \",\".join(map(str, list(col_to_registerid.values())))\n",
    "    )\n",
    "    with engine.connect() as conn:\n",
    "        mapping_df = pd.read_sql_query(query, conn)\n",
    "    registerid_to_typeid = dict(zip(mapping_df['ID'], mapping_df['TypeId']))\n",
    "    grouped_df = df[['utcperiod']].copy() if 'utcperiod' in df.columns else df.copy()\n",
    "    for group_name, typeid_list in group_mapping.items():\n",
    "        cols_for_group = []\n",
    "        for col, reg_id in col_to_registerid.items():\n",
    "            typeid_val = registerid_to_typeid.get(reg_id)\n",
    "            if typeid_val in typeid_list:\n",
    "                cols_for_group.append(col)\n",
    "        if cols_for_group:\n",
    "            numeric_subset = [c for c in cols_for_group if '(status)' not in c.lower()]\n",
    "            if numeric_subset:\n",
    "                grouped_df[group_name + \" Total\"] = df[numeric_subset].sum(axis=1, numeric_only=True)\n",
    "            else:\n",
    "                grouped_df[group_name + \" Total\"] = 0\n",
    "        else:\n",
    "            grouped_df[group_name + \" Total\"] = 0\n",
    "    return grouped_df\n",
    "\n",
    "def filter_columns_by_selected_groups(df: pd.DataFrame, engine, group_mapping: dict) -> pd.DataFrame:\n",
    "    import re\n",
    "    registerid_pattern = re.compile(r'\\((\\d+)\\)')\n",
    "    col_to_registerid = {}\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ['utcperiod', 'utc period']:\n",
    "            continue\n",
    "        match = registerid_pattern.search(col)\n",
    "        if match:\n",
    "            col_to_registerid[col] = int(match.group(1))\n",
    "    if not col_to_registerid:\n",
    "        return df[['utcperiod']] if 'utcperiod' in df.columns else pd.DataFrame()\n",
    "    query = \"SELECT ID, TypeId FROM dbo.TBL_Register WHERE ID IN ({})\".format(\n",
    "        \",\".join(map(str, list(col_to_registerid.values())))\n",
    "    )\n",
    "    with engine.connect() as conn:\n",
    "        mapping_df = pd.read_sql_query(query, conn)\n",
    "    regid_to_typeid = dict(zip(mapping_df['ID'], mapping_df['TypeId']))\n",
    "    selected_cols = []\n",
    "    for col, reg_id in col_to_registerid.items():\n",
    "        typeid_val = regid_to_typeid.get(reg_id)\n",
    "        for grp, tid_list in group_mapping.items():\n",
    "            if typeid_val in tid_list:\n",
    "                selected_cols.append(col)\n",
    "                break\n",
    "    cols = []\n",
    "    if 'utcperiod' in df.columns:\n",
    "        cols.append('utcperiod')\n",
    "    cols.extend(selected_cols)\n",
    "    return df[cols]\n",
    "\n",
    "search_method_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"TransferpointID\", \"transferpoint\"),\n",
    "        (\"ObjectID\", \"objectid\"),\n",
    "        (\"RegisterID\", \"registerid\"),\n",
    "        (\"RegistratorID\", \"registratorid\")\n",
    "    ],\n",
    "    value=\"transferpoint\",\n",
    "    description=\"Filter:\"\n",
    ")\n",
    "search_method_dropdown.layout = widgets.Layout(width='240px', height='35px')\n",
    "\n",
    "def fetch_typeids_for_ean(ean_value: str) -> Set[int]:\n",
    "    search_method = search_method_dropdown.value\n",
    "    try:\n",
    "        if search_method == \"transferpoint\":\n",
    "            query = \"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                JOIN TBL_ConnectionPoint cp ON cp.ID = r.ConnectionPointId\n",
    "                WHERE cp.EAN_ConnectionPoint = ?\n",
    "                      OR cp.TransferPointID IN (\n",
    "                          SELECT ID FROM TBL_ConnectionPoint WHERE EAN_ConnectionPoint = ?\n",
    "                      )\n",
    "            \"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                df_temp = pd.read_sql_query(query, conn, params=(ean_value, ean_value))\n",
    "        elif search_method == \"objectid\":\n",
    "            query = \"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                JOIN TBL_ConnectionPoint cp ON cp.ID = r.ConnectionPointId\n",
    "                WHERE cp.ObjectId = (\n",
    "                    SELECT TOP 1 cp2.ObjectId\n",
    "                    FROM TBL_ConnectionPoint cp2\n",
    "                    WHERE cp2.EAN_ConnectionPoint = ?\n",
    "                )\n",
    "            \"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                df_temp = pd.read_sql_query(query, conn, params=(ean_value,))\n",
    "        elif search_method == \"registerid\":\n",
    "            query = \"\"\"\n",
    "                SELECT DISTINCT TypeId\n",
    "                FROM TBL_Register\n",
    "                WHERE ID = ?\n",
    "            \"\"\"\n",
    "            try:\n",
    "                register_id = int(ean_value)\n",
    "            except ValueError:\n",
    "                return set()\n",
    "            with engine.connect() as conn:\n",
    "                df_temp = pd.read_sql_query(query, conn, params=(register_id,))\n",
    "        elif search_method == \"registratorid\":\n",
    "            query = \"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                WHERE r.RegistratorID = ?\n",
    "            \"\"\"\n",
    "            try:\n",
    "                registrator_id = int(ean_value)\n",
    "            except ValueError:\n",
    "                return set()\n",
    "            with engine.connect() as conn:\n",
    "                df_temp = pd.read_sql_query(query, conn, params=(registrator_id,))\n",
    "        else:\n",
    "            return set()\n",
    "        if df_temp.empty:\n",
    "            return set()\n",
    "        return set(df_temp['TypeId'].unique())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching TypeIDs: {e}\")\n",
    "        return set()\n",
    "\n",
    "def fetch_min_max_period(ean_value: str,\n",
    "    allowed_typeids_str: str,\n",
    "    start_date: datetime,\n",
    "    end_date: datetime\n",
    ") -> Tuple[Optional[datetime], Optional[datetime]]:\n",
    "    search_method = search_method_dropdown.value\n",
    "    cache_key = (ean_value, allowed_typeids_str, start_date, end_date, 'minmax', search_method)\n",
    "    cached = min_max_cache.get(cache_key)\n",
    "    if cached is not None:\n",
    "        logger.info(\"Min/Max periode uit cache gehaald.\")\n",
    "        return cached\n",
    "    start_date_str = start_date.strftime('%d/%m/%Y %H:%M')\n",
    "    end_date_str = end_date.strftime('%d/%m/%Y %H:%M')\n",
    "    sp_query = \"\"\"\n",
    "        EXEC [dbo].[usp_GetMinMaxPeriodForEAN]\n",
    "             @EAN_ConnectionPoint = ?,\n",
    "             @AllowedTypeIDs = ?,\n",
    "             @StartDateStr = ?,\n",
    "             @EndDateStr = ?,\n",
    "             @SearchMethod = ?\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            df_temp = pd.read_sql_query(\n",
    "                sp_query, conn,\n",
    "                params=(ean_value, allowed_typeids_str, start_date_str, end_date_str, search_method)\n",
    "            )\n",
    "        if df_temp.empty or pd.isnull(df_temp['MinUTCPeriod'].iloc[0]):\n",
    "            result = (None, None)\n",
    "        else:\n",
    "            result = (df_temp['MinUTCPeriod'].iloc[0], df_temp['MaxUTCPeriod'].iloc[0])\n",
    "        min_max_cache.set(cache_key, result)\n",
    "        logger.info(\"Min/Max periode in cache gezet.\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching min/max period: {e}\")\n",
    "        return (None, None)\n",
    "\n",
    "def fetch_full_data(ean_value: str,\n",
    "    allowed_typeids_str: str,\n",
    "    start_date: datetime,\n",
    "    end_date: datetime,\n",
    "    interval_minutes: int = 5,\n",
    "    include_status: bool = False\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    search_method = search_method_dropdown.value\n",
    "    cache_key = (ean_value, allowed_typeids_str, start_date, end_date,\n",
    "    'pivot', search_method, interval_minutes, include_status)\n",
    "    cached = full_data_cache.get(cache_key)\n",
    "    if cached is not None:\n",
    "        logger.info(\"Volledige data uit cache gehaald.\")\n",
    "        return cached\n",
    "    start_date_str = start_date.strftime('%d/%m/%Y %H:%M')\n",
    "    end_date_str = end_date.strftime('%d/%m/%Y %H:%M')\n",
    "    sp_query = \"\"\"\n",
    "        EXEC [dbo].[usp_GetConnectionDataFull]\n",
    "             @EAN_ConnectionPoint = ?,\n",
    "             @AllowedTypeIDs      = ?,\n",
    "             @StartDateStr        = ?,\n",
    "             @EndDateStr          = ?,\n",
    "             @SearchMethod        = ?,\n",
    "             @IntervalMinutes     = ?,\n",
    "             @IncludeStatus       = ?\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            df = pd.read_sql_query(\n",
    "                sp_query, conn,\n",
    "                params=(\n",
    "                    ean_value,\n",
    "                    allowed_typeids_str,\n",
    "                    start_date_str,\n",
    "                    end_date_str,\n",
    "                    search_method,\n",
    "                    interval_minutes,\n",
    "                    int(include_status)\n",
    "                ),\n",
    "                parse_dates=['utcperiod']\n",
    "            )\n",
    "        if df.empty:\n",
    "            result = None\n",
    "        else:\n",
    "            result = df\n",
    "        full_data_cache.set(cache_key, result)\n",
    "        logger.info(\"Volledige data in cache gezet.\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching full data: {e}\")\n",
    "        return None\n",
    "\n",
    "def build_dataset(ean_val: str,\n",
    "    chosen_groups: List[str],\n",
    "    start_date: datetime,\n",
    "    end_date: datetime,\n",
    "    freq_val: str,\n",
    "    aggregate: bool,\n",
    "    include_status_flag: bool = False\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    typeids_final = []\n",
    "    for grp in chosen_groups:\n",
    "        typeids_final.extend(group_typeid_mapping.get(grp, []))\n",
    "    if not typeids_final:\n",
    "        logger.warning(\"Geen TypeIDs in chosen_groups.\")\n",
    "        return None\n",
    "    allowed_typeids_str = \",\".join(str(tid) for tid in set(typeids_final))\n",
    "    minp, maxp = fetch_min_max_period(ean_val, allowed_typeids_str, start_date, end_date)\n",
    "    if not minp or not maxp:\n",
    "        logger.info(\"Geen data (minp, maxp is None).\")\n",
    "        return None\n",
    "    if freq_val in get_freq_minutes.__globals__['FREQS']:\n",
    "        interval_minutes = get_freq_minutes(freq_val)\n",
    "    else:\n",
    "        logger.warning(f\"Frequency value '{freq_val}' not found in FREQS. Defaulting to 5 minutes for interval_minutes.\")\n",
    "        interval_minutes = 5\n",
    "    sp_include_status = (not aggregate) and include_status_flag\n",
    "    df_full = fetch_full_data(\n",
    "        ean_val,\n",
    "        allowed_typeids_str,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        interval_minutes=interval_minutes,\n",
    "        include_status=sp_include_status\n",
    "    )\n",
    "    if df_full is None or df_full.empty:\n",
    "        logger.info(\"Lege dataset (df_full).\")\n",
    "        return None\n",
    "    df_f = df_full[\n",
    "        (df_full['utcperiod'] >= start_date) &\n",
    "        (df_full['utcperiod'] <= end_date)\n",
    "    ].copy()\n",
    "    if df_f.empty:\n",
    "        logger.info(\"Geen rijen binnen periode.\")\n",
    "        return None\n",
    "    df_f.set_index('utcperiod', inplace=True)\n",
    "    if freq_val.lower() == 'auto':\n",
    "        periods = df_f.index.sort_values()\n",
    "        freq_val = detect_auto_frequency(periods)\n",
    "        logger.info(f\"Automatisch gedetecteerde frequentie: {freq_val}\")\n",
    "    if freq_val not in get_freq_minutes.__globals__['FREQS']:\n",
    "        logger.error(f\"Ongeldige frequentie '{freq_val}' voor resampling.\")\n",
    "        return None\n",
    "    if aggregate:\n",
    "        df_reset = df_f.reset_index()\n",
    "        selected_mapping = {grp: group_typeid_mapping[grp] for grp in chosen_groups if grp in group_typeid_mapping}\n",
    "        df_grouped = group_columns_by_typeid(df_reset, engine, selected_mapping)\n",
    "        df_grouped.set_index('utcperiod', inplace=True)\n",
    "        df_interest = df_grouped\n",
    "    else:\n",
    "        selected_mapping = {grp: group_typeid_mapping[grp] for grp in chosen_groups if grp in group_typeid_mapping}\n",
    "        df_interest = filter_columns_by_selected_groups(df_f, engine, selected_mapping)\n",
    "    if df_interest.empty:\n",
    "        logger.info(\"DataFrame is leeg na filteren/groeperen (df_interest).\")\n",
    "        return None\n",
    "    if not isinstance(df_interest.index, pd.DatetimeIndex):\n",
    "        logger.warning(\"df_interest index is not a DatetimeIndex. Attempting conversion.\")\n",
    "        try:\n",
    "            df_interest.index = pd.to_datetime(df_interest.index)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Kon df_interest.index niet converteren naar DatetimeIndex: {e}\")\n",
    "            return None\n",
    "    if df_interest.index.min() is pd.NaT or df_interest.index.max() is pd.NaT:\n",
    "        logger.warning(\"df_interest index contains NaT values or is empty after conversion. Cannot proceed with resampling.\")\n",
    "        return None\n",
    "    distributed_df = resample_dataframe(df_interest, freq_val, method='sum')\n",
    "    distributed_df = distributed_df.reset_index()\n",
    "    if 'index' in distributed_df.columns:\n",
    "        distributed_df.rename(columns={'index': 'UTC Period'}, inplace=True)\n",
    "    elif 'utcperiod' in distributed_df.columns:\n",
    "        distributed_df.rename(columns={'utcperiod': 'UTC Period'}, inplace=True)\n",
    "    cols = distributed_df.columns.tolist()\n",
    "    if 'UTC Period' in cols:\n",
    "        cols.insert(0, cols.pop(cols.index('UTC Period')))\n",
    "    distributed_df = distributed_df[cols]\n",
    "    final_cols = []\n",
    "    col_list = distributed_df.columns.tolist()\n",
    "    if 'UTC Period' in col_list:\n",
    "        final_cols.append('UTC Period')\n",
    "    consumption_cols = [c for c in col_list if c not in final_cols and '(consumption)' in c.lower()]\n",
    "    for ccol in consumption_cols:\n",
    "        final_cols.append(ccol)\n",
    "        status_candidate = ccol.replace('(consumption)', '(status)')\n",
    "        if status_candidate in col_list:\n",
    "            final_cols.append(status_candidate)\n",
    "    leftover_cols = [c for c in col_list if c not in final_cols]\n",
    "    final_cols.extend(leftover_cols)\n",
    "    distributed_df = distributed_df[final_cols]\n",
    "    return distributed_df\n",
    "\n",
    "def export_dataset_to_csv(df: pd.DataFrame, filename: str) -> bool:\n",
    "    if df is None or df.empty:\n",
    "        logger.warning(\"Kan niet exporteren: lege DataFrame.\")\n",
    "        return False\n",
    "    df_export = df.copy()\n",
    "    if \"UTC Period\" in df_export.columns:\n",
    "        df_export[\"UTC Period\"] = pd.to_datetime(df_export[\"UTC Period\"], errors='coerce').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df_export.to_csv(filename, index=False)\n",
    "    logger.info(f\"CSV geëxporteerd: {filename}\")\n",
    "    return True\n",
    "\n",
    "def export_dataset_to_excel(df: pd.DataFrame, filename: str, excel_format: bool, include_status: bool) -> bool:\n",
    "    if df is None or df.empty:\n",
    "        logger.warning(\"Kan niet exporteren: lege DataFrame.\")\n",
    "        return False\n",
    "    try:\n",
    "        from xlsxwriter.utility import xl_col_to_name\n",
    "        with pd.ExcelWriter(filename, engine='xlsxwriter', datetime_format='yyyy-mm-dd hh:mm:ss') as writer:\n",
    "            df.to_excel(writer, index=False, sheet_name='Dataset')\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets['Dataset']\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'text_wrap': True,\n",
    "                'align': 'center',\n",
    "                'valign': 'middle',\n",
    "                'fg_color': '#F2F2F2',\n",
    "                'border': 1,\n",
    "                'border_color': '#808080',\n",
    "                'font_name': 'Arial',\n",
    "                'font_size': 10\n",
    "            })\n",
    "            data_format = workbook.add_format({\n",
    "                'border': 1,\n",
    "                'border_color': '#808080',\n",
    "                'align': 'center',\n",
    "                'valign': 'middle',\n",
    "                'font_name': 'Arial',\n",
    "                'font_size': 10\n",
    "            })\n",
    "            df_columns = df.columns.tolist()\n",
    "            num_rows = len(df)\n",
    "            for col_num, value in enumerate(df_columns):\n",
    "                worksheet.write(0, col_num, value, header_format)\n",
    "                col_header = str(value).lower()\n",
    "                if col_header == 'utc period':\n",
    "                    col_width = 25\n",
    "                elif 'consumption' in col_header:\n",
    "                    col_width = 15\n",
    "                elif 'status' in col_header:\n",
    "                    col_width = 10\n",
    "                else:\n",
    "                    col_width = max(15, len(str(value)) + 2)\n",
    "                worksheet.set_column(col_num, col_num, col_width, data_format)\n",
    "            worksheet.set_row(0, 42)\n",
    "            worksheet.freeze_panes(1, 1)\n",
    "            if \"UTC Period\" in df_columns:\n",
    "                col_index = df_columns.index(\"UTC Period\")\n",
    "                worksheet.set_column(col_index, col_index, 25, workbook.add_format({\n",
    "                    'num_format': 'yyyy-mm-dd hh:mm:ss',\n",
    "                    'align': 'center',\n",
    "                    'valign': 'middle',\n",
    "                    'font_name': 'Arial',\n",
    "                    'font_size': 10\n",
    "                }))\n",
    "            status_p_format = workbook.add_format({\n",
    "                'bg_color': '#FFFFAF',\n",
    "                'align': 'center',\n",
    "                'valign': 'middle',\n",
    "                'border': 1,\n",
    "                'border_color': '#808080',\n",
    "                'font_name': 'Arial',\n",
    "                'font_size': 10\n",
    "            })\n",
    "            status_t_format = workbook.add_format({\n",
    "                'bg_color': '#FFDB69',\n",
    "                'align': 'center',\n",
    "                'valign': 'middle',\n",
    "                'border': 1,\n",
    "                'border_color': '#808080',\n",
    "                'font_name': 'Arial',\n",
    "                'font_size': 10\n",
    "            })\n",
    "            status_empty_format = workbook.add_format({\n",
    "                'bg_color': '#CCFFCC',\n",
    "                'align': 'center',\n",
    "                'valign': 'middle',\n",
    "                'border': 1,\n",
    "                'border_color': '#808080',\n",
    "                'font_name': 'Arial',\n",
    "                'font_size': 10\n",
    "            })\n",
    "            if excel_format:\n",
    "                for col_num, col_name in enumerate(df_columns):\n",
    "                    if 'consumption' in str(col_name).lower():\n",
    "                        if include_status:\n",
    "                            status_col_name = col_name.replace('(consumption)', '(status)')\n",
    "                            if status_col_name in df_columns:\n",
    "                                status_col_index = df_columns.index(status_col_name)\n",
    "                                status_letter = xl_col_to_name(status_col_index)\n",
    "                                worksheet.conditional_format(1, col_num, num_rows, col_num, {\n",
    "                                    'type': 'formula',\n",
    "                                    'criteria': f'=${status_letter}2=\"P\"',\n",
    "                                    'format': status_p_format,\n",
    "                                    'stop_if_true': True\n",
    "                                })\n",
    "                                worksheet.conditional_format(1, col_num, num_rows, col_num, {\n",
    "                                    'type': 'formula',\n",
    "                                    'criteria': f'=${status_letter}2=\"T\"',\n",
    "                                    'format': status_t_format,\n",
    "                                    'stop_if_true': True\n",
    "                                })\n",
    "                                worksheet.conditional_format(1, col_num, num_rows, col_num, {\n",
    "                                    'type': 'formula',\n",
    "                                    'criteria': f'=${status_letter}2=\"\"',\n",
    "                                    'format': status_empty_format,\n",
    "                                    'stop_if_true': True\n",
    "                                })\n",
    "                        else:\n",
    "                            worksheet.conditional_format(1, col_num, num_rows, col_num, {\n",
    "                                'type': '3_color_scale',\n",
    "                                'min_color': \"#FFFFFF\",\n",
    "                                'mid_color': \"#FFFFCC\",\n",
    "                                'max_color': \"#FFCCCC\"\n",
    "                            })\n",
    "                for col_num, col_name in enumerate(df_columns):\n",
    "                    if 'status' in str(col_name).lower():\n",
    "                        worksheet.conditional_format(1, col_num, num_rows, col_num, {\n",
    "                            'type': 'cell',\n",
    "                            'criteria': '==',\n",
    "                            'value': '\"P\"',\n",
    "                            'format': status_p_format\n",
    "                        })\n",
    "                        worksheet.conditional_format(1, col_num, num_rows, col_num, {\n",
    "                            'type': 'cell',\n",
    "                            'criteria': '==',\n",
    "                            'value': '\"T\"',\n",
    "                            'format': status_t_format\n",
    "                        })\n",
    "                        worksheet.conditional_format(1, col_num, num_rows, col_num, {\n",
    "                            'type': 'cell',\n",
    "                            'criteria': '==',\n",
    "                            'value': '\"\"',\n",
    "                            'format': status_empty_format\n",
    "                        })\n",
    "        logger.info(f\"Excel bestand opgeslagen: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error exporting to Excel: {e}\")\n",
    "        return False\n",
    "\n",
    "# === UI CONTROLS, LAYOUT EN INTERACTIES ===\n",
    "common_layout = widgets.Layout(width='240px', height='35px')\n",
    "start_datetime_input = widgets.Text(\n",
    "    value='01/01/2024 00:00',\n",
    "    placeholder='dd/mm/yyyy HH:MM',\n",
    "    description='StartDatum:',\n",
    "    layout=common_layout\n",
    ")\n",
    "end_datetime_input = widgets.Text(\n",
    "    value='31/12/2024 00:00',\n",
    "    placeholder='dd/mm/yyyy HH:MM',\n",
    "    description='EindDatum:',\n",
    "    layout=common_layout\n",
    ")\n",
    "freq_selector = widgets.Dropdown(\n",
    "    options=[('Automatisch (standaard)', 'auto'),\n",
    "             ('Elke 5 minuten', '5T'), ('Elke 15 minuten', '15T'),\n",
    "             ('Per uur', 'H'), ('Dagelijks', 'D'),\n",
    "             ('Wekelijks', 'W'),\n",
    "             ('Maandelijks', 'ME'), \n",
    "             ('Jaarlijks', 'Y')],\n",
    "    value='auto',\n",
    "    description='Frequentie:',\n",
    "    layout=common_layout\n",
    ")\n",
    "aggregate_checkbox = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Geaggregeerd?',\n",
    "    layout=widgets.Layout(margin='2px 0 2px 0')\n",
    ")\n",
    "status_checkbox = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Include Status? (en pas kleur op consumption aan)',\n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(margin='2px 0 2px 0')\n",
    ")\n",
    "excel_format_checkbox = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Voorwaardelijke opmaak Excel?',\n",
    "    layout=widgets.Layout(margin='2px 0 2px 0')\n",
    ")\n",
    "warning_message = widgets.HTML(\"\")\n",
    "warning_container = widgets.VBox([])\n",
    "quick_fix_freq_button = widgets.Button(\n",
    "    description=\"Wijzig freq naar 1 uur\",\n",
    "    button_style=\"warning\",\n",
    "    icon=\"clock-o\",\n",
    "    layout=common_layout\n",
    ")\n",
    "quick_fix_date_button = widgets.Button(\n",
    "    description=\"Beperk datumbereik\",\n",
    "    button_style=\"warning\",\n",
    "    icon=\"calendar\",\n",
    "    layout=common_layout\n",
    ")\n",
    "output_area = widgets.Output(layout={'border': '1px solid black'})\n",
    "data_table_output = widgets.Output(layout={\n",
    "    'border': '1px solid #ccc', 'overflow_x': 'auto',\n",
    "    'overflow_y': 'auto', 'max_height': '400px', 'width': '100%'\n",
    "})\n",
    "insights_output = widgets.Output(layout={\n",
    "    'border': '1px solid #ccc', 'overflow_x': 'auto',\n",
    "    'overflow_y': 'auto', 'max_height': '400px', 'width': '100%'\n",
    "})\n",
    "view_tab = widgets.Tab(children=[data_table_output, insights_output])\n",
    "view_tab.set_title(0, \"Dataset\")\n",
    "view_tab.set_title(1, \"Inzichten\")\n",
    "btn_load_filters = widgets.Button(description='Zoeken', button_style='info', icon='filter', layout=common_layout)\n",
    "btn_build_dataset = widgets.Button(description='Laad Dataset', button_style='success', icon='database', disabled=True, layout=common_layout)\n",
    "btn_view_dataset = widgets.Button(description=\"Bekijk Dataset\", button_style='primary', icon='eye', disabled=True, layout=common_layout)\n",
    "btn_view_insights = widgets.Button(description=\"Bekijk Inzichten\", button_style='primary', icon='info', disabled=True, layout=common_layout)\n",
    "btn_download_csv = widgets.Button(description=\"Download CSV\", button_style='primary', icon='download', disabled=True, layout=common_layout)\n",
    "btn_download_excel = widgets.Button(description=\"Download XLS\", button_style='primary', icon='file-excel-o', disabled=True, layout=common_layout)\n",
    "btn_reset_filters = widgets.Button(description='Reset Filters', button_style='warning', icon='refresh', layout=common_layout)\n",
    "ean_input = widgets.Text(\n",
    "    description='EAN:',\n",
    "    placeholder='Vul ID/EAN in',\n",
    "    value='',\n",
    "    layout=common_layout\n",
    ")\n",
    "options_container = widgets.VBox([aggregate_checkbox, status_checkbox, excel_format_checkbox])\n",
    "options_accordion = widgets.Accordion(children=[options_container])\n",
    "options_accordion.set_title(0, \"Opties\")\n",
    "options_accordion.selected_index = None\n",
    "group_checkbox_container = widgets.VBox([])\n",
    "group_accordion = widgets.Accordion(children=[group_checkbox_container])\n",
    "group_accordion.set_title(0, \"Beschikbare groepen\")\n",
    "group_accordion.selected_index = None\n",
    "row_top = widgets.HBox(\n",
    "    [ean_input, search_method_dropdown, btn_load_filters, btn_reset_filters],\n",
    "    layout=widgets.Layout(gap=\"5px\", flex_flow='row wrap')\n",
    ")\n",
    "row_dates = widgets.HBox([start_datetime_input, end_datetime_input, freq_selector],\n",
    "                         layout=widgets.Layout(gap=\"10px\", flex_flow='row wrap'))\n",
    "action_buttons_row = widgets.HBox(\n",
    "    [btn_build_dataset, btn_view_dataset, btn_view_insights, btn_download_csv, btn_download_excel],\n",
    "    layout=widgets.Layout(justify_content='flex-start', flex_flow='row wrap')\n",
    ")\n",
    "toggle_filters_button = widgets.Button(\n",
    "    description=\"Verberg filters\",\n",
    "    icon='chevron-up',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='150px', height='35px')\n",
    ")\n",
    "filters_container = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Filters</h3>\"),\n",
    "    row_top,\n",
    "    row_dates,\n",
    "    warning_container,\n",
    "    options_accordion,\n",
    "    group_accordion,\n",
    "    action_buttons_row,\n",
    "    progress_widget.widget(),  # Progress bar widget\n",
    "    output_area,\n",
    "    view_tab\n",
    "], layout=widgets.Layout(display='block', border='1px solid #ccc', padding='5px'))\n",
    "final_ui = widgets.VBox([\n",
    "    toggle_filters_button,\n",
    "    filters_container\n",
    "])\n",
    "display(final_ui)\n",
    "\n",
    "current_df = None\n",
    "\n",
    "def toggle_filters_display(b):\n",
    "    if filters_container.layout.display == 'none':\n",
    "        filters_container.layout.display = 'block'\n",
    "        toggle_filters_button.description = \"Verberg filters\"\n",
    "        toggle_filters_button.icon = \"chevron-up\"\n",
    "    else:\n",
    "        filters_container.layout.display = 'none'\n",
    "        toggle_filters_button.description = \"Toon filters\"\n",
    "        toggle_filters_button.icon = \"chevron-down\"\n",
    "toggle_filters_button.on_click(toggle_filters_display)\n",
    "\n",
    "def adjust_dates_on_freq_change(change):\n",
    "    freq_value = change['new'] if isinstance(change, dict) else change\n",
    "    if freq_value == 'auto':\n",
    "        return\n",
    "    start_dt_str = start_datetime_input.value\n",
    "    end_dt_str = end_datetime_input.value\n",
    "    start_dt_parsed = parse_user_datetime(start_dt_str)\n",
    "    end_dt_parsed = parse_user_datetime(end_dt_str)\n",
    "    if start_dt_parsed is None:\n",
    "        logger.warning(f\"Ongeldige startdatum '{start_dt_str}' bij aanpassen frequentie.\")\n",
    "        return\n",
    "    if end_dt_parsed is None:\n",
    "        logger.warning(f\"Ongeldige einddatum '{end_dt_str}' bij aanpassen frequentie.\")\n",
    "        return\n",
    "    adjusted_start_dt = round_datetime_to_freq(start_dt_parsed, freq_value, is_start=True)\n",
    "    adjusted_end_dt = round_datetime_to_freq(end_dt_parsed, freq_value, is_start=False)\n",
    "    if adjusted_start_dt:\n",
    "        start_datetime_input.value = adjusted_start_dt.strftime('%d/%m/%Y %H:%M')\n",
    "    if adjusted_end_dt:\n",
    "        end_datetime_input.value = adjusted_end_dt.strftime('%d/%m/%Y %H:%M')\n",
    "\n",
    "def validate_data_request(change=None):\n",
    "    start_dt = parse_user_datetime(start_datetime_input.value)\n",
    "    end_dt = parse_user_datetime(end_datetime_input.value)\n",
    "    current_warnings = []\n",
    "    if not start_dt:\n",
    "        current_warnings.append(\"Ongeldige startdatum/tijd (formaat dd/mm/yyyy HH:MM)!\")\n",
    "    if not end_dt:\n",
    "        current_warnings.append(\"Ongeldige einddatum/tijd (formaat dd/mm/yyyy HH:MM)!\")\n",
    "    if start_dt and end_dt and end_dt < start_dt:\n",
    "        current_warnings.append(\"Einddatum mag niet vóór de startdatum liggen.\")\n",
    "    freq_val = freq_selector.value\n",
    "    if freq_val.lower() != 'auto' and start_dt and end_dt and end_dt >= start_dt:\n",
    "        is_ok, expected_rows = check_max_rows(start_dt, end_dt, freq_val, max_rows=MAX_ROWS)\n",
    "        if not is_ok:\n",
    "            warning_text = (\n",
    "                f\"U probeert te veel data op te vragen ({int(expected_rows)} rijen bij freq '{freq_val}'). \"\n",
    "                \"Verklein het datumbereik of verhoog de resolutie (bijv. naar 'Per uur').\"\n",
    "            )\n",
    "            current_warnings.append(warning_text)\n",
    "            warning_container.children = [\n",
    "                widgets.HTML(f\"<span style='color:red; font-weight:bold;'>{'; '.join(current_warnings)}</span>\"),\n",
    "                widgets.HBox([quick_fix_freq_button, quick_fix_date_button], layout=widgets.Layout(justify_content='center'))\n",
    "            ]\n",
    "            return\n",
    "    if current_warnings:\n",
    "        warning_message.value = f\"<span style='color:red; font-weight:bold;'>{'; '.join(current_warnings)}</span>\"\n",
    "        quick_fix_buttons_display = []\n",
    "        if any(\"te veel data\" in warn_msg for warn_msg in current_warnings):\n",
    "            quick_fix_buttons_display = [widgets.HBox([quick_fix_freq_button, quick_fix_date_button], layout=widgets.Layout(justify_content='center'))]\n",
    "        warning_container.children = [warning_message] + quick_fix_buttons_display\n",
    "    else:\n",
    "        warning_message.value = \"\"\n",
    "        warning_container.children = []\n",
    "\n",
    "def on_aggregate_change(change):\n",
    "    status_checkbox.disabled = change['new']\n",
    "aggregate_checkbox.observe(on_aggregate_change, names='value')\n",
    "status_checkbox.disabled = aggregate_checkbox.value\n",
    "\n",
    "def on_freq_change_and_validate(change):\n",
    "    adjust_dates_on_freq_change(change)\n",
    "    validate_data_request(change)\n",
    "\n",
    "start_datetime_input.observe(validate_data_request, names=\"value\")\n",
    "end_datetime_input.observe(validate_data_request, names=\"value\")\n",
    "freq_selector.observe(on_freq_change_and_validate, names='value')\n",
    "\n",
    "def quick_fix_freq_action(b):\n",
    "    freq_selector.value = 'H'\n",
    "quick_fix_freq_button.on_click(quick_fix_freq_action)\n",
    "\n",
    "def quick_fix_date_action(b):\n",
    "    start_dt = parse_user_datetime(start_datetime_input.value)\n",
    "    if not start_dt:\n",
    "        return\n",
    "    freq_val = freq_selector.value\n",
    "    if freq_val == 'auto':\n",
    "        logger.info(\"Quick fix date: Freq is 'auto', using 'H' for calculation.\")\n",
    "        freq_val = 'H'\n",
    "    seconds_per_interval = get_freq_seconds(freq_val)\n",
    "    if seconds_per_interval <= 0:\n",
    "        seconds_per_interval = 3600\n",
    "    max_duration = (MAX_ROWS - 1) * seconds_per_interval\n",
    "    new_end_dt = start_dt + timedelta(seconds=max_duration)\n",
    "    end_datetime_input.value = new_end_dt.strftime('%d/%m/%Y %H:%M')\n",
    "    validate_data_request()\n",
    "quick_fix_date_button.on_click(quick_fix_date_action)\n",
    "\n",
    "def load_filters_thread(ean_val: str):\n",
    "    btn_build_dataset.disabled = True\n",
    "    btn_view_dataset.disabled = True\n",
    "    btn_view_insights.disabled = True\n",
    "    btn_download_csv.disabled = True\n",
    "    btn_download_excel.disabled = True\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(\"Filters worden geladen...\")\n",
    "    typeids = fetch_typeids_for_ean(ean_val)\n",
    "    if not typeids:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(\"Geen TypeIDs gevonden voor deze invoer.\")\n",
    "        group_checkbox_container.children = []\n",
    "        group_accordion.selected_index = None\n",
    "        return\n",
    "    relevant_groups = []\n",
    "    for grp, tlist in group_typeid_mapping.items():\n",
    "        if set(tlist).intersection(typeids):\n",
    "            relevant_groups.append(grp)\n",
    "    if not relevant_groups:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(\"Geen relevante groepen gevonden voor de TypeIDs.\")\n",
    "        group_checkbox_container.children = []\n",
    "        group_accordion.selected_index = None\n",
    "        return\n",
    "    checkboxes = []\n",
    "    for grp in sorted(relevant_groups):\n",
    "        cb = widgets.Checkbox(value=True, description=grp, indent=False)\n",
    "        checkboxes.append(cb)\n",
    "    group_checkbox_container.children = checkboxes\n",
    "    group_accordion.selected_index = 0\n",
    "    btn_build_dataset.disabled = False\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(f\"Filters geladen. Beschikbare groepen: {', '.join(sorted(relevant_groups))}\")\n",
    "\n",
    "def on_load_filters_clicked(b):\n",
    "    ean_val = ean_input.value.strip()\n",
    "    if not ean_val:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(\"Vul een EAN of ID in.\")\n",
    "        return\n",
    "    threading.Thread(target=load_filters_thread, args=(ean_val,)).start()\n",
    "\n",
    "def on_reset_filters_clicked(b):\n",
    "    if group_checkbox_container.children:\n",
    "        for cb in group_checkbox_container.children:\n",
    "            cb.value = True\n",
    "    ean_input.value = ''\n",
    "    start_datetime_input.value = '01/01/2024 00:00'\n",
    "    end_datetime_input.value = '31/12/2024 00:00'\n",
    "    freq_selector.value = 'auto'\n",
    "    aggregate_checkbox.value = True\n",
    "    status_checkbox.value = False\n",
    "    excel_format_checkbox.value = False\n",
    "    status_checkbox.disabled = aggregate_checkbox.value\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(\"Filters zijn gereset.\")\n",
    "    validate_data_request()\n",
    "\n",
    "def get_selected_groups() -> List[str]:\n",
    "    return [cb.description for cb in group_checkbox_container.children if cb.value]\n",
    "\n",
    "def build_dataset_thread():\n",
    "    global current_df\n",
    "    btn_build_dataset.disabled = True\n",
    "    btn_view_dataset.disabled = True\n",
    "    btn_view_insights.disabled = True\n",
    "    btn_download_csv.disabled = True\n",
    "    btn_download_excel.disabled = True\n",
    "    progress_widget.show(status=\"Dataset wordt opgebouwd...\")  # Toon en reset progress bar\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "    ean_val = ean_input.value.strip()\n",
    "    if not ean_val:\n",
    "        with output_area:\n",
    "            print(\"Vul een EAN/ID in.\")\n",
    "        progress_widget.update(100, \"Fout: EAN/ID ontbreekt\", error=True)\n",
    "        progress_widget.finish()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "    validate_data_request()\n",
    "    if warning_container.children:\n",
    "        with output_area:\n",
    "            display(HTML(\"<span style='color:red; font-weight:bold;'>Los de validatiefouten op voordat u de dataset bouwt.</span>\"))\n",
    "        progress_widget.update(100, \"Validatiefout\", error=True)\n",
    "        progress_widget.finish()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "    start_dt = parse_user_datetime(start_datetime_input.value)\n",
    "    end_dt = parse_user_datetime(end_datetime_input.value)\n",
    "    if not start_dt or not end_dt:\n",
    "        with output_area:\n",
    "            print(\"Interne fout: Ongeldige datums ondanks validatie.\")\n",
    "        progress_widget.update(100, \"Fout: Interne datumfout\", error=True)\n",
    "        progress_widget.finish()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "    freq_val = freq_selector.value\n",
    "    agg_val = aggregate_checkbox.value\n",
    "    status_val = status_checkbox.value\n",
    "    chosen = get_selected_groups()\n",
    "    if not chosen:\n",
    "        with output_area:\n",
    "            print(\"Geen groepen geselecteerd.\")\n",
    "        progress_widget.update(100, \"Fout: Geen groepen\", error=True)\n",
    "        progress_widget.finish()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "    progress_widget.update(30, \"TypeIDs en min/max periode ophalen...\")\n",
    "    df_resampled = build_dataset(\n",
    "        ean_val,\n",
    "        chosen,\n",
    "        start_dt,\n",
    "        end_dt,\n",
    "        freq_val,\n",
    "        agg_val,\n",
    "        include_status_flag=status_val\n",
    "    )\n",
    "    progress_widget.update(80, \"Dataset verwerken...\")\n",
    "    if df_resampled is None or df_resampled.empty:\n",
    "        progress_widget.update(100, \"Geen dataset opgehaald.\", error=True)\n",
    "        with output_area:\n",
    "            print(\"Geen dataset opgehaald. Controleer filters of logs voor details.\")\n",
    "        progress_widget.finish()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "    current_df = df_resampled.copy()\n",
    "    progress_widget.update(100, f\"Dataset geladen met {len(current_df)} rijen.\")\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Dataset succesvol geladen met {len(current_df)} rijen.\\nU kunt nu de dataset bekijken, inzichten genereren of downloaden.\")\n",
    "    btn_view_dataset.disabled = False\n",
    "    btn_view_insights.disabled = False\n",
    "    btn_download_csv.disabled = False\n",
    "    btn_download_excel.disabled = False\n",
    "    progress_widget.finish()\n",
    "    btn_build_dataset.disabled = False\n",
    "\n",
    "def on_build_dataset_clicked(b):\n",
    "    with data_table_output: clear_output()\n",
    "    with insights_output: clear_output()\n",
    "    threading.Thread(target=build_dataset_thread).start()\n",
    "\n",
    "def show_dataset_table():\n",
    "    with data_table_output:\n",
    "        clear_output(wait=True)\n",
    "        if current_df is None or current_df.empty:\n",
    "            print(\"Nog geen dataset geladen of de dataset is leeg.\")\n",
    "        else:\n",
    "            limit = 50\n",
    "            html_table = current_df.head(limit).to_html(classes=\"dataframe\", index=False, escape=True)\n",
    "            info_message = \"\"\n",
    "            if len(current_df) > limit:\n",
    "                info_message = f\"<p><i>Toont de eerste {limit} rijen van {len(current_df)} totale rijen. Download voor de volledige dataset.</i></p>\"\n",
    "            scrollable_html = f\"\"\"\n",
    "            <div style=\"overflow-x: auto; overflow-y: auto; max-height: 380px; width: 100%;\">\n",
    "                {html_table}\n",
    "            </div>\n",
    "            {info_message}\n",
    "            \"\"\"\n",
    "            display(HTML(scrollable_html))\n",
    "    view_tab.selected_index = 0\n",
    "\n",
    "def show_insights():\n",
    "    with insights_output:\n",
    "        clear_output(wait=True)\n",
    "        if current_df is None or current_df.empty:\n",
    "            print(\"Nog geen dataset geladen of de dataset is leeg om inzichten te genereren.\")\n",
    "        else:\n",
    "            insights_html = generate_insights(current_df)\n",
    "            display(HTML(f\"<div style='font-family: Roboto, sans-serif; font-size:14px;'>{insights_html}</div>\"))\n",
    "    view_tab.selected_index = 1\n",
    "\n",
    "def on_view_dataset_clicked(b):\n",
    "    show_dataset_table()\n",
    "\n",
    "def on_view_insights_clicked(b):\n",
    "    show_insights()\n",
    "\n",
    "def on_download_csv_clicked(b):\n",
    "    if current_df is None or current_df.empty:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Geen dataset om te downloaden.\")\n",
    "        return\n",
    "    ean_val = ean_input.value.strip().replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename_base = f\"dataset_{ean_val}_{ts}.csv\"\n",
    "    downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "    if not os.path.isdir(downloads_folder):\n",
    "        try:\n",
    "            os.makedirs(downloads_folder)\n",
    "        except OSError:\n",
    "            logger.warning(f\"Kon map {downloads_folder} niet aanmaken. CSV wordt opgeslagen in huidige werkmap.\")\n",
    "            downloads_folder = os.getcwd()\n",
    "    filename = os.path.join(downloads_folder, filename_base)\n",
    "    if export_dataset_to_csv(current_df, filename):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(f\"<p>CSV bestand opgeslagen in uw Downloads map: <code>{filename}</code></p>\"\n",
    "                         f\"<p>Als de download niet automatisch start, kunt u het bestand hier vinden.</p>\"))\n",
    "    else:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Fout bij exporteren naar CSV.\")\n",
    "\n",
    "def on_download_excel_clicked(b):\n",
    "    if current_df is None or current_df.empty:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Geen dataset om te downloaden.\")\n",
    "        return\n",
    "    ean_val = ean_input.value.strip().replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename_base = f\"dataset_{ean_val}_{ts}.xlsx\"\n",
    "    downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "    if not os.path.isdir(downloads_folder):\n",
    "        try:\n",
    "            os.makedirs(downloads_folder)\n",
    "        except OSError:\n",
    "            logger.warning(f\"Kon map {downloads_folder} niet aanmaken. Excel wordt opgeslagen in huidige werkmap.\")\n",
    "            downloads_folder = os.getcwd()\n",
    "    filename = os.path.join(downloads_folder, filename_base)\n",
    "    apply_excel_format = excel_format_checkbox.value\n",
    "    include_status_for_formatting = status_checkbox.value and not aggregate_checkbox.value\n",
    "    if export_dataset_to_excel(current_df, filename, apply_excel_format, include_status_for_formatting):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(f\"<p>Excel bestand opgeslagen in uw Downloads map: <code>{filename}</code></p>\"\n",
    "                         f\"<p>Als de download niet automatisch start, kunt u het bestand hier vinden.</p>\"))\n",
    "    else:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Fout bij exporteren naar Excel.\")\n",
    "\n",
    "btn_load_filters.on_click(on_load_filters_clicked)\n",
    "btn_reset_filters.on_click(on_reset_filters_clicked)\n",
    "btn_build_dataset.on_click(on_build_dataset_clicked)\n",
    "btn_view_dataset.on_click(on_view_dataset_clicked)\n",
    "btn_view_insights.on_click(on_view_insights_clicked)\n",
    "btn_download_csv.on_click(on_download_csv_clicked)\n",
    "btn_download_excel.on_click(on_download_excel_clicked)\n",
    "\n",
    "# Initial validation call to check default dates\n",
    "validate_data_request()\n",
    "adjust_dates_on_freq_change({'new': freq_selector.value})\n",
    "validate_data_request()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energymonitor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
