<<<<<<< Updated upstream
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30a1a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root {\n",
       "    --primary-color: #0069d9;\n",
       "    --primary-hover: #005cbf;\n",
       "    --primary-active: #0050a3;\n",
       "    --text-color: #2c3e50;\n",
       "    --bg-input: #ffffff;\n",
       "    --border-input: #dfe3e8;\n",
       "    --border-radius: 6px;\n",
       "    --spacing: 0.5rem;\n",
       "    --transition-speed: 0.2s;\n",
       "}\n",
       "\n",
       "/* --- Basis typografie & body --- */\n",
       "body,\n",
       ".widget-label,\n",
       ".widget-html,\n",
       ".widget-dropdown,\n",
       ".widget-text {\n",
       "    font-family: 'Inter', sans-serif !important;\n",
       "    font-size: 0.95rem !important;\n",
       "    color: var(--text-color) !important;\n",
       "}\n",
       "\n",
       "/* --- Globale container alignment --- */\n",
       ".jupyter-widgets.widget-container.widget-label {\n",
       "    display: flex !important;\n",
       "    align-items: center !important;\n",
       "}\n",
       "\n",
       "/* --- Labels --- */\n",
       ".widget-label {\n",
       "    margin-right: var(--spacing) !important;\n",
       "    font-weight: 500 !important;\n",
       "}\n",
       "\n",
       ".widget-text input[type=\"text\"],\n",
       ".widget-text input[type=\"number\"],\n",
       ".widget-dropdown select {\n",
       "    display: inline-block !important;\n",
       "    width: auto !important;\n",
       "    min-width: 8rem !important;\n",
       "    height: 2.5rem !important;\n",
       "    padding: 0 var(--spacing) !important;\n",
       "    margin: var(--spacing) 0 !important;\n",
       "    border: 1px solid var(--border-input) !important;\n",
       "    border-radius: var(--border-radius) !important;\n",
       "    background-color: var(--bg-input) !important;\n",
       "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.05) !important;\n",
       "    transition: border-color var(--transition-speed) ease-in-out !important;\n",
       "}\n",
       ".widget-text input:focus,\n",
       ".widget-dropdown select:focus {\n",
       "    border-color: var(--primary-color) !important;\n",
       "    outline: none !important;\n",
       "    box-shadow: 0 0 0 2px rgba(0,105,217,0.2) !important;\n",
       "}\n",
       ".widget-button {\n",
       "    display: inline-flex !important;\n",
       "    align-items: center !important;\n",
       "    justify-content: center !important;\n",
       "    padding: 0 var(--spacing) !important;\n",
       "    margin: var(--spacing) var(--spacing) 0 0 !important;\n",
       "    height: 2.5rem !important;\n",
       "    min-width: 6.5rem !important;\n",
       "    font-weight: 600 !important;\n",
       "    font-size: 0.9rem !important;\n",
       "    color: #fff !important;\n",
       "    background-color: var(--primary-color) !important;\n",
       "    border: 1px solid var(--primary-color) !important;\n",
       "    border-radius: var(--border-radius) !important;\n",
       "    box-shadow: 0 2px 6px rgba(0,0,0,0.1) !important;\n",
       "    cursor: pointer !important;\n",
       "    transition:\n",
       "        background-color var(--transition-speed) ease,\n",
       "        border-color var(--transition-speed) ease,\n",
       "        box-shadow var(--transition-speed) ease,\n",
       "        transform var(--transition-speed) ease !important;\n",
       "}\n",
       ".widget-button:hover {\n",
       "    background-color: var(--primary-hover) !important;\n",
       "    border-color: var(--primary-hover) !important;\n",
       "    box-shadow: 0 4px 12px rgba(0,0,0,0.15) !important;\n",
       "    transform: translateY(-1px) !important;\n",
       "}\n",
       ".widget-button:active {\n",
       "    background-color: var(--primary-active) !important;\n",
       "    border-color: var(--primary-active) !important;\n",
       "    box-shadow: 0 2px 6px rgba(0,0,0,0.1) !important;\n",
       "    transform: translateY(0) !important;\n",
       "}\n",
       ".widget-button:disabled {\n",
       "    background-color: #a0aec0 !important;\n",
       "    border-color: #a0aec0 !important;\n",
       "    box-shadow: none !important;\n",
       "    opacity: 0.7 !important;\n",
       "    cursor: not-allowed !important;\n",
       "}\n",
       "\n",
       ".widget-button.mod-outline {\n",
       "    background-color: transparent !important;\n",
       "    color: var(--primary-color) !important;\n",
       "    border: 1px solid var(--primary-color) !important;\n",
       "}\n",
       ".widget-button.mod-outline:hover {\n",
       "    background-color: rgba(0,105,217,0.1) !important;\n",
       "}\n",
       "\n",
       "/* --- Checkbox labels --- */\n",
       ".widget-checkbox label {\n",
       "    margin-left: var(--spacing) !important;\n",
       "    font-weight: 400 !important;\n",
       "}\n",
       "\n",
       "/* --- Accordion headers & containers --- */\n",
       ".widget-accordion > .widget-label {\n",
       "    font-weight: 600 !important;\n",
       "    margin-bottom: 0.25rem !important;\n",
       "}\n",
       "\n",
       "/* --- Progress bar styling (optioneel) --- */\n",
       ".jupyter-widgets .progress {\n",
       "    height: 0.75rem !important;\n",
       "    margin-top: var(--spacing) !important;\n",
       "    background-color: #e9ecef !important;\n",
       "    border-radius: var(--border-radius) !important;\n",
       "}\n",
       ".jupyter-widgets .progress-bar {\n",
       "    transition: width var(--transition-speed) ease !important;\n",
       "}\n",
       "\n",
       "/* ——— Zorg dat HBox-containers wrappen en baseline uitlijnen ——— */\n",
       ".jupyter-widgets .widget-hbox {\n",
       "    display: flex !important;\n",
       "    flex-wrap: wrap !important;\n",
       "    align-items: baseline !important;\n",
       "    gap: var(--spacing) !important;\n",
       "}\n",
       ".jupyter-widgets .widget-hbox .widget-label,\n",
       ".jupyter-widgets .widget-hbox .widget-text,\n",
       ".jupyter-widgets .widget-hbox .widget-dropdown,\n",
       ".jupyter-widgets .widget-hbox .widget-button {\n",
       "    align-self: baseline !important;\n",
       "    margin-top: 0 !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Python executable: c:\\Users\\StanvanBon\\Miniconda3\\envs\\energymonitor_env\\python.exe\n",
      "▶ dotenv module: c:\\Users\\StanvanBon\\Miniconda3\\envs\\energymonitor_env\\Lib\\site-packages\\dotenv\\__init__.py\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658a077270604f29895e940b3b195663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='info', description='Terug naar Startscherm', icon='home', layout=Layout(he…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893cd62f91b941698cba8307d3093e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef84d775c75d4a6fb2a07bc4880a8e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='info', description='Verberg filters', icon='chevron-up', layout=Layout(hei…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common_imports import *\n",
    "show_home_button()\n",
    "from db_connection import get_engine\n",
    "engine = get_engine()\n",
    "logging .basicConfig (level =logging .INFO )\n",
    "logger =logging .getLogger (__name__ )\n",
    "\n",
    "# Added imports\n",
    "import pytz\n",
    "from datetime import time as dt_time\n",
    "\n",
    "# --- Utils Section ---\n",
    "class DateAdjustmentUtils:\n",
    "    AMSTERDAM_TZ = pytz.timezone('Europe/Amsterdam')\n",
    "\n",
    "    @staticmethod\n",
    "    def localize_to_amsterdam(dt: datetime) -> datetime:\n",
    "        \"\"\"Localizes a naive datetime object to Europe/Amsterdam timezone.\"\"\"\n",
    "        if dt.tzinfo is None:\n",
    "            return DateAdjustmentUtils.AMSTERDAM_TZ.localize(dt)\n",
    "        return dt.astimezone(DateAdjustmentUtils.AMSTERDAM_TZ)\n",
    "\n",
    "    @staticmethod\n",
    "    def round_datetime(dt: datetime, freq_value: str, is_start_date: bool) -> Optional[datetime]:\n",
    "        \"\"\"\n",
    "        Rounds a datetime object based on the given frequency.\n",
    "        'dt' is assumed to be a naive datetime object.\n",
    "        Returns a timezone-aware datetime object (Europe/Amsterdam).\n",
    "        \"\"\"\n",
    "        if not dt:\n",
    "            logger.warning(\"round_datetime received None for dt.\")\n",
    "            return None\n",
    "\n",
    "        # Ensure dt is naive, then localize to Amsterdam\n",
    "        dt_ams = DateAdjustmentUtils.localize_to_amsterdam(dt.replace(tzinfo=None))\n",
    "\n",
    "        if freq_value == '5T':\n",
    "            minute_rounded = (dt_ams.minute // 5) * 5\n",
    "            return dt_ams.replace(minute=minute_rounded, second=0, microsecond=0)\n",
    "        elif freq_value == '15T':\n",
    "            minute_rounded = (dt_ams.minute // 15) * 15\n",
    "            return dt_ams.replace(minute=minute_rounded, second=0, microsecond=0)\n",
    "        elif freq_value == 'H':\n",
    "            return dt_ams.replace(minute=0, second=0, microsecond=0)\n",
    "        elif freq_value == 'D':\n",
    "            # Start: 00:00 of geselecteerde dag\n",
    "            # Eind: 00:00 volgende dag\n",
    "            base_dt = dt_ams.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "            if not is_start_date:  # This is an end date\n",
    "                return base_dt + timedelta(days=1)\n",
    "            return base_dt\n",
    "        elif freq_value == 'W':\n",
    "            # Start: ma 00:00 van dezelfde ISO-week\n",
    "            # Eind: ma 00:00 van week +1\n",
    "            # weekday() returns 0 for Monday, 6 for Sunday\n",
    "            start_of_this_week = (dt_ams - timedelta(days=dt_ams.weekday())).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "            if not is_start_date:  # This is an end date\n",
    "                return start_of_this_week + timedelta(weeks=1)\n",
    "            return start_of_this_week\n",
    "        elif freq_value == 'ME': # Changed from 'M' to 'ME' to match dropdown and internal dicts if selector is updated\n",
    "            # Start: 1e 00:00 van maand\n",
    "            # Eind: 1e 00:00 volgende maand\n",
    "            start_of_this_month = dt_ams.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "            if not is_start_date:  # This is an end date\n",
    "                next_month_year = start_of_this_month.year\n",
    "                next_month_month = start_of_this_month.month + 1\n",
    "                if next_month_month > 12:\n",
    "                    next_month_month = 1\n",
    "                    next_month_year += 1\n",
    "                return start_of_this_month.replace(year=next_month_year, month=next_month_month)\n",
    "            return start_of_this_month\n",
    "        elif freq_value == 'Y':\n",
    "            # Start: 1 jan 00:00\n",
    "            # Eind: 1 jan 00:00 volgend jaar\n",
    "            start_of_this_year = dt_ams.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "            if not is_start_date:  # This is an end date\n",
    "                return start_of_this_year.replace(year=start_of_this_year.year + 1)\n",
    "            return start_of_this_year\n",
    "        \n",
    "        logger.warning(f\"Onbekende freq_value '{freq_value}' in DateAdjustmentUtils.round_datetime. Datum niet aangepast.\")\n",
    "        return dt_ams # Fallback: return original localized datetime\n",
    "\n",
    "class TTLCache :\n",
    "    \"\"\"Thread-safe cache met Time-To-Live (standaard 5 minuten).\"\"\"\n",
    "    def __init__ (self ,ttl :int =300 ):\n",
    "        self .cache ={}\n",
    "        self .ttl =ttl\n",
    "        self .lock =threading .Lock ()\n",
    "\n",
    "    def get (self ,key ):\n",
    "        with self .lock :\n",
    "            entry =self .cache .get (key )\n",
    "            if entry is None :\n",
    "                return None\n",
    "            value ,expires_at =entry\n",
    "            if time .time ()>expires_at :\n",
    "                del self .cache [key ]\n",
    "                return None\n",
    "            return value\n",
    "\n",
    "    def set (self ,key ,value ):\n",
    "        with self .lock :\n",
    "            expires_at =time .time ()+self .ttl\n",
    "            self .cache [key ]=(value ,expires_at )\n",
    "\n",
    "min_max_cache =TTLCache (ttl =300 )\n",
    "full_data_cache =TTLCache (ttl =300 )\n",
    "\n",
    "from mappings import get_typeids, validate_unique_ids, group_typeid_mapping\n",
    "\n",
    "validate_unique_ids()\n",
    "\n",
    "FREQ_TO_SECONDS ={\n",
    "'5T':300 ,\n",
    "'15T':900 ,\n",
    "'H':3600 ,\n",
    "'D':86400 ,\n",
    "'W':604800 ,\n",
    "'ME':2592000 , # For 30 days, actual month length varies\n",
    "'Y':31536000  # For 365 days\n",
    "}\n",
    "FREQ_TO_MINUTES ={\n",
    "'5T':5 ,\n",
    "'15T':15 ,\n",
    "'H':60 ,\n",
    "'D':1440 ,\n",
    "'W':10080 ,\n",
    "'ME':43200 , # For 30 days\n",
    "'Y':525600  # For 365 days\n",
    "}\n",
    "MAX_ROWS =8000\n",
    "def parse_user_datetime (dt_str :str )->Optional [datetime ]:\n",
    "    try :\n",
    "        return datetime .strptime (dt_str ,'%d/%m/%Y %H:%M')\n",
    "    except ValueError :\n",
    "        return None\n",
    "def generate_insights (df :pd .DataFrame )->str :\n",
    "    \"\"\"\n",
    "    Genereert inzichten in tabelvorm per status-kanaal en geeft een HTML-tabel.\n",
    "    \"\"\"\n",
    "    insights_df =get_insights_df (df )\n",
    "    if insights_df .empty :\n",
    "        return \"Geen inzichten beschikbaar.\"\n",
    "    return insights_df .to_html (classes =\"dataframe\",border =0 )\n",
    "\n",
    "def get_insights_df (df :pd .DataFrame )->pd .DataFrame :\n",
    "    \"\"\"\n",
    "    Genereert inzichten als DataFrame per status-kanaal.\n",
    "    Voor elk status-kanaal en per status (\"P\" of \"T\") wordt het aantal voorkomen,\n",
    "    plus de eerste (van datum) en laatste (tot datum) keer dat deze status voorkomt.\n",
    "    \"\"\"\n",
    "    if df is None or df .empty :\n",
    "        return pd .DataFrame ()\n",
    "\n",
    "    time_col =None\n",
    "    if \"UTC Period\"in df .columns :\n",
    "        time_col =\"UTC Period\"\n",
    "    elif \"utcperiod\"in df .columns :\n",
    "        time_col =\"utcperiod\"\n",
    "\n",
    "    status_cols =[col for col in df .columns if 'status'in col .lower ()]\n",
    "    if not status_cols :\n",
    "        return pd .DataFrame ()\n",
    "\n",
    "    rows =[]\n",
    "    for col in status_cols :\n",
    "        for stat in [\"P\",\"T\"]:\n",
    "            count =(df [col ]==stat ).sum ()\n",
    "            if count >0 and time_col is not None :\n",
    "                dates =pd .to_datetime (df .loc [df [col ]==stat ,time_col ],errors ='coerce')\n",
    "                start_date =dates .min ()\n",
    "                end_date =dates .max ()\n",
    "            else :\n",
    "                start_date =None\n",
    "                end_date =None\n",
    "            rows .append ({\n",
    "            \"Kanaal\":col ,\n",
    "            \"Status\":stat ,\n",
    "            \"Count\":count ,\n",
    "            \"Van datum\":start_date ,\n",
    "            \"Tot datum\":end_date\n",
    "            })\n",
    "\n",
    "    insights_df =pd .DataFrame (rows )\n",
    "    insights_df .set_index ([\"Kanaal\",\"Status\"],inplace =True )\n",
    "    return insights_df\n",
    "def group_columns_by_typeid (df :pd .DataFrame ,engine ,group_mapping :dict )->pd .DataFrame :\n",
    "    import re\n",
    "    registerid_pattern =re .compile (r'\\((\\d+)\\)')\n",
    "    col_to_registerid ={}\n",
    "    for col in df .columns :\n",
    "        if col .lower ()in ['utcperiod','utc period']:\n",
    "            continue\n",
    "        match =registerid_pattern .search (col )\n",
    "        if match :\n",
    "            reg_id =int (match .group (1 ))\n",
    "            col_to_registerid [col ]=reg_id\n",
    "    if not col_to_registerid :\n",
    "        raise ValueError (\"Geen register-ID's gevonden in de DataFrame kolomnamen.\")\n",
    "\n",
    "    query =\"SELECT ID, TypeId FROM dbo.TBL_Register WHERE ID IN ({})\".format (\n",
    "    \",\".join (map (str ,list (col_to_registerid .values ())))\n",
    "    )\n",
    "    with engine .connect ()as conn :\n",
    "        mapping_df =pd .read_sql_query (query ,conn )\n",
    "    registerid_to_typeid =dict (zip (mapping_df ['ID'],mapping_df ['TypeId']))\n",
    "\n",
    "    grouped_df =df [['utcperiod']].copy ()if 'utcperiod'in df .columns else df .copy ()\n",
    "\n",
    "    for group_name ,typeid_list in group_mapping .items ():\n",
    "        cols_for_group =[]\n",
    "        for col ,reg_id in col_to_registerid .items ():\n",
    "            typeid_val =registerid_to_typeid .get (reg_id )\n",
    "            if typeid_val in typeid_list :\n",
    "                cols_for_group .append (col )\n",
    "\n",
    "        if cols_for_group :\n",
    "            numeric_subset =[c for c in cols_for_group if '(status)'not in c .lower ()]\n",
    "            if numeric_subset :\n",
    "                grouped_df [group_name +\" Total\"]=df [numeric_subset ].sum (axis =1 ,numeric_only =True )\n",
    "            else :\n",
    "                grouped_df [group_name +\" Total\"]=0\n",
    "        else :\n",
    "            grouped_df [group_name +\" Total\"]=0\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "def filter_columns_by_selected_groups (df :pd .DataFrame ,engine ,group_mapping :dict )->pd .DataFrame :\n",
    "    import re\n",
    "    registerid_pattern =re .compile (r'\\((\\d+)\\)')\n",
    "    col_to_registerid ={}\n",
    "    for col in df .columns :\n",
    "        if col .lower ()in ['utcperiod','utc period']:\n",
    "            continue\n",
    "        match =registerid_pattern .search (col )\n",
    "        if match :\n",
    "            col_to_registerid [col ]=int (match .group (1 ))\n",
    "    if not col_to_registerid :\n",
    "        return df [['utcperiod']]if 'utcperiod'in df .columns else pd .DataFrame ()\n",
    "\n",
    "    query =\"SELECT ID, TypeId FROM dbo.TBL_Register WHERE ID IN ({})\".format (\n",
    "    \",\".join (map (str ,list (col_to_registerid .values ())))\n",
    "    )\n",
    "    with engine .connect ()as conn :\n",
    "        mapping_df =pd .read_sql_query (query ,conn )\n",
    "    regid_to_typeid =dict (zip (mapping_df ['ID'],mapping_df ['TypeId']))\n",
    "\n",
    "    selected_cols =[]\n",
    "    for col ,reg_id in col_to_registerid .items ():\n",
    "        typeid_val =regid_to_typeid .get (reg_id )\n",
    "        for grp ,tid_list in group_mapping .items ():\n",
    "            if typeid_val in tid_list :\n",
    "                selected_cols .append (col )\n",
    "                break\n",
    "\n",
    "    cols =[]\n",
    "    if 'utcperiod'in df .columns :\n",
    "        cols .append ('utcperiod')\n",
    "    cols .extend (selected_cols )\n",
    "    return df [cols ]\n",
    "search_method_dropdown =widgets .Dropdown (\n",
    "options =[\n",
    "(\"TransferpointID\",\"transferpoint\"),\n",
    "(\"ObjectID\",\"objectid\"),\n",
    "(\"RegisterID\",\"registerid\"),\n",
    "(\"RegistratorID\",\"registratorid\")\n",
    "],\n",
    "value =\"transferpoint\",\n",
    "description =\"Filter:\"\n",
    ")\n",
    "search_method_dropdown .layout =widgets .Layout (width ='240px',height ='35px')\n",
    "\n",
    "def fetch_typeids_for_ean (ean_value :str )->Set [int ]:\n",
    "    search_method =search_method_dropdown .value\n",
    "    try :\n",
    "        if search_method ==\"transferpoint\":\n",
    "            query =\"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                JOIN TBL_ConnectionPoint cp ON cp.ID = r.ConnectionPointId\n",
    "                WHERE cp.EAN_ConnectionPoint = ?\n",
    "                      OR cp.TransferPointID IN (\n",
    "                          SELECT ID FROM TBL_ConnectionPoint WHERE EAN_ConnectionPoint = ?\n",
    "                      )\n",
    "            \"\"\"\n",
    "            with engine .connect ()as conn :\n",
    "                df_temp =pd .read_sql_query (query ,conn ,params =(ean_value ,ean_value ))\n",
    "        elif search_method ==\"objectid\":\n",
    "            query =\"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                JOIN TBL_ConnectionPoint cp ON cp.ID = r.ConnectionPointId\n",
    "                WHERE cp.ObjectId = (\n",
    "                    SELECT TOP 1 cp2.ObjectId\n",
    "                    FROM TBL_ConnectionPoint cp2\n",
    "                    WHERE cp2.EAN_ConnectionPoint = ?\n",
    "                )\n",
    "            \"\"\"\n",
    "            with engine .connect ()as conn :\n",
    "                df_temp =pd .read_sql_query (query ,conn ,params =(ean_value ,))\n",
    "        elif search_method ==\"registerid\":\n",
    "            query =\"\"\"\n",
    "                SELECT DISTINCT TypeId\n",
    "                FROM TBL_Register\n",
    "                WHERE ID = ?\n",
    "            \"\"\"\n",
    "            try :\n",
    "                register_id =int (ean_value )\n",
    "            except ValueError :\n",
    "                return set ()\n",
    "            with engine .connect ()as conn :\n",
    "                df_temp =pd .read_sql_query (query ,conn ,params =(register_id ,))\n",
    "        elif search_method ==\"registratorid\":\n",
    "            query =\"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                WHERE r.RegistratorID = ?\n",
    "            \"\"\"\n",
    "            try :\n",
    "                registrator_id =int (ean_value )\n",
    "            except ValueError :\n",
    "                return set ()\n",
    "            with engine .connect ()as conn :\n",
    "                df_temp =pd .read_sql_query (query ,conn ,params =(registrator_id ,))\n",
    "        else :\n",
    "            return set ()\n",
    "\n",
    "        if df_temp .empty :\n",
    "            return set ()\n",
    "        return set (df_temp ['TypeId'].unique ())\n",
    "\n",
    "    except Exception as e :\n",
    "        logger .error (f\"Error fetching TypeIDs: {e}\")\n",
    "        return set ()\n",
    "\n",
    "def fetch_min_max_period (ean_value :str ,\n",
    "allowed_typeids_str :str ,\n",
    "start_date :datetime ,\n",
    "end_date :datetime\n",
    ")->Tuple [Optional [datetime ],Optional [datetime ]]:\n",
    "    search_method =search_method_dropdown .value\n",
    "    cache_key =(ean_value ,allowed_typeids_str ,start_date ,end_date ,'minmax',search_method )\n",
    "    cached =min_max_cache .get (cache_key )\n",
    "    if cached is not None :\n",
    "        logger .info (\"Min/Max periode uit cache gehaald.\")\n",
    "        return cached\n",
    "\n",
    "    start_date_str =start_date .strftime ('%d/%m/%Y %H:%M')\n",
    "    end_date_str =end_date .strftime ('%d/%m/%Y %H:%M')\n",
    "    sp_query =\"\"\"\n",
    "        EXEC [dbo].[usp_GetMinMaxPeriodForEAN]\n",
    "             @EAN_ConnectionPoint = ?,\n",
    "             @AllowedTypeIDs = ?,\n",
    "             @StartDateStr = ?,\n",
    "             @EndDateStr = ?,\n",
    "             @SearchMethod = ?\n",
    "    \"\"\"\n",
    "    try :\n",
    "        with engine .connect ()as conn :\n",
    "            df_temp =pd .read_sql_query (\n",
    "            sp_query ,conn ,\n",
    "            params =(ean_value ,allowed_typeids_str ,start_date_str ,end_date_str ,search_method )\n",
    "            )\n",
    "        if df_temp .empty or pd .isnull (df_temp ['MinUTCPeriod'].iloc [0 ]):\n",
    "            result =(None ,None )\n",
    "        else :\n",
    "            result =(df_temp ['MinUTCPeriod'].iloc [0 ],df_temp ['MaxUTCPeriod'].iloc [0 ])\n",
    "\n",
    "        min_max_cache .set (cache_key ,result )\n",
    "        logger .info (\"Min/Max periode in cache gezet.\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e :\n",
    "        logger .error (f\"Error fetching min/max period: {e}\")\n",
    "        return (None ,None )\n",
    "\n",
    "def fetch_full_data (ean_value :str ,\n",
    "allowed_typeids_str :str ,\n",
    "start_date :datetime ,\n",
    "end_date :datetime ,\n",
    "interval_minutes :int =5 ,\n",
    "include_status :bool =False\n",
    ")->Optional [pd .DataFrame ]:\n",
    "    search_method =search_method_dropdown .value\n",
    "    cache_key =(ean_value ,allowed_typeids_str ,start_date ,end_date ,\n",
    "    'pivot',search_method ,interval_minutes ,include_status )\n",
    "    cached =full_data_cache .get (cache_key )\n",
    "    if cached is not None :\n",
    "        logger .info (\"Volledige data uit cache gehaald.\")\n",
    "        return cached\n",
    "\n",
    "    start_date_str =start_date .strftime ('%d/%m/%Y %H:%M')\n",
    "    end_date_str =end_date .strftime ('%d/%m/%Y %H:%M')\n",
    "    sp_query =\"\"\"\n",
    "        EXEC [dbo].[usp_GetConnectionDataFull]\n",
    "             @EAN_ConnectionPoint = ?,\n",
    "             @AllowedTypeIDs      = ?,\n",
    "             @StartDateStr        = ?,\n",
    "             @EndDateStr          = ?,\n",
    "             @SearchMethod        = ?,\n",
    "             @IntervalMinutes     = ?,\n",
    "             @IncludeStatus       = ?\n",
    "    \"\"\"\n",
    "    try :\n",
    "        with engine .connect ()as conn :\n",
    "            df =pd .read_sql_query (\n",
    "            sp_query ,conn ,\n",
    "            params =(\n",
    "            ean_value ,\n",
    "            allowed_typeids_str ,\n",
    "            start_date_str ,\n",
    "            end_date_str ,\n",
    "            search_method ,\n",
    "            interval_minutes ,\n",
    "            int (include_status )\n",
    "            ),\n",
    "            parse_dates =['utcperiod']\n",
    "            )\n",
    "        if df .empty :\n",
    "            result =None\n",
    "        else :\n",
    "            result =df\n",
    "\n",
    "        full_data_cache .set (cache_key ,result )\n",
    "        logger .info (\"Volledige data in cache gezet.\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e :\n",
    "        logger .error (f\"Error fetching full data: {e}\")\n",
    "        return None\n",
    "def distribute_consumption_across_intervals (df :pd .DataFrame ,freq :str )->pd .DataFrame :\n",
    "    if df .empty :\n",
    "        return df\n",
    "    numeric_df =df .select_dtypes (include =[np .number ])\n",
    "    non_numeric_df =df .select_dtypes (exclude =[np .number ])\n",
    "\n",
    "    numeric_df =numeric_df .groupby (numeric_df .index ).sum ()\n",
    "    cumsum_numeric =numeric_df .cumsum ()\n",
    "\n",
    "    new_index =pd .date_range (start =df .index .min (),end =df .index .max (),freq =freq )\n",
    "    cumsum_numeric =cumsum_numeric .reindex (new_index ).interpolate (method ='linear')\n",
    "    distributed_numeric =cumsum_numeric .diff ()\n",
    "    if not distributed_numeric .empty :\n",
    "        distributed_numeric .iloc [0 ]=cumsum_numeric .iloc [0 ]\n",
    "    distributed_numeric =distributed_numeric .fillna (0 )\n",
    "\n",
    "    if non_numeric_df .empty :\n",
    "        result =distributed_numeric\n",
    "    else :\n",
    "        non_numeric_df =non_numeric_df .groupby (non_numeric_df .index ).first ()\n",
    "        non_numeric_df =non_numeric_df .reindex (new_index ,method ='ffill')\n",
    "        result =pd .concat ([non_numeric_df ,distributed_numeric ],axis =1 )\n",
    "    return result\n",
    "def build_dataset (ean_val :str ,\n",
    "chosen_groups :List [str ],\n",
    "start_date :datetime ,\n",
    "end_date :datetime ,\n",
    "freq_val :str ,\n",
    "aggregate :bool ,\n",
    "include_status_flag :bool =False\n",
    ")->Optional [pd .DataFrame ]:\n",
    "    typeids_final =[]\n",
    "    for grp in chosen_groups :\n",
    "        typeids_final .extend (group_typeid_mapping .get (grp ,[]))\n",
    "\n",
    "    if not typeids_final :\n",
    "        logger .warning (\"Geen TypeIDs in chosen_groups.\")\n",
    "        return None\n",
    "\n",
    "    allowed_typeids_str =\",\".join (str (tid )for tid in set (typeids_final ))\n",
    "\n",
    "\n",
    "    minp ,maxp =fetch_min_max_period (ean_val ,allowed_typeids_str ,start_date ,end_date )\n",
    "    if not minp or not maxp :\n",
    "        logger .info (\"Geen data (minp, maxp is None).\")\n",
    "        return None\n",
    "\n",
    "    if freq_val in FREQ_TO_MINUTES :\n",
    "        interval_minutes =FREQ_TO_MINUTES [freq_val ]\n",
    "    else : # Default for 'auto' or unknown, though 'auto' is resolved before this point typically\n",
    "        logger.warning(f\"Frequency value '{freq_val}' not found in FREQ_TO_MINUTES. Defaulting to 5 minutes for interval_minutes.\")\n",
    "        interval_minutes =5\n",
    "\n",
    "\n",
    "    sp_include_status =(not aggregate )and include_status_flag\n",
    "    df_full =fetch_full_data (\n",
    "    ean_val ,\n",
    "    allowed_typeids_str ,\n",
    "    start_date , # Using original start_date for fetching, SP might handle wider range\n",
    "    end_date ,   # Using original end_date for fetching\n",
    "    interval_minutes =interval_minutes ,\n",
    "    include_status =sp_include_status\n",
    "    )\n",
    "    if df_full is None or df_full .empty :\n",
    "        logger .info (\"Lege dataset (df_full).\")\n",
    "        return None\n",
    "\n",
    "    # Ensure start_date and end_date are timezone-aware (UTC, as 'utcperiod' implies) or compatible for comparison\n",
    "    # The df_full['utcperiod'] is parsed by read_sql_query, typically naive.\n",
    "    # It's better if build_dataset receives localized start/end dates or localizes them here.\n",
    "    # For now, assuming they are comparable or SP handles localization.\n",
    "    # If start_date/end_date from input are naive, they should be localized like in DateAdjustmentUtils.\n",
    "    # However, current problem scope is adjust_dates_on_freq_change. This part is pre-existing.\n",
    "\n",
    "    df_f =df_full [\n",
    "    (df_full ['utcperiod']>=start_date )& # This comparison might be tricky if one is aware and other naive.\n",
    "    (df_full ['utcperiod']<=end_date )\n",
    "    ].copy ()\n",
    "\n",
    "    if df_f .empty :\n",
    "        logger .info (\"Geen rijen binnen periode.\")\n",
    "        return None\n",
    "\n",
    "    df_f .set_index ('utcperiod',inplace =True )\n",
    "\n",
    "    # freq_val_lower is used here, but freq_val is passed to distribute_consumption_across_intervals\n",
    "    # Pandas freq strings are case-sensitive. Usually uppercase.\n",
    "    # The freq_selector values are uppercase (5T, H, D, W, ME, Y) or 'auto'.\n",
    "    # So freq_val should be used directly unless specific lowercasing is needed.\n",
    "\n",
    "    if freq_val .lower ()=='auto': # freq_val.lower() usage\n",
    "        periods =df_f .index .sort_values ()\n",
    "        if len (periods )>1 :\n",
    "            diffs =periods .to_series ().diff ().dropna ().dt .total_seconds ().astype (int )\n",
    "            mode_diff =diffs .mode ()[0 ] if not diffs.empty else FREQ_TO_SECONDS.get('H', 3600) # handle empty diffs\n",
    "            freq_found =None\n",
    "            for key ,sec in FREQ_TO_SECONDS .items ():\n",
    "\n",
    "                if abs (sec -mode_diff )<10 : # Allow small tolerance\n",
    "                    freq_found =key\n",
    "                    break\n",
    "            if freq_found is None : # Fallback if no close match\n",
    "                freq_found ='H' # Default to Hourly\n",
    "            freq_val =freq_found # Update freq_val to the detected one\n",
    "            logger .info (f\"Automatisch gedetecteerde frequentie: {freq_val}\")\n",
    "        else :\n",
    "            freq_val ='H' # Fallback if only one data point\n",
    "            logger .info (\"Niet genoeg data om frequentie te detecteren; gebruik 'H' als fallback.\")\n",
    "    \n",
    "    # Ensure freq_val is valid for distribute_consumption_across_intervals\n",
    "    # which passes it to pd.date_range(freq=freq_val)\n",
    "    if freq_val not in FREQ_TO_SECONDS and freq_val != 'auto': # 'auto' is resolved above\n",
    "        logger.error(f\"Ongeldige frequentie '{freq_val}' voor resampling. Check FREQ_TO_SECONDS/MINUTES.\")\n",
    "        # Potentially return None or use a default frequency\n",
    "        return None\n",
    "\n",
    "\n",
    "    if aggregate :\n",
    "        df_reset =df_f .reset_index ()\n",
    "        selected_mapping ={grp :group_typeid_mapping [grp ]for grp in chosen_groups if grp in group_typeid_mapping }\n",
    "        df_grouped =group_columns_by_typeid (df_reset ,engine ,selected_mapping )\n",
    "        df_grouped .set_index ('utcperiod',inplace =True )\n",
    "        df_interest =df_grouped\n",
    "    else :\n",
    "        selected_mapping ={grp :group_typeid_mapping [grp ]for grp in chosen_groups if grp in group_typeid_mapping }\n",
    "        df_interest =filter_columns_by_selected_groups (df_f ,engine ,selected_mapping )\n",
    "\n",
    "    if df_interest .empty :\n",
    "        logger.info(\"DataFrame is leeg na filteren/groeperen (df_interest).\")\n",
    "        return None\n",
    "\n",
    "    # df_interest index should be DatetimeIndex for distribute_consumption_across_intervals\n",
    "    if not isinstance(df_interest.index, pd.DatetimeIndex):\n",
    "        logger.warning(\"df_interest index is not a DatetimeIndex. Attempting conversion.\")\n",
    "        try:\n",
    "            df_interest.index = pd.to_datetime(df_interest.index)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Kon df_interest.index niet converteren naar DatetimeIndex: {e}\")\n",
    "            return None\n",
    "            \n",
    "    if df_interest.index.min() is pd.NaT or df_interest.index.max() is pd.NaT:\n",
    "        logger.warning(\"df_interest index contains NaT values or is empty after conversion. Cannot proceed with resampling.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    distributed_df =distribute_consumption_across_intervals (df_interest ,freq_val ) # freq_val should be Pandas compatible\n",
    "    distributed_df =distributed_df .reset_index ()\n",
    "\n",
    "    if 'index'in distributed_df .columns :\n",
    "        distributed_df .rename (columns ={'index':'UTC Period'},inplace =True )\n",
    "    elif 'utcperiod'in distributed_df .columns : # Should be 'index' from reset_index\n",
    "        distributed_df .rename (columns ={'utcperiod':'UTC Period'},inplace =True )\n",
    "\n",
    "\n",
    "    cols =distributed_df .columns .tolist ()\n",
    "    if 'UTC Period'in cols :\n",
    "        cols .insert (0 ,cols .pop (cols .index ('UTC Period')))\n",
    "    distributed_df =distributed_df [cols ]\n",
    "\n",
    "    final_cols =[]\n",
    "    col_list =distributed_df .columns .tolist ()\n",
    "    if 'UTC Period'in col_list :\n",
    "        final_cols .append ('UTC Period')\n",
    "    consumption_cols =[c for c in col_list if c not in final_cols and '(consumption)'in c .lower ()]\n",
    "    for ccol in consumption_cols :\n",
    "        final_cols .append (ccol )\n",
    "        status_candidate =ccol .replace ('(consumption)','(status)')\n",
    "        if status_candidate in col_list :\n",
    "            final_cols .append (status_candidate )\n",
    "    leftover_cols =[c for c in col_list if c not in final_cols ]\n",
    "    final_cols .extend (leftover_cols )\n",
    "    distributed_df =distributed_df [final_cols ]\n",
    "    return distributed_df\n",
    "\n",
    "def export_dataset_to_csv (df :pd .DataFrame ,filename :str )->bool :\n",
    "    if df is None or df .empty :\n",
    "        logger .warning (\"Kan niet exporteren: lege DataFrame.\")\n",
    "        return False\n",
    "    df_export =df .copy ()\n",
    "    if \"UTC Period\"in df_export .columns :\n",
    "        df_export [\"UTC Period\"]=pd .to_datetime (df_export [\"UTC Period\"],errors ='coerce').dt .strftime ('%Y-%m-%d %H:%M:%S')\n",
    "    df_export .to_csv (filename ,index =False )\n",
    "    logger .info (f\"CSV geëxporteerd: {filename}\")\n",
    "    return True\n",
    "\n",
    "# Modified function signature for export_dataset_to_excel\n",
    "def export_dataset_to_excel (df :pd .DataFrame ,filename :str, excel_format: bool, include_status: bool )->bool :\n",
    "    if df is None or df .empty :\n",
    "        logger .warning (\"Kan niet exporteren: lege DataFrame.\")\n",
    "        return False\n",
    "    try :\n",
    "        # Import necessary for xl_col_to_name if not globally available\n",
    "        from xlsxwriter.utility import xl_col_to_name\n",
    "\n",
    "        with pd .ExcelWriter (filename ,engine ='xlsxwriter',datetime_format ='yyyy-mm-dd hh:mm:ss')as writer :\n",
    "\n",
    "            df .to_excel (writer ,index =False ,sheet_name ='Dataset')\n",
    "\n",
    "            workbook =writer .book\n",
    "            worksheet =writer .sheets ['Dataset']\n",
    "\n",
    "            header_format =workbook .add_format ({\n",
    "            'bold':True ,\n",
    "            'text_wrap':True ,\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'fg_color':'#F2F2F2',\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "            data_format =workbook .add_format ({\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "\n",
    "            df_columns =df .columns .tolist ()\n",
    "            num_rows =len (df )\n",
    "            for col_num ,value in enumerate (df_columns ):\n",
    "                worksheet .write (0 ,col_num ,value ,header_format )\n",
    "                col_header =str (value ).lower ()\n",
    "                if col_header =='utc period':\n",
    "                    col_width =25\n",
    "                elif 'consumption'in col_header :\n",
    "                    col_width =15\n",
    "                elif 'status'in col_header :\n",
    "                    col_width =10\n",
    "                else :\n",
    "                    col_width =max (15 ,len (str (value ))+2 )\n",
    "                worksheet .set_column (col_num ,col_num ,col_width ,data_format )\n",
    "\n",
    "            worksheet .set_row (0 ,42 )\n",
    "            worksheet .freeze_panes (1 ,1 )\n",
    "\n",
    "            if \"UTC Period\"in df_columns :\n",
    "                col_index =df_columns .index (\"UTC Period\")\n",
    "                worksheet .set_column (col_index ,col_index ,25 ,workbook .add_format ({\n",
    "                'num_format':'yyyy-mm-dd hh:mm:ss',\n",
    "                'align':'center',\n",
    "                'valign':'middle',\n",
    "                'font_name':'Arial',\n",
    "                'font_size':10\n",
    "                }))\n",
    "\n",
    "            status_p_format =workbook .add_format ({\n",
    "            'bg_color':'#FFFFAF', # Pale Yellow\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "            status_t_format =workbook .add_format ({\n",
    "            'bg_color':'#FFDB69', # Light Orange/Gold\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "            status_empty_format =workbook .add_format ({ # For empty status cells, if needed for consumption\n",
    "            'bg_color':'#CCFFCC', # Light Green\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "\n",
    "            if excel_format : # Uses the parameter passed to the function\n",
    "\n",
    "                for col_num ,col_name in enumerate (df_columns ):\n",
    "                    if 'consumption'in str (col_name ).lower ():\n",
    "                        if include_status : # Uses the parameter passed to the function\n",
    "                            status_col_name =col_name .replace ('(consumption)','(status)')\n",
    "                            if status_col_name in df_columns :\n",
    "                                status_col_index =df_columns .index (status_col_name )\n",
    "                                status_letter =xl_col_to_name (status_col_index ) # xl_col_to_name needs import\n",
    "                                # Excel formulas are 1-indexed for rows\n",
    "                                worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                                'type':'formula',\n",
    "                                'criteria':f'=${status_letter}2=\"P\"', # Check from row 2 downwards\n",
    "                                'format':status_p_format ,\n",
    "                                'stop_if_true':True\n",
    "                                })\n",
    "                                worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                                'type':'formula',\n",
    "                                'criteria':f'=${status_letter}2=\"T\"',\n",
    "                                'format':status_t_format ,\n",
    "                                'stop_if_true':True\n",
    "                                })\n",
    "                                worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                                'type':'formula',\n",
    "                                'criteria':f'=${status_letter}2=\"\"', # Or ISBLANK(${status_letter}2)\n",
    "                                'format':status_empty_format , # Assuming you want to format consumption where status is blank\n",
    "                                'stop_if_true':True\n",
    "                                })\n",
    "                        else : # If not include_status, apply a generic format to consumption\n",
    "                            worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                            'type':'3_color_scale', # Example: a color scale\n",
    "                            'min_color':\"#FFFFFF\", # White\n",
    "                            'mid_color':\"#FFFFCC\", # Pale yellow\n",
    "                            'max_color':\"#FFCCCC\"  # Light red\n",
    "                            })\n",
    "\n",
    "                # Formatting for status columns themselves\n",
    "                for col_num ,col_name in enumerate (df_columns ):\n",
    "                    if 'status'in str (col_name ).lower ():\n",
    "                        worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                        'type':'cell',\n",
    "                        'criteria':'==',\n",
    "                        'value':'\"P\"',\n",
    "                        'format':status_p_format\n",
    "                        }) # Removed stop_if_true as it's the final rule for \"P\"\n",
    "                        worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                        'type':'cell',\n",
    "                        'criteria':'==',\n",
    "                        'value':'\"T\"',\n",
    "                        'format':status_t_format\n",
    "                        }) # Removed stop_if_true\n",
    "                        worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                        'type':'cell',\n",
    "                        'criteria':'==',\n",
    "                        'value':'\"\"', # Or 'criteria':'blanks'\n",
    "                        'format':status_empty_format # Format for blank status cells\n",
    "                        }) # Removed stop_if_true\n",
    "\n",
    "\n",
    "        logger .info (f\"Excel bestand opgeslagen: {filename}\")\n",
    "        return True\n",
    "    except Exception as e :\n",
    "        logger .error (f\"Error exporting to Excel: {e}\")\n",
    "        return False\n",
    "common_layout =widgets .Layout (width ='240px',height ='35px')\n",
    "start_datetime_input =widgets .Text (\n",
    "value ='01/01/2024 00:00',\n",
    "placeholder ='dd/mm/yyyy HH:MM',\n",
    "description ='StartDatum:',\n",
    "layout =common_layout\n",
    ")\n",
    "end_datetime_input =widgets .Text (\n",
    "value ='31/12/2024 00:00',\n",
    "placeholder ='dd/mm/yyyy HH:MM',\n",
    "description ='EindDatum:',\n",
    "layout =common_layout\n",
    ")\n",
    "freq_selector =widgets .Dropdown (\n",
    "options =[('Automatisch (standaard)','auto'),\n",
    "('Elke 5 minuten','5T'),('Elke 15 minuten','15T'),\n",
    "('Per uur','H'),('Dagelijks','D'),\n",
    "('Wekelijks','W'),\n",
    "('Maandelijks','ME'), # MODIFIED: 'M' to 'ME' for consistency with table and FREQ_TO_SECONDS\n",
    "('Jaarlijks','Y')],\n",
    "value ='auto',\n",
    "description ='Frequentie:',\n",
    "layout =common_layout\n",
    ")\n",
    "aggregate_checkbox =widgets .Checkbox (\n",
    "value =True ,\n",
    "description ='Geaggregeerd?',\n",
    "layout =widgets .Layout (margin ='2px 0 2px 0')\n",
    ")\n",
    "status_checkbox =widgets .Checkbox (\n",
    "value =False ,\n",
    "description ='Include Status? (en pas kleur op consumption aan)',\n",
    "disabled =True ,\n",
    "layout =widgets .Layout (margin ='2px 0 2px 0')\n",
    ")\n",
    "\n",
    "excel_format_checkbox =widgets .Checkbox (\n",
    "value =False , # Default to False, user can enable it\n",
    "description ='Voorwaardelijke opmaak Excel?',\n",
    "layout =widgets .Layout (margin ='2px 0 2px 0')\n",
    ")\n",
    "\n",
    "def on_aggregate_change (change ):\n",
    "\n",
    "    status_checkbox .disabled =change ['new']\n",
    "aggregate_checkbox .observe (on_aggregate_change ,names ='value')\n",
    "\n",
    "status_checkbox .disabled =aggregate_checkbox .value\n",
    "\n",
    "warning_message =widgets .HTML (\"\")\n",
    "warning_container =widgets .VBox ([]) # Initially empty\n",
    "quick_fix_freq_button =widgets .Button (\n",
    "description =\"Wijzig freq naar 1 uur\",\n",
    "button_style =\"warning\", # 'warning' is yellow\n",
    "icon =\"clock-o\",\n",
    "layout =common_layout\n",
    ")\n",
    "quick_fix_date_button =widgets .Button (\n",
    "description =\"Beperk datumbereik\",\n",
    "button_style =\"warning\",\n",
    "icon =\"calendar\",\n",
    "layout =common_layout\n",
    ")\n",
    "\n",
    "progress_bar =widgets .IntProgress (value =0 ,min =0 ,max =100 ,step =1 ,description ='Dataset:',bar_style ='info') # Options: 'success', 'info', 'warning', 'danger' or ''\n",
    "progress_bar .layout =widgets .Layout (width ='220px',height ='30px')\n",
    "status_label =widgets .Label (value =\"\",layout =widgets .Layout (width =\"auto\",margin =\"0 0 0 10px\")) # Auto width, margin for spacing\n",
    "progress_container =widgets .HBox ([progress_bar ,status_label ])\n",
    "progress_container .layout .visibility ='hidden' # Start hidden\n",
    "\n",
    "output_area =widgets .Output (layout ={'border':'1px solid black'})\n",
    "data_table_output =widgets .Output (layout ={\n",
    "'border':'1px solid #ccc', # Lighter border\n",
    "'overflow_x':'auto',\n",
    "'overflow_y':'auto',\n",
    "'max_height':'400px', # Limit height\n",
    "'width':'100%' # Take full available width\n",
    "})\n",
    "insights_output =widgets .Output (layout ={\n",
    "'border':'1px solid #ccc',\n",
    "'overflow_x':'auto',\n",
    "'overflow_y':'auto',\n",
    "'max_height':'400px',\n",
    "'width':'100%'\n",
    "})\n",
    "view_tab =widgets .Tab (children =[data_table_output ,insights_output ])\n",
    "view_tab .set_title (0 ,\"Dataset\")\n",
    "view_tab .set_title (1 ,\"Inzichten\")\n",
    "\n",
    "btn_load_filters =widgets .Button (description ='Zoeken',button_style ='info',icon ='filter',layout =common_layout )\n",
    "btn_build_dataset =widgets .Button (description ='Laad Dataset',button_style ='success',icon ='database',disabled =True ,layout =common_layout )\n",
    "btn_view_dataset =widgets .Button (description =\"Bekijk Dataset\",button_style ='primary',icon ='eye',disabled =True ,layout =common_layout )\n",
    "btn_view_insights =widgets .Button (description =\"Bekijk Inzichten\",button_style ='primary',icon ='info',disabled =True ,layout =common_layout )\n",
    "btn_download_csv =widgets .Button (description =\"Download CSV\",button_style ='primary',icon ='download',disabled =True ,layout =common_layout )\n",
    "btn_download_excel =widgets .Button (description =\"Download XLS\",button_style ='primary',icon ='file-excel-o',disabled =True ,layout =common_layout )\n",
    "btn_reset_filters =widgets .Button (description ='Reset Filters',button_style ='warning',icon ='refresh',layout =common_layout )\n",
    "\n",
    "ean_input = widgets.Text(\n",
    "    description='EAN:',\n",
    "    placeholder='Vul ID/EAN in',\n",
    "    value='', # Default empty or provide a test EAN\n",
    "    layout=common_layout\n",
    ")\n",
    "\n",
    "options_container =widgets .VBox ([aggregate_checkbox ,status_checkbox ,excel_format_checkbox ])\n",
    "options_accordion =widgets .Accordion (children =[options_container ])\n",
    "options_accordion .set_title (0 ,\"Opties\")\n",
    "options_accordion .selected_index =None # Collapsed by default\n",
    "\n",
    "group_checkbox_container =widgets .VBox ([]) # Checkboxes will be added here dynamically\n",
    "group_accordion =widgets .Accordion (children =[group_checkbox_container ])\n",
    "group_accordion .set_title (0 ,\"Beschikbare groepen\")\n",
    "group_accordion .selected_index =None # Collapsed by default\n",
    "\n",
    "row_top =widgets .HBox (\n",
    "[ean_input ,search_method_dropdown ,btn_load_filters ,btn_reset_filters ],\n",
    "layout =widgets .Layout (gap =\"5px\",flex_flow ='row wrap') # Added gap and wrap\n",
    ")\n",
    "row_dates =widgets .HBox ([start_datetime_input ,end_datetime_input ,freq_selector ],\n",
    "layout =widgets .Layout (gap =\"10px\",flex_flow ='row wrap')) # Added gap and wrap\n",
    "\n",
    "action_buttons_row =widgets .HBox (\n",
    "[btn_build_dataset ,btn_view_dataset ,btn_view_insights ,btn_download_csv ,btn_download_excel ],\n",
    "layout =widgets .Layout (justify_content ='flex-start',flex_flow ='row wrap') # Wrap buttons\n",
    ")\n",
    "\n",
    "toggle_filters_button =widgets .Button (\n",
    "description =\"Verberg filters\", # Initial text\n",
    "icon ='chevron-up', # Initial icon\n",
    "button_style ='info',\n",
    "layout =widgets .Layout (width ='150px',height ='35px')\n",
    ")\n",
    "\n",
    "filters_container =widgets .VBox ([\n",
    "widgets .HTML (\"<h3>Filters</h3>\"), # Title for the filter section\n",
    "row_top ,\n",
    "row_dates ,\n",
    "warning_container , # For displaying validation messages\n",
    "options_accordion ,\n",
    "group_accordion ,\n",
    "action_buttons_row ,\n",
    "progress_container , # Progress bar and status\n",
    "output_area , # For general messages / logs\n",
    "view_tab # Tabs for dataset and insights\n",
    "],layout =widgets .Layout (display ='block',border ='1px solid #ccc',padding ='5px')) # Initial display state and styling\n",
    "\n",
    "final_ui =widgets .VBox ([\n",
    "toggle_filters_button ,\n",
    "filters_container\n",
    "])\n",
    "display (final_ui )\n",
    "\n",
    "current_df =None # Stores the latest generated DataFrame\n",
    "progress_start_time =None\n",
    "progress_running =False\n",
    "current_progress =0\n",
    "current_status =\"\"\n",
    "\n",
    "def progress_timer ():\n",
    "    global progress_running ,progress_start_time ,current_progress ,current_status\n",
    "    while progress_running :\n",
    "        if current_progress >0 and progress_start_time is not None: # Check progress_start_time\n",
    "            elapsed =time .time ()-progress_start_time\n",
    "            if current_progress >0 and current_progress < 100 : # Avoid division by zero or stale estimates\n",
    "                fraction_done =current_progress /100\n",
    "                if fraction_done >0 : # Should always be true here\n",
    "                    estimated_total =elapsed /fraction_done\n",
    "                    remaining =max (0 ,estimated_total -elapsed )\n",
    "                    status_label .value =f\"{current_status} - {current_progress}% - Resterende tijd: {int(remaining)} sec\"\n",
    "        time .sleep (1 ) # Update every second\n",
    "\n",
    "def update_progress (progress ,status =\"\",error =False ):\n",
    "    global progress_start_time ,progress_running ,current_progress ,current_status\n",
    "    if not progress_running and progress > 0 and progress < 100: # Start of a new task\n",
    "        progress_start_time =time .time ()\n",
    "        progress_running =True\n",
    "        progress_bar.value = 0 # Reset progress bar for new task\n",
    "        if not hasattr (update_progress ,'timer_thread')or not update_progress .timer_thread .is_alive ():\n",
    "            update_progress .timer_thread =threading .Thread (target =progress_timer ,daemon =True )\n",
    "            update_progress .timer_thread .start ()\n",
    "        progress_bar .bar_style =\"info\"\n",
    "        progress_container .layout .visibility ='visible'\n",
    "    \n",
    "    current_progress =progress\n",
    "    current_status =status\n",
    "    progress_bar .value =progress\n",
    "    status_label .value =f\"{status} - {progress}%\"\n",
    "\n",
    "    if error :\n",
    "        progress_bar .bar_style =\"danger\"\n",
    "        progress_running = False # Stop timer on error\n",
    "    elif progress >=100 :\n",
    "        progress_bar .bar_style =\"success\"\n",
    "        status_label.value = f\"{status} - {progress}% - Voltooid!\"\n",
    "        # progress_running = False # Timer will stop naturally or can be stopped in finish_progress\n",
    "    else :\n",
    "        progress_bar .bar_style =\"info\"\n",
    "\n",
    "def finish_progress ():\n",
    "    global progress_running ,current_progress ,current_status, progress_start_time\n",
    "    # Give a brief moment for the 100% status to be visible\n",
    "    if current_progress >= 100 and not progress_bar.bar_style == 'danger':\n",
    "        time.sleep(2) # Show success message briefly\n",
    "    \n",
    "    progress_running =False\n",
    "    progress_container .layout .visibility ='hidden'\n",
    "    progress_bar .value =0\n",
    "    status_label .value =\"\"\n",
    "    current_progress =0\n",
    "    current_status =\"\"\n",
    "    progress_start_time = None\n",
    "\n",
    "\n",
    "# --- New Function: adjust_dates_on_freq_change ---\n",
    "def adjust_dates_on_freq_change(change): # ipywidgets observe passes a change dictionary\n",
    "    freq_value = change['new'] if isinstance(change, dict) else change # Accommodate direct call if needed\n",
    "\n",
    "    if freq_value == 'auto':\n",
    "        # Laat beide waarden ongemoeid.\n",
    "        return\n",
    "\n",
    "    start_dt_str = start_datetime_input.value\n",
    "    end_dt_str = end_datetime_input.value\n",
    "\n",
    "    start_dt_parsed = parse_user_datetime(start_dt_str)\n",
    "    end_dt_parsed = parse_user_datetime(end_dt_str)\n",
    "\n",
    "    # It's crucial that parse_user_datetime returns naive datetimes\n",
    "    if start_dt_parsed is None:\n",
    "        logger.warning(f\"Ongeldige startdatum '{start_dt_str}' bij aanpassen frequentie. Formaat moet '%d/%m/%Y %H:%M' zijn.\")\n",
    "        # Optionally clear/flag input, but for now, just log and don't adjust.\n",
    "        return\n",
    "    if end_dt_parsed is None:\n",
    "        logger.warning(f\"Ongeldige einddatum '{end_dt_str}' bij aanpassen frequentie. Formaat moet '%d/%m/%Y %H:%M' zijn.\")\n",
    "        return\n",
    "\n",
    "    # Adjust start date\n",
    "    adjusted_start_dt = DateAdjustmentUtils.round_datetime(start_dt_parsed, freq_value, is_start_date=True)\n",
    "    \n",
    "    # Adjust end date\n",
    "    adjusted_end_dt = DateAdjustmentUtils.round_datetime(end_dt_parsed, freq_value, is_start_date=False)\n",
    "\n",
    "    # Format back to string and update widgets\n",
    "    # The datetime objects returned by round_datetime are timezone-aware (Europe/Amsterdam)\n",
    "    # strftime on a timezone-aware datetime object will format it in that timezone.\n",
    "    if adjusted_start_dt:\n",
    "        start_datetime_input.value = adjusted_start_dt.strftime('%d/%m/%Y %H:%M')\n",
    "    if adjusted_end_dt:\n",
    "        end_datetime_input.value = adjusted_end_dt.strftime('%d/%m/%Y %H:%M')\n",
    "\n",
    "\n",
    "def validate_data_request (change =None ): # change can be None if called directly\n",
    "    start_dt =parse_user_datetime (start_datetime_input .value )\n",
    "    end_dt =parse_user_datetime (end_datetime_input .value )\n",
    "    \n",
    "    current_warnings = []\n",
    "\n",
    "    if not start_dt:\n",
    "        current_warnings.append(\"Ongeldige startdatum/tijd (formaat dd/mm/yyyy HH:MM)!\")\n",
    "    if not end_dt:\n",
    "        current_warnings.append(\"Ongeldige einddatum/tijd (formaat dd/mm/yyyy HH:MM)!\")\n",
    "    \n",
    "    if start_dt and end_dt and end_dt < start_dt :\n",
    "        current_warnings.append(\"Einddatum mag niet vóór de startdatum liggen.\")\n",
    "\n",
    "    freq_val =freq_selector .value\n",
    "    if freq_val.lower() != 'auto' and start_dt and end_dt and end_dt >= start_dt:\n",
    "        if freq_val in FREQ_TO_SECONDS :\n",
    "            seconds_per_interval =FREQ_TO_SECONDS [freq_val ]\n",
    "            duration_seconds =(end_dt -start_dt ).total_seconds ()\n",
    "            if duration_seconds <0 : # Should be caught by end_dt < start_dt\n",
    "                duration_seconds =0\n",
    "\n",
    "            # Ensure seconds_per_interval is not zero\n",
    "            if seconds_per_interval > 0:\n",
    "                expected_rows =duration_seconds /seconds_per_interval +1\n",
    "                if expected_rows >MAX_ROWS :\n",
    "                    warning_text = (\n",
    "                        f\"U probeert te veel data op te vragen ({int(expected_rows)} rijen bij freq '{freq_val}'). \"\n",
    "                        \"Verklein het datumbereik of verhoog de resolutie (bijv. naar 'Per uur').\"\n",
    "                    )\n",
    "                    current_warnings.append(warning_text)\n",
    "                    warning_container.children = [\n",
    "                        widgets.HTML(f\"<span style='color:red; font-weight:bold;'>{'; '.join(current_warnings)}</span>\"),\n",
    "                        widgets.HBox([quick_fix_freq_button, quick_fix_date_button], layout=widgets.Layout(justify_content='center'))\n",
    "                    ]\n",
    "                    return # Stop further processing if too many rows\n",
    "            else:\n",
    "                current_warnings.append(f\"Interval voor frequentie '{freq_val}' is nul of ongeldig.\")\n",
    "        else:\n",
    "            current_warnings.append(f\"Frequentie '{freq_val}' niet herkend voor rij-estimatie.\")\n",
    "\n",
    "\n",
    "    if current_warnings:\n",
    "        warning_message.value = f\"<span style='color:red; font-weight:bold;'>{'; '.join(current_warnings)}</span>\"\n",
    "        quick_fix_buttons = []\n",
    "        # Only show quick fix if the specific warning about MAX_ROWS is present\n",
    "        if any(\"te veel data\" in warn_msg for warn_msg in current_warnings):\n",
    "             quick_fix_buttons = [widgets.HBox([quick_fix_freq_button, quick_fix_date_button], layout=widgets.Layout(justify_content='center'))]\n",
    "        warning_container.children = [warning_message] + quick_fix_buttons\n",
    "    else:\n",
    "        warning_message.value = \"\"\n",
    "        warning_container.children = []\n",
    "\n",
    "\n",
    "# --- Combined Callback ---\n",
    "def on_freq_change_and_validate(change):\n",
    "    # `change` is a dictionary like {'name': 'value', 'old': 'auto', 'new': '5T', 'owner': Dropdown(...), 'type': 'change'}\n",
    "    adjust_dates_on_freq_change(change) # Pass the whole change object which contains 'new' value\n",
    "    validate_data_request(change)       # Pass the whole change object\n",
    "\n",
    "\n",
    "start_datetime_input .observe (validate_data_request ,names =\"value\")\n",
    "end_datetime_input .observe (validate_data_request ,names =\"value\")\n",
    "# MODIFIED: Old observer removed, new combined observer added\n",
    "# freq_selector .observe (validate_data_request ,names =\"value\") # OLD\n",
    "freq_selector.observe(on_freq_change_and_validate, names='value') # NEW\n",
    "\n",
    "\n",
    "def quick_fix_freq_action (b ):\n",
    "    freq_selector .value ='H' # This will trigger on_freq_change_and_validate\n",
    "    # validate_data_request () # No longer needed here, will be called by the observer\n",
    "quick_fix_freq_button .on_click (quick_fix_freq_action )\n",
    "\n",
    "def quick_fix_date_action (b ):\n",
    "    start_dt =parse_user_datetime (start_datetime_input .value )\n",
    "    if not start_dt :\n",
    "        return # Or handle error: e.g., set a default start_dt\n",
    "    \n",
    "    freq_val = freq_selector.value\n",
    "    if freq_val == 'auto': # If auto, maybe default to 'H' for this calculation or warn user\n",
    "        logger.info(\"Quick fix date: Freq is 'auto', using 'H' for calculation.\")\n",
    "        freq_val = 'H' \n",
    "\n",
    "    seconds_per_interval =FREQ_TO_SECONDS .get (freq_val ,3600 ) # Default to 1 hour if freq_val is somehow unknown\n",
    "    if seconds_per_interval <= 0: seconds_per_interval = 3600 # Safety net\n",
    "\n",
    "    max_duration = (MAX_ROWS -1) * seconds_per_interval # Max duration for MAX_ROWS items\n",
    "    \n",
    "    # Localize start_dt to ensure timedelta arithmetic is consistent if start_dt was naive\n",
    "    # However, parse_user_datetime returns naive. For consistency with adjust_dates, we'd localize.\n",
    "    # For simplicity here, assuming naive arithmetic is sufficient for timedelta.\n",
    "    new_end_dt = start_dt + timedelta(seconds=max_duration)\n",
    "    \n",
    "    # If original start_dt was localized, new_end_dt would be too.\n",
    "    # Since start_dt is naive, new_end_dt is naive. strftime is fine.\n",
    "    end_datetime_input .value =new_end_dt .strftime ('%d/%m/%Y %H:%M')\n",
    "    # validate_data_request () # No longer needed here, will be called by end_datetime_input observer\n",
    "quick_fix_date_button .on_click (quick_fix_date_action )\n",
    "\n",
    "def toggle_filters_display (b ):\n",
    "    if filters_container .layout .display =='none':\n",
    "        filters_container .layout .display ='block'\n",
    "        toggle_filters_button .description =\"Verberg filters\"\n",
    "        toggle_filters_button .icon =\"chevron-up\"\n",
    "    else :\n",
    "        filters_container .layout .display ='none'\n",
    "        toggle_filters_button .description =\"Toon filters\"\n",
    "        toggle_filters_button .icon =\"chevron-down\"\n",
    "toggle_filters_button .on_click (toggle_filters_display )\n",
    "\n",
    "def load_filters_thread (ean_val :str ):\n",
    "    btn_build_dataset .disabled =True\n",
    "    btn_view_dataset .disabled =True\n",
    "    btn_view_insights .disabled =True\n",
    "    btn_download_csv .disabled =True\n",
    "    btn_download_excel .disabled =True\n",
    "    with output_area :\n",
    "        clear_output ()\n",
    "        print (\"Filters worden geladen...\")\n",
    "\n",
    "    typeids =fetch_typeids_for_ean (ean_val )\n",
    "    if not typeids :\n",
    "        with output_area :\n",
    "            clear_output ()\n",
    "            print (\"Geen TypeIDs gevonden voor deze invoer.\")\n",
    "        group_checkbox_container .children =[]\n",
    "        group_accordion.selected_index = None # Collapse if no groups\n",
    "        return\n",
    "\n",
    "    relevant_groups =[]\n",
    "    for grp ,tlist in group_typeid_mapping .items ():\n",
    "        if set (tlist ).intersection (typeids ):\n",
    "            relevant_groups .append (grp )\n",
    "\n",
    "    if not relevant_groups:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(\"Geen relevante groepen gevonden voor de TypeIDs.\")\n",
    "        group_checkbox_container.children = []\n",
    "        group_accordion.selected_index = None\n",
    "        return\n",
    "        \n",
    "    checkboxes =[]\n",
    "    for grp in sorted (relevant_groups ): # Sort for consistent order\n",
    "        cb =widgets .Checkbox (value =True ,description =grp ,indent =False )\n",
    "        checkboxes .append (cb )\n",
    "    group_checkbox_container .children =checkboxes\n",
    "    group_accordion .selected_index =0 # Expand to show groups\n",
    "\n",
    "    btn_build_dataset .disabled =False\n",
    "    # Other buttons remain disabled until dataset is built\n",
    "\n",
    "    with output_area :\n",
    "        clear_output ()\n",
    "        print (f\"Filters geladen. Beschikbare groepen: {', '.join(sorted(relevant_groups))}\")\n",
    "\n",
    "def on_load_filters_clicked(b):\n",
    "    ean_val = ean_input.value.strip()\n",
    "    if not ean_val:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(\"Vul een EAN of ID in.\")\n",
    "        return\n",
    "    # Use threading to avoid blocking UI, though this function is mostly quick DB calls\n",
    "    threading.Thread(target=load_filters_thread, args=(ean_val,)).start()\n",
    "\n",
    "\n",
    "def on_reset_filters_clicked (b ):\n",
    "    if group_checkbox_container .children :\n",
    "        for cb in group_checkbox_container .children :\n",
    "            cb .value =True\n",
    "    ean_input .value ='871692160011845654' # Example EAN\n",
    "    start_datetime_input .value ='01/01/2024 00:00'\n",
    "    end_datetime_input .value ='31/12/2024 00:00' # Corrected to a valid future or same year date\n",
    "    freq_selector .value ='auto' # This will trigger adjust_dates and validate\n",
    "    aggregate_checkbox .value =True\n",
    "    status_checkbox .value =False\n",
    "    excel_format_checkbox.value = False\n",
    "\n",
    "\n",
    "    status_checkbox .disabled =aggregate_checkbox .value # This is already handled by observe\n",
    "    with output_area :\n",
    "        clear_output ()\n",
    "        print (\"Filters zijn gereset.\")\n",
    "    # Explicitly call validate after reset, as freq might not change if it was already 'auto'\n",
    "    validate_data_request()\n",
    "    # If freq was 'auto', adjust_dates was not called. If it was something else, it was.\n",
    "    # To be sure, one might call adjust_dates manually if needed, or ensure freq change fires it.\n",
    "    # If freq_selector.value was already 'auto', its observer wouldn't fire.\n",
    "    # However, changing start/end dates will trigger their observers for validation.\n",
    "    # The date rounding from freq change is only for non-'auto' frequencies.\n",
    "\n",
    "def get_selected_groups ()->List [str ]:\n",
    "    return [cb .description for cb in group_checkbox_container .children if cb .value ]\n",
    "\n",
    "def build_dataset_thread ():\n",
    "    global current_df\n",
    "    # Disable buttons during build\n",
    "    btn_build_dataset.disabled = True\n",
    "    btn_view_dataset.disabled = True\n",
    "    btn_view_insights.disabled = True\n",
    "    btn_download_csv.disabled = True\n",
    "    btn_download_excel.disabled = True\n",
    "\n",
    "    update_progress (0 ,\"Dataset wordt opgebouwd...\") # Reset and start progress\n",
    "\n",
    "    with output_area : # Clear previous messages from output_area\n",
    "        clear_output (wait=True) # wait=True to avoid flickering if new print comes fast\n",
    "\n",
    "    ean_val =ean_input .value .strip ()\n",
    "    if not ean_val :\n",
    "        with output_area : print (\"Vul een EAN/ID in.\")\n",
    "        update_progress(100, \"Fout: EAN/ID ontbreekt\", error=True)\n",
    "        finish_progress ()\n",
    "        btn_build_dataset.disabled = False # Re-enable build button\n",
    "        return\n",
    "\n",
    "    # Perform validation again before building, using the validation function\n",
    "    validate_data_request() # This will update warning_container\n",
    "    if warning_container.children: # If there are validation warnings\n",
    "        with output_area:\n",
    "             display(HTML(\"<span style='color:red; font-weight:bold;'>Los de validatiefouten op voordat u de dataset bouwt.</span>\"))\n",
    "        update_progress(100, \"Validatiefout\", error=True)\n",
    "        finish_progress()\n",
    "        btn_build_dataset.disabled = False # Re-enable build button\n",
    "        return\n",
    "\n",
    "    start_dt =parse_user_datetime (start_datetime_input .value )\n",
    "    end_dt =parse_user_datetime (end_datetime_input .value )\n",
    "    # These should be valid due to the check above, but defensive check is okay\n",
    "    if not start_dt or not end_dt:\n",
    "        with output_area: print(\"Interne fout: Ongeldige datums ondanks validatie.\")\n",
    "        update_progress(100, \"Fout: Interne datumfout\", error=True)\n",
    "        finish_progress()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "\n",
    "\n",
    "    freq_val =freq_selector .value\n",
    "    agg_val =aggregate_checkbox .value\n",
    "    status_val =status_checkbox .value\n",
    "    chosen =get_selected_groups ()\n",
    "    if not chosen :\n",
    "        with output_area : print (\"Geen groepen geselecteerd.\")\n",
    "        update_progress(100, \"Fout: Geen groepen\", error=True)\n",
    "        finish_progress ()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "\n",
    "    update_progress (30 ,\"TypeIDs en min/max periode ophalen...\")\n",
    "    \n",
    "    # For build_dataset, datetimes should ideally be localized if SP expects specific timezone or for internal consistency\n",
    "    # The current `build_dataset` takes naive datetimes as per `parse_user_datetime`\n",
    "    # This part remains as per original logic unless specified to change.\n",
    "\n",
    "    df_resampled =build_dataset (\n",
    "    ean_val ,\n",
    "    chosen ,\n",
    "    start_dt , # Naive datetime\n",
    "    end_dt ,   # Naive datetime\n",
    "    freq_val ,\n",
    "    agg_val ,\n",
    "    include_status_flag =status_val\n",
    "    )\n",
    "    \n",
    "    update_progress (80 ,\"Dataset verwerken...\")\n",
    "\n",
    "    if df_resampled is None or df_resampled .empty :\n",
    "        update_progress (100 ,\"Geen dataset opgehaald.\",error =True )\n",
    "        with output_area :\n",
    "            print (\"Geen dataset opgehaald. Controleer filters of logs voor details.\")\n",
    "        finish_progress ()\n",
    "        btn_build_dataset.disabled = False # Re-enable build button\n",
    "        return\n",
    "\n",
    "    current_df =df_resampled .copy ()\n",
    "    update_progress (100 ,f\"Dataset geladen met {len(current_df)} rijen.\")\n",
    "\n",
    "    with output_area : # Clear previous messages and show success\n",
    "        clear_output(wait=True)\n",
    "        print (f\"Dataset succesvol geladen met {len(current_df)} rijen.\\nU kunt nu de dataset bekijken, inzichten genereren of downloaden.\")\n",
    "\n",
    "    # Enable action buttons for the loaded dataset\n",
    "    btn_view_dataset .disabled =False\n",
    "    btn_view_insights .disabled =False\n",
    "    btn_download_csv .disabled =False\n",
    "    btn_download_excel .disabled =False\n",
    "    finish_progress ()\n",
    "    btn_build_dataset.disabled = False # Re-enable build button for another run\n",
    "\n",
    "\n",
    "def on_build_dataset_clicked (b ):\n",
    "    # Clear previous views\n",
    "    with data_table_output: clear_output()\n",
    "    with insights_output: clear_output()\n",
    "    threading .Thread (target =build_dataset_thread ).start ()\n",
    "\n",
    "def show_dataset_table ():\n",
    "    with data_table_output :\n",
    "        clear_output (wait =True )\n",
    "        if current_df is None or current_df .empty :\n",
    "            print (\"Nog geen dataset geladen of de dataset is leeg.\")\n",
    "        else :\n",
    "            limit =50 # Show head(50) for performance\n",
    "            html_table =current_df .head (limit ).to_html (classes =\"dataframe\",index =False ,escape=True)\n",
    "            # Info about partial display\n",
    "            info_message = \"\"\n",
    "            if len(current_df) > limit:\n",
    "                info_message = f\"<p><i>Toont de eerste {limit} rijen van {len(current_df)} totale rijen. Download voor de volledige dataset.</i></p>\"\n",
    "            \n",
    "            scrollable_html =f\"\"\"\n",
    "            <div style=\"overflow-x: auto; overflow-y: auto; max-height: 380px; width: 100%;\">\n",
    "                {html_table}\n",
    "            </div>\n",
    "            {info_message}\n",
    "            \"\"\"\n",
    "            display (HTML (scrollable_html ))\n",
    "    view_tab .selected_index =0\n",
    "\n",
    "def show_insights ():\n",
    "    with insights_output :\n",
    "        clear_output (wait =True )\n",
    "        if current_df is None or current_df .empty :\n",
    "            print (\"Nog geen dataset geladen of de dataset is leeg om inzichten te genereren.\")\n",
    "        else :\n",
    "            # Potentially long operation, consider threading or async if generate_insights is slow\n",
    "            insights_html =generate_insights (current_df ) # Assumes current_df is appropriately formatted\n",
    "            display (HTML (f\"<div style='font-family: Roboto, sans-serif; font-size:14px;'>{insights_html}</div>\"))\n",
    "    view_tab .selected_index =1\n",
    "\n",
    "def on_view_dataset_clicked (b ):\n",
    "    show_dataset_table ()\n",
    "\n",
    "def on_view_insights_clicked (b ):\n",
    "    show_insights ()\n",
    "\n",
    "def on_download_csv_clicked (b ):\n",
    "    if current_df is None or current_df .empty :\n",
    "        with output_area :\n",
    "            clear_output (wait=True)\n",
    "            print (\"Geen dataset om te downloaden.\")\n",
    "        return\n",
    "\n",
    "    ean_val =ean_input .value .strip ().replace (\" \",\"_\").replace(\"/\",\"_\") # Sanitize filename\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename_base = f\"dataset_{ean_val}_{ts}.csv\"\n",
    "\n",
    "    downloads_folder =os .path .join (os .path .expanduser (\"~\"),\"Downloads\")\n",
    "    if not os .path .isdir (downloads_folder ):\n",
    "        try:\n",
    "            os.makedirs(downloads_folder) # Create if not exists\n",
    "        except OSError: # Fallback to current working directory if creation fails\n",
    "            logger.warning(f\"Kon map {downloads_folder} niet aanmaken. CSV wordt opgeslagen in huidige werkmap.\")\n",
    "            downloads_folder =os .getcwd ()\n",
    "\n",
    "\n",
    "    filename =os .path .join (downloads_folder ,filename_base)\n",
    "    if export_dataset_to_csv (current_df ,filename ):\n",
    "        with output_area :\n",
    "            clear_output (wait=True)\n",
    "            # Create a downloadable link (Jupyter specific)\n",
    "            # For local Jupyter, direct file path is more informative. For Hub/Lab, link might be better.\n",
    "            display (HTML (f\"<p>CSV bestand opgeslagen in uw Downloads map: <code>{filename}</code></p>\"\n",
    "                           f\"<p>Als de download niet automatisch start, kunt u het bestand hier vinden.</p>\"))\n",
    "    else:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Fout bij exporteren naar CSV.\")\n",
    "\n",
    "\n",
    "def on_download_excel_clicked (b ):\n",
    "    if current_df is None or current_df .empty :\n",
    "        with output_area :\n",
    "            clear_output (wait=True)\n",
    "            print (\"Geen dataset om te downloaden.\")\n",
    "        return\n",
    "\n",
    "    ean_val =ean_input .value .strip ().replace (\" \",\"_\").replace(\"/\",\"_\") # Sanitize filename\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename_base = f\"dataset_{ean_val}_{ts}.xlsx\"\n",
    "    \n",
    "    downloads_folder =os .path .join (os .path .expanduser (\"~\"),\"Downloads\")\n",
    "    if not os .path .isdir (downloads_folder ):\n",
    "        try:\n",
    "            os.makedirs(downloads_folder)\n",
    "        except OSError:\n",
    "            logger.warning(f\"Kon map {downloads_folder} niet aanmaken. Excel wordt opgeslagen in huidige werkmap.\")\n",
    "            downloads_folder =os .getcwd ()\n",
    "\n",
    "    filename =os .path .join (downloads_folder ,filename_base)\n",
    "    \n",
    "    # Get formatting options from checkboxes\n",
    "    apply_excel_format = excel_format_checkbox.value\n",
    "    include_status_for_formatting = status_checkbox.value and not aggregate_checkbox.value # Status only relevant if not aggregated\n",
    "\n",
    "    if export_dataset_to_excel(current_df, filename, apply_excel_format, include_status_for_formatting):\n",
    "        with output_area :\n",
    "            clear_output (wait=True)\n",
    "            display (HTML (f\"<p>Excel bestand opgeslagen in uw Downloads map: <code>{filename}</code></p>\"\n",
    "                           f\"<p>Als de download niet automatisch start, kunt u het bestand hier vinden.</p>\"))\n",
    "    else:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Fout bij exporteren naar Excel.\")\n",
    "\n",
    "\n",
    "btn_load_filters.on_click(on_load_filters_clicked)\n",
    "btn_reset_filters .on_click (on_reset_filters_clicked )\n",
    "btn_build_dataset .on_click (on_build_dataset_clicked )\n",
    "btn_view_dataset .on_click (on_view_dataset_clicked )\n",
    "btn_view_insights .on_click (on_view_insights_clicked )\n",
    "btn_download_csv .on_click (on_download_csv_clicked )\n",
    "btn_download_excel .on_click (on_download_excel_clicked )\n",
    "\n",
    "# Initial validation call to check default dates\n",
    "validate_data_request()\n",
    "# Initial call to adjust dates based on default frequency (if not 'auto')\n",
    "# This ensures that if the initial freq is e.g. '5T', dates are rounded on load.\n",
    "adjust_dates_on_freq_change({'new': freq_selector.value}) # Pass a mock change object\n",
    "validate_data_request() # And re-validate after potential adjustment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energymonitor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30a1a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root {\n",
       "    --primary-color: #0069d9;\n",
       "    --primary-hover: #005cbf;\n",
       "    --primary-active: #0050a3;\n",
       "    --text-color: #2c3e50;\n",
       "    --bg-input: #ffffff;\n",
       "    --border-input: #dfe3e8;\n",
       "    --border-radius: 6px;\n",
       "    --spacing: 0.5rem;\n",
       "    --transition-speed: 0.2s;\n",
       "}\n",
       "\n",
       "/* --- Basis typografie & body --- */\n",
       "body,\n",
       ".widget-label,\n",
       ".widget-html,\n",
       ".widget-dropdown,\n",
       ".widget-text {\n",
       "    font-family: 'Inter', sans-serif !important;\n",
       "    font-size: 0.95rem !important;\n",
       "    color: var(--text-color) !important;\n",
       "}\n",
       "\n",
       "/* --- Globale container alignment --- */\n",
       ".jupyter-widgets.widget-container.widget-label {\n",
       "    display: flex !important;\n",
       "    align-items: center !important;\n",
       "}\n",
       "\n",
       "/* --- Labels --- */\n",
       ".widget-label {\n",
       "    margin-right: var(--spacing) !important;\n",
       "    font-weight: 500 !important;\n",
       "}\n",
       "\n",
       ".widget-text input[type=\"text\"],\n",
       ".widget-text input[type=\"number\"],\n",
       ".widget-dropdown select {\n",
       "    display: inline-block !important;\n",
       "    width: auto !important;\n",
       "    min-width: 8rem !important;\n",
       "    height: 2.5rem !important;\n",
       "    padding: 0 var(--spacing) !important;\n",
       "    margin: var(--spacing) 0 !important;\n",
       "    border: 1px solid var(--border-input) !important;\n",
       "    border-radius: var(--border-radius) !important;\n",
       "    background-color: var(--bg-input) !important;\n",
       "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.05) !important;\n",
       "    transition: border-color var(--transition-speed) ease-in-out !important;\n",
       "}\n",
       ".widget-text input:focus,\n",
       ".widget-dropdown select:focus {\n",
       "    border-color: var(--primary-color) !important;\n",
       "    outline: none !important;\n",
       "    box-shadow: 0 0 0 2px rgba(0,105,217,0.2) !important;\n",
       "}\n",
       ".widget-button {\n",
       "    display: inline-flex !important;\n",
       "    align-items: center !important;\n",
       "    justify-content: center !important;\n",
       "    padding: 0 var(--spacing) !important;\n",
       "    margin: var(--spacing) var(--spacing) 0 0 !important;\n",
       "    height: 2.5rem !important;\n",
       "    min-width: 6.5rem !important;\n",
       "    font-weight: 600 !important;\n",
       "    font-size: 0.9rem !important;\n",
       "    color: #fff !important;\n",
       "    background-color: var(--primary-color) !important;\n",
       "    border: 1px solid var(--primary-color) !important;\n",
       "    border-radius: var(--border-radius) !important;\n",
       "    box-shadow: 0 2px 6px rgba(0,0,0,0.1) !important;\n",
       "    cursor: pointer !important;\n",
       "    transition:\n",
       "        background-color var(--transition-speed) ease,\n",
       "        border-color var(--transition-speed) ease,\n",
       "        box-shadow var(--transition-speed) ease,\n",
       "        transform var(--transition-speed) ease !important;\n",
       "}\n",
       ".widget-button:hover {\n",
       "    background-color: var(--primary-hover) !important;\n",
       "    border-color: var(--primary-hover) !important;\n",
       "    box-shadow: 0 4px 12px rgba(0,0,0,0.15) !important;\n",
       "    transform: translateY(-1px) !important;\n",
       "}\n",
       ".widget-button:active {\n",
       "    background-color: var(--primary-active) !important;\n",
       "    border-color: var(--primary-active) !important;\n",
       "    box-shadow: 0 2px 6px rgba(0,0,0,0.1) !important;\n",
       "    transform: translateY(0) !important;\n",
       "}\n",
       ".widget-button:disabled {\n",
       "    background-color: #a0aec0 !important;\n",
       "    border-color: #a0aec0 !important;\n",
       "    box-shadow: none !important;\n",
       "    opacity: 0.7 !important;\n",
       "    cursor: not-allowed !important;\n",
       "}\n",
       "\n",
       ".widget-button.mod-outline {\n",
       "    background-color: transparent !important;\n",
       "    color: var(--primary-color) !important;\n",
       "    border: 1px solid var(--primary-color) !important;\n",
       "}\n",
       ".widget-button.mod-outline:hover {\n",
       "    background-color: rgba(0,105,217,0.1) !important;\n",
       "}\n",
       "\n",
       "/* --- Checkbox labels --- */\n",
       ".widget-checkbox label {\n",
       "    margin-left: var(--spacing) !important;\n",
       "    font-weight: 400 !important;\n",
       "}\n",
       "\n",
       "/* --- Accordion headers & containers --- */\n",
       ".widget-accordion > .widget-label {\n",
       "    font-weight: 600 !important;\n",
       "    margin-bottom: 0.25rem !important;\n",
       "}\n",
       "\n",
       "/* --- Progress bar styling (optioneel) --- */\n",
       ".jupyter-widgets .progress {\n",
       "    height: 0.75rem !important;\n",
       "    margin-top: var(--spacing) !important;\n",
       "    background-color: #e9ecef !important;\n",
       "    border-radius: var(--border-radius) !important;\n",
       "}\n",
       ".jupyter-widgets .progress-bar {\n",
       "    transition: width var(--transition-speed) ease !important;\n",
       "}\n",
       "\n",
       "/* ——— Zorg dat HBox-containers wrappen en baseline uitlijnen ——— */\n",
       ".jupyter-widgets .widget-hbox {\n",
       "    display: flex !important;\n",
       "    flex-wrap: wrap !important;\n",
       "    align-items: baseline !important;\n",
       "    gap: var(--spacing) !important;\n",
       "}\n",
       ".jupyter-widgets .widget-hbox .widget-label,\n",
       ".jupyter-widgets .widget-hbox .widget-text,\n",
       ".jupyter-widgets .widget-hbox .widget-dropdown,\n",
       ".jupyter-widgets .widget-hbox .widget-button {\n",
       "    align-self: baseline !important;\n",
       "    margin-top: 0 !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Python executable: c:\\Users\\StanvanBon\\Miniconda3\\envs\\energymonitor_env\\python.exe\n",
      "▶ dotenv module: c:\\Users\\StanvanBon\\Miniconda3\\envs\\energymonitor_env\\Lib\\site-packages\\dotenv\\__init__.py\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7950095f03a4ca39f8c33ec480cb40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='info', description='Terug naar Startscherm', icon='home', layout=Layout(he…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de528cb321e4d8c8f733d46006f77d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c981d7950744a7becd158e5d5efefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='info', description='Verberg filters', icon='chevron-up', layout=Layout(hei…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common_imports import *\n",
    "show_home_button()\n",
    "from db_connection import get_engine\n",
    "engine = get_engine()\n",
    "logging .basicConfig (level =logging .INFO )\n",
    "logger =logging .getLogger (__name__ )\n",
    "\n",
    "# Added imports\n",
    "import pytz\n",
    "from datetime import time as dt_time\n",
    "\n",
    "# --- Utils Section ---\n",
    "class DateAdjustmentUtils:\n",
    "    AMSTERDAM_TZ = pytz.timezone('Europe/Amsterdam')\n",
    "\n",
    "    @staticmethod\n",
    "    def localize_to_amsterdam(dt: datetime) -> datetime:\n",
    "        \"\"\"Localizes a naive datetime object to Europe/Amsterdam timezone.\"\"\"\n",
    "        if dt.tzinfo is None:\n",
    "            return DateAdjustmentUtils.AMSTERDAM_TZ.localize(dt)\n",
    "        return dt.astimezone(DateAdjustmentUtils.AMSTERDAM_TZ)\n",
    "\n",
    "    @staticmethod\n",
    "    def round_datetime(dt: datetime, freq_value: str, is_start_date: bool) -> Optional[datetime]:\n",
    "        \"\"\"\n",
    "        Rounds a datetime object based on the given frequency.\n",
    "        'dt' is assumed to be a naive datetime object.\n",
    "        Returns a timezone-aware datetime object (Europe/Amsterdam).\n",
    "        \"\"\"\n",
    "        if not dt:\n",
    "            logger.warning(\"round_datetime received None for dt.\")\n",
    "            return None\n",
    "\n",
    "        # Ensure dt is naive, then localize to Amsterdam\n",
    "        dt_ams = DateAdjustmentUtils.localize_to_amsterdam(dt.replace(tzinfo=None))\n",
    "\n",
    "        if freq_value == '5T':\n",
    "            minute_rounded = (dt_ams.minute // 5) * 5\n",
    "            return dt_ams.replace(minute=minute_rounded, second=0, microsecond=0)\n",
    "        elif freq_value == '15T':\n",
    "            minute_rounded = (dt_ams.minute // 15) * 15\n",
    "            return dt_ams.replace(minute=minute_rounded, second=0, microsecond=0)\n",
    "        elif freq_value == 'H':\n",
    "            return dt_ams.replace(minute=0, second=0, microsecond=0)\n",
    "        elif freq_value == 'D':\n",
    "            # Start: 00:00 of geselecteerde dag\n",
    "            # Eind: 00:00 volgende dag\n",
    "            base_dt = dt_ams.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "            if not is_start_date:  # This is an end date\n",
    "                return base_dt + timedelta(days=1)\n",
    "            return base_dt\n",
    "        elif freq_value == 'W':\n",
    "            # Start: ma 00:00 van dezelfde ISO-week\n",
    "            # Eind: ma 00:00 van week +1\n",
    "            # weekday() returns 0 for Monday, 6 for Sunday\n",
    "            start_of_this_week = (dt_ams - timedelta(days=dt_ams.weekday())).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "            if not is_start_date:  # This is an end date\n",
    "                return start_of_this_week + timedelta(weeks=1)\n",
    "            return start_of_this_week\n",
    "        elif freq_value == 'ME': # Changed from 'M' to 'ME' to match dropdown and internal dicts if selector is updated\n",
    "            # Start: 1e 00:00 van maand\n",
    "            # Eind: 1e 00:00 volgende maand\n",
    "            start_of_this_month = dt_ams.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "            if not is_start_date:  # This is an end date\n",
    "                next_month_year = start_of_this_month.year\n",
    "                next_month_month = start_of_this_month.month + 1\n",
    "                if next_month_month > 12:\n",
    "                    next_month_month = 1\n",
    "                    next_month_year += 1\n",
    "                return start_of_this_month.replace(year=next_month_year, month=next_month_month)\n",
    "            return start_of_this_month\n",
    "        elif freq_value == 'Y':\n",
    "            # Start: 1 jan 00:00\n",
    "            # Eind: 1 jan 00:00 volgend jaar\n",
    "            start_of_this_year = dt_ams.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "            if not is_start_date:  # This is an end date\n",
    "                return start_of_this_year.replace(year=start_of_this_year.year + 1)\n",
    "            return start_of_this_year\n",
    "        \n",
    "        logger.warning(f\"Onbekende freq_value '{freq_value}' in DateAdjustmentUtils.round_datetime. Datum niet aangepast.\")\n",
    "        return dt_ams # Fallback: return original localized datetime\n",
    "\n",
    "class TTLCache :\n",
    "    \"\"\"Thread-safe cache met Time-To-Live (standaard 5 minuten).\"\"\"\n",
    "    def __init__ (self ,ttl :int =300 ):\n",
    "        self .cache ={}\n",
    "        self .ttl =ttl\n",
    "        self .lock =threading .Lock ()\n",
    "\n",
    "    def get (self ,key ):\n",
    "        with self .lock :\n",
    "            entry =self .cache .get (key )\n",
    "            if entry is None :\n",
    "                return None\n",
    "            value ,expires_at =entry\n",
    "            if time .time ()>expires_at :\n",
    "                del self .cache [key ]\n",
    "                return None\n",
    "            return value\n",
    "\n",
    "    def set (self ,key ,value ):\n",
    "        with self .lock :\n",
    "            expires_at =time .time ()+self .ttl\n",
    "            self .cache [key ]=(value ,expires_at )\n",
    "\n",
    "min_max_cache =TTLCache (ttl =300 )\n",
    "full_data_cache =TTLCache (ttl =300 )\n",
    "\n",
    "from mappings import get_typeids, validate_unique_ids, group_typeid_mapping\n",
    "\n",
    "validate_unique_ids()\n",
    "\n",
    "FREQ_TO_SECONDS ={\n",
    "'5T':300 ,\n",
    "'15T':900 ,\n",
    "'H':3600 ,\n",
    "'D':86400 ,\n",
    "'W':604800 ,\n",
    "'ME':2592000 , # For 30 days, actual month length varies\n",
    "'Y':31536000  # For 365 days\n",
    "}\n",
    "FREQ_TO_MINUTES ={\n",
    "'5T':5 ,\n",
    "'15T':15 ,\n",
    "'H':60 ,\n",
    "'D':1440 ,\n",
    "'W':10080 ,\n",
    "'ME':43200 , # For 30 days\n",
    "'Y':525600  # For 365 days\n",
    "}\n",
    "MAX_ROWS =8000\n",
    "def parse_user_datetime (dt_str :str )->Optional [datetime ]:\n",
    "    try :\n",
    "        return datetime .strptime (dt_str ,'%d/%m/%Y %H:%M')\n",
    "    except ValueError :\n",
    "        return None\n",
    "def generate_insights (df :pd .DataFrame )->str :\n",
    "    \"\"\"\n",
    "    Genereert inzichten in tabelvorm per status-kanaal en geeft een HTML-tabel.\n",
    "    \"\"\"\n",
    "    insights_df =get_insights_df (df )\n",
    "    if insights_df .empty :\n",
    "        return \"Geen inzichten beschikbaar.\"\n",
    "    return insights_df .to_html (classes =\"dataframe\",border =0 )\n",
    "\n",
    "def get_insights_df (df :pd .DataFrame )->pd .DataFrame :\n",
    "    \"\"\"\n",
    "    Genereert inzichten als DataFrame per status-kanaal.\n",
    "    Voor elk status-kanaal en per status (\"P\" of \"T\") wordt het aantal voorkomen,\n",
    "    plus de eerste (van datum) en laatste (tot datum) keer dat deze status voorkomt.\n",
    "    \"\"\"\n",
    "    if df is None or df .empty :\n",
    "        return pd .DataFrame ()\n",
    "\n",
    "    time_col =None\n",
    "    if \"UTC Period\"in df .columns :\n",
    "        time_col =\"UTC Period\"\n",
    "    elif \"utcperiod\"in df .columns :\n",
    "        time_col =\"utcperiod\"\n",
    "\n",
    "    status_cols =[col for col in df .columns if 'status'in col .lower ()]\n",
    "    if not status_cols :\n",
    "        return pd .DataFrame ()\n",
    "\n",
    "    rows =[]\n",
    "    for col in status_cols :\n",
    "        for stat in [\"P\",\"T\"]:\n",
    "            count =(df [col ]==stat ).sum ()\n",
    "            if count >0 and time_col is not None :\n",
    "                dates =pd .to_datetime (df .loc [df [col ]==stat ,time_col ],errors ='coerce')\n",
    "                start_date =dates .min ()\n",
    "                end_date =dates .max ()\n",
    "            else :\n",
    "                start_date =None\n",
    "                end_date =None\n",
    "            rows .append ({\n",
    "            \"Kanaal\":col ,\n",
    "            \"Status\":stat ,\n",
    "            \"Count\":count ,\n",
    "            \"Van datum\":start_date ,\n",
    "            \"Tot datum\":end_date\n",
    "            })\n",
    "\n",
    "    insights_df =pd .DataFrame (rows )\n",
    "    insights_df .set_index ([\"Kanaal\",\"Status\"],inplace =True )\n",
    "    return insights_df\n",
    "def group_columns_by_typeid (df :pd .DataFrame ,engine ,group_mapping :dict )->pd .DataFrame :\n",
    "    import re\n",
    "    registerid_pattern =re .compile (r'\\((\\d+)\\)')\n",
    "    col_to_registerid ={}\n",
    "    for col in df .columns :\n",
    "        if col .lower ()in ['utcperiod','utc period']:\n",
    "            continue\n",
    "        match =registerid_pattern .search (col )\n",
    "        if match :\n",
    "            reg_id =int (match .group (1 ))\n",
    "            col_to_registerid [col ]=reg_id\n",
    "    if not col_to_registerid :\n",
    "        raise ValueError (\"Geen register-ID's gevonden in de DataFrame kolomnamen.\")\n",
    "\n",
    "    query =\"SELECT ID, TypeId FROM dbo.TBL_Register WHERE ID IN ({})\".format (\n",
    "    \",\".join (map (str ,list (col_to_registerid .values ())))\n",
    "    )\n",
    "    with engine .connect ()as conn :\n",
    "        mapping_df =pd .read_sql_query (query ,conn )\n",
    "    registerid_to_typeid =dict (zip (mapping_df ['ID'],mapping_df ['TypeId']))\n",
    "\n",
    "    grouped_df =df [['utcperiod']].copy ()if 'utcperiod'in df .columns else df .copy ()\n",
    "\n",
    "    for group_name ,typeid_list in group_mapping .items ():\n",
    "        cols_for_group =[]\n",
    "        for col ,reg_id in col_to_registerid .items ():\n",
    "            typeid_val =registerid_to_typeid .get (reg_id )\n",
    "            if typeid_val in typeid_list :\n",
    "                cols_for_group .append (col )\n",
    "\n",
    "        if cols_for_group :\n",
    "            numeric_subset =[c for c in cols_for_group if '(status)'not in c .lower ()]\n",
    "            if numeric_subset :\n",
    "                grouped_df [group_name +\" Total\"]=df [numeric_subset ].sum (axis =1 ,numeric_only =True )\n",
    "            else :\n",
    "                grouped_df [group_name +\" Total\"]=0\n",
    "        else :\n",
    "            grouped_df [group_name +\" Total\"]=0\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "def filter_columns_by_selected_groups (df :pd .DataFrame ,engine ,group_mapping :dict )->pd .DataFrame :\n",
    "    import re\n",
    "    registerid_pattern =re .compile (r'\\((\\d+)\\)')\n",
    "    col_to_registerid ={}\n",
    "    for col in df .columns :\n",
    "        if col .lower ()in ['utcperiod','utc period']:\n",
    "            continue\n",
    "        match =registerid_pattern .search (col )\n",
    "        if match :\n",
    "            col_to_registerid [col ]=int (match .group (1 ))\n",
    "    if not col_to_registerid :\n",
    "        return df [['utcperiod']]if 'utcperiod'in df .columns else pd .DataFrame ()\n",
    "\n",
    "    query =\"SELECT ID, TypeId FROM dbo.TBL_Register WHERE ID IN ({})\".format (\n",
    "    \",\".join (map (str ,list (col_to_registerid .values ())))\n",
    "    )\n",
    "    with engine .connect ()as conn :\n",
    "        mapping_df =pd .read_sql_query (query ,conn )\n",
    "    regid_to_typeid =dict (zip (mapping_df ['ID'],mapping_df ['TypeId']))\n",
    "\n",
    "    selected_cols =[]\n",
    "    for col ,reg_id in col_to_registerid .items ():\n",
    "        typeid_val =regid_to_typeid .get (reg_id )\n",
    "        for grp ,tid_list in group_mapping .items ():\n",
    "            if typeid_val in tid_list :\n",
    "                selected_cols .append (col )\n",
    "                break\n",
    "\n",
    "    cols =[]\n",
    "    if 'utcperiod'in df .columns :\n",
    "        cols .append ('utcperiod')\n",
    "    cols .extend (selected_cols )\n",
    "    return df [cols ]\n",
    "search_method_dropdown =widgets .Dropdown (\n",
    "options =[\n",
    "(\"TransferpointID\",\"transferpoint\"),\n",
    "(\"ObjectID\",\"objectid\"),\n",
    "(\"RegisterID\",\"registerid\"),\n",
    "(\"RegistratorID\",\"registratorid\")\n",
    "],\n",
    "value =\"transferpoint\",\n",
    "description =\"Filter:\"\n",
    ")\n",
    "search_method_dropdown .layout =widgets .Layout (width ='240px',height ='35px')\n",
    "\n",
    "def fetch_typeids_for_ean (ean_value :str )->Set [int ]:\n",
    "    search_method =search_method_dropdown .value\n",
    "    try :\n",
    "        if search_method ==\"transferpoint\":\n",
    "            query =\"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                JOIN TBL_ConnectionPoint cp ON cp.ID = r.ConnectionPointId\n",
    "                WHERE cp.EAN_ConnectionPoint = ?\n",
    "                      OR cp.TransferPointID IN (\n",
    "                          SELECT ID FROM TBL_ConnectionPoint WHERE EAN_ConnectionPoint = ?\n",
    "                      )\n",
    "            \"\"\"\n",
    "            with engine .connect ()as conn :\n",
    "                df_temp =pd .read_sql_query (query ,conn ,params =(ean_value ,ean_value ))\n",
    "        elif search_method ==\"objectid\":\n",
    "            query =\"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                JOIN TBL_ConnectionPoint cp ON cp.ID = r.ConnectionPointId\n",
    "                WHERE cp.ObjectId = (\n",
    "                    SELECT TOP 1 cp2.ObjectId\n",
    "                    FROM TBL_ConnectionPoint cp2\n",
    "                    WHERE cp2.EAN_ConnectionPoint = ?\n",
    "                )\n",
    "            \"\"\"\n",
    "            with engine .connect ()as conn :\n",
    "                df_temp =pd .read_sql_query (query ,conn ,params =(ean_value ,))\n",
    "        elif search_method ==\"registerid\":\n",
    "            query =\"\"\"\n",
    "                SELECT DISTINCT TypeId\n",
    "                FROM TBL_Register\n",
    "                WHERE ID = ?\n",
    "            \"\"\"\n",
    "            try :\n",
    "                register_id =int (ean_value )\n",
    "            except ValueError :\n",
    "                return set ()\n",
    "            with engine .connect ()as conn :\n",
    "                df_temp =pd .read_sql_query (query ,conn ,params =(register_id ,))\n",
    "        elif search_method ==\"registratorid\":\n",
    "            query =\"\"\"\n",
    "                SELECT DISTINCT r.TypeId\n",
    "                FROM TBL_Register r\n",
    "                WHERE r.RegistratorID = ?\n",
    "            \"\"\"\n",
    "            try :\n",
    "                registrator_id =int (ean_value )\n",
    "            except ValueError :\n",
    "                return set ()\n",
    "            with engine .connect ()as conn :\n",
    "                df_temp =pd .read_sql_query (query ,conn ,params =(registrator_id ,))\n",
    "        else :\n",
    "            return set ()\n",
    "\n",
    "        if df_temp .empty :\n",
    "            return set ()\n",
    "        return set (df_temp ['TypeId'].unique ())\n",
    "\n",
    "    except Exception as e :\n",
    "        logger .error (f\"Error fetching TypeIDs: {e}\")\n",
    "        return set ()\n",
    "\n",
    "def fetch_min_max_period (ean_value :str ,\n",
    "allowed_typeids_str :str ,\n",
    "start_date :datetime ,\n",
    "end_date :datetime\n",
    ")->Tuple [Optional [datetime ],Optional [datetime ]]:\n",
    "    search_method =search_method_dropdown .value\n",
    "    cache_key =(ean_value ,allowed_typeids_str ,start_date ,end_date ,'minmax',search_method )\n",
    "    cached =min_max_cache .get (cache_key )\n",
    "    if cached is not None :\n",
    "        logger .info (\"Min/Max periode uit cache gehaald.\")\n",
    "        return cached\n",
    "\n",
    "    start_date_str =start_date .strftime ('%d/%m/%Y %H:%M')\n",
    "    end_date_str =end_date .strftime ('%d/%m/%Y %H:%M')\n",
    "    sp_query =\"\"\"\n",
    "        EXEC [dbo].[usp_GetMinMaxPeriodForEAN]\n",
    "             @EAN_ConnectionPoint = ?,\n",
    "             @AllowedTypeIDs = ?,\n",
    "             @StartDateStr = ?,\n",
    "             @EndDateStr = ?,\n",
    "             @SearchMethod = ?\n",
    "    \"\"\"\n",
    "    try :\n",
    "        with engine .connect ()as conn :\n",
    "            df_temp =pd .read_sql_query (\n",
    "            sp_query ,conn ,\n",
    "            params =(ean_value ,allowed_typeids_str ,start_date_str ,end_date_str ,search_method )\n",
    "            )\n",
    "        if df_temp .empty or pd .isnull (df_temp ['MinUTCPeriod'].iloc [0 ]):\n",
    "            result =(None ,None )\n",
    "        else :\n",
    "            result =(df_temp ['MinUTCPeriod'].iloc [0 ],df_temp ['MaxUTCPeriod'].iloc [0 ])\n",
    "\n",
    "        min_max_cache .set (cache_key ,result )\n",
    "        logger .info (\"Min/Max periode in cache gezet.\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e :\n",
    "        logger .error (f\"Error fetching min/max period: {e}\")\n",
    "        return (None ,None )\n",
    "\n",
    "def fetch_full_data (ean_value :str ,\n",
    "allowed_typeids_str :str ,\n",
    "start_date :datetime ,\n",
    "end_date :datetime ,\n",
    "interval_minutes :int =5 ,\n",
    "include_status :bool =False\n",
    ")->Optional [pd .DataFrame ]:\n",
    "    search_method =search_method_dropdown .value\n",
    "    cache_key =(ean_value ,allowed_typeids_str ,start_date ,end_date ,\n",
    "    'pivot',search_method ,interval_minutes ,include_status )\n",
    "    cached =full_data_cache .get (cache_key )\n",
    "    if cached is not None :\n",
    "        logger .info (\"Volledige data uit cache gehaald.\")\n",
    "        return cached\n",
    "\n",
    "    start_date_str =start_date .strftime ('%d/%m/%Y %H:%M')\n",
    "    end_date_str =end_date .strftime ('%d/%m/%Y %H:%M')\n",
    "    sp_query =\"\"\"\n",
    "        EXEC [dbo].[usp_GetConnectionDataFull]\n",
    "             @EAN_ConnectionPoint = ?,\n",
    "             @AllowedTypeIDs      = ?,\n",
    "             @StartDateStr        = ?,\n",
    "             @EndDateStr          = ?,\n",
    "             @SearchMethod        = ?,\n",
    "             @IntervalMinutes     = ?,\n",
    "             @IncludeStatus       = ?\n",
    "    \"\"\"\n",
    "    try :\n",
    "        with engine .connect ()as conn :\n",
    "            df =pd .read_sql_query (\n",
    "            sp_query ,conn ,\n",
    "            params =(\n",
    "            ean_value ,\n",
    "            allowed_typeids_str ,\n",
    "            start_date_str ,\n",
    "            end_date_str ,\n",
    "            search_method ,\n",
    "            interval_minutes ,\n",
    "            int (include_status )\n",
    "            ),\n",
    "            parse_dates =['utcperiod']\n",
    "            )\n",
    "        if df .empty :\n",
    "            result =None\n",
    "        else :\n",
    "            result =df\n",
    "\n",
    "        full_data_cache .set (cache_key ,result )\n",
    "        logger .info (\"Volledige data in cache gezet.\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e :\n",
    "        logger .error (f\"Error fetching full data: {e}\")\n",
    "        return None\n",
    "def distribute_consumption_across_intervals (df :pd .DataFrame ,freq :str )->pd .DataFrame :\n",
    "    if df .empty :\n",
    "        return df\n",
    "    numeric_df =df .select_dtypes (include =[np .number ])\n",
    "    non_numeric_df =df .select_dtypes (exclude =[np .number ])\n",
    "\n",
    "    numeric_df =numeric_df .groupby (numeric_df .index ).sum ()\n",
    "    cumsum_numeric =numeric_df .cumsum ()\n",
    "\n",
    "    new_index =pd .date_range (start =df .index .min (),end =df .index .max (),freq =freq )\n",
    "    cumsum_numeric =cumsum_numeric .reindex (new_index ).interpolate (method ='linear')\n",
    "    distributed_numeric =cumsum_numeric .diff ()\n",
    "    if not distributed_numeric .empty :\n",
    "        distributed_numeric .iloc [0 ]=cumsum_numeric .iloc [0 ]\n",
    "    distributed_numeric =distributed_numeric .fillna (0 )\n",
    "\n",
    "    if non_numeric_df .empty :\n",
    "        result =distributed_numeric\n",
    "    else :\n",
    "        non_numeric_df =non_numeric_df .groupby (non_numeric_df .index ).first ()\n",
    "        non_numeric_df =non_numeric_df .reindex (new_index ,method ='ffill')\n",
    "        result =pd .concat ([non_numeric_df ,distributed_numeric ],axis =1 )\n",
    "    return result\n",
    "def build_dataset (ean_val :str ,\n",
    "chosen_groups :List [str ],\n",
    "start_date :datetime ,\n",
    "end_date :datetime ,\n",
    "freq_val :str ,\n",
    "aggregate :bool ,\n",
    "include_status_flag :bool =False\n",
    ")->Optional [pd .DataFrame ]:\n",
    "    typeids_final =[]\n",
    "    for grp in chosen_groups :\n",
    "        typeids_final .extend (group_typeid_mapping .get (grp ,[]))\n",
    "\n",
    "    if not typeids_final :\n",
    "        logger .warning (\"Geen TypeIDs in chosen_groups.\")\n",
    "        return None\n",
    "\n",
    "    allowed_typeids_str =\",\".join (str (tid )for tid in set (typeids_final ))\n",
    "\n",
    "\n",
    "    minp ,maxp =fetch_min_max_period (ean_val ,allowed_typeids_str ,start_date ,end_date )\n",
    "    if not minp or not maxp :\n",
    "        logger .info (\"Geen data (minp, maxp is None).\")\n",
    "        return None\n",
    "\n",
    "    if freq_val in FREQ_TO_MINUTES :\n",
    "        interval_minutes =FREQ_TO_MINUTES [freq_val ]\n",
    "    else : # Default for 'auto' or unknown, though 'auto' is resolved before this point typically\n",
    "        logger.warning(f\"Frequency value '{freq_val}' not found in FREQ_TO_MINUTES. Defaulting to 5 minutes for interval_minutes.\")\n",
    "        interval_minutes =5\n",
    "\n",
    "\n",
    "    sp_include_status =(not aggregate )and include_status_flag\n",
    "    df_full =fetch_full_data (\n",
    "    ean_val ,\n",
    "    allowed_typeids_str ,\n",
    "    start_date , # Using original start_date for fetching, SP might handle wider range\n",
    "    end_date ,   # Using original end_date for fetching\n",
    "    interval_minutes =interval_minutes ,\n",
    "    include_status =sp_include_status\n",
    "    )\n",
    "    if df_full is None or df_full .empty :\n",
    "        logger .info (\"Lege dataset (df_full).\")\n",
    "        return None\n",
    "\n",
    "    # Ensure start_date and end_date are timezone-aware (UTC, as 'utcperiod' implies) or compatible for comparison\n",
    "    # The df_full['utcperiod'] is parsed by read_sql_query, typically naive.\n",
    "    # It's better if build_dataset receives localized start/end dates or localizes them here.\n",
    "    # For now, assuming they are comparable or SP handles localization.\n",
    "    # If start_date/end_date from input are naive, they should be localized like in DateAdjustmentUtils.\n",
    "    # However, current problem scope is adjust_dates_on_freq_change. This part is pre-existing.\n",
    "\n",
    "    df_f =df_full [\n",
    "    (df_full ['utcperiod']>=start_date )& # This comparison might be tricky if one is aware and other naive.\n",
    "    (df_full ['utcperiod']<=end_date )\n",
    "    ].copy ()\n",
    "\n",
    "    if df_f .empty :\n",
    "        logger .info (\"Geen rijen binnen periode.\")\n",
    "        return None\n",
    "\n",
    "    df_f .set_index ('utcperiod',inplace =True )\n",
    "\n",
    "    # freq_val_lower is used here, but freq_val is passed to distribute_consumption_across_intervals\n",
    "    # Pandas freq strings are case-sensitive. Usually uppercase.\n",
    "    # The freq_selector values are uppercase (5T, H, D, W, ME, Y) or 'auto'.\n",
    "    # So freq_val should be used directly unless specific lowercasing is needed.\n",
    "\n",
    "    if freq_val .lower ()=='auto': # freq_val.lower() usage\n",
    "        periods =df_f .index .sort_values ()\n",
    "        if len (periods )>1 :\n",
    "            diffs =periods .to_series ().diff ().dropna ().dt .total_seconds ().astype (int )\n",
    "            mode_diff =diffs .mode ()[0 ] if not diffs.empty else FREQ_TO_SECONDS.get('H', 3600) # handle empty diffs\n",
    "            freq_found =None\n",
    "            for key ,sec in FREQ_TO_SECONDS .items ():\n",
    "\n",
    "                if abs (sec -mode_diff )<10 : # Allow small tolerance\n",
    "                    freq_found =key\n",
    "                    break\n",
    "            if freq_found is None : # Fallback if no close match\n",
    "                freq_found ='H' # Default to Hourly\n",
    "            freq_val =freq_found # Update freq_val to the detected one\n",
    "            logger .info (f\"Automatisch gedetecteerde frequentie: {freq_val}\")\n",
    "        else :\n",
    "            freq_val ='H' # Fallback if only one data point\n",
    "            logger .info (\"Niet genoeg data om frequentie te detecteren; gebruik 'H' als fallback.\")\n",
    "    \n",
    "    # Ensure freq_val is valid for distribute_consumption_across_intervals\n",
    "    # which passes it to pd.date_range(freq=freq_val)\n",
    "    if freq_val not in FREQ_TO_SECONDS and freq_val != 'auto': # 'auto' is resolved above\n",
    "        logger.error(f\"Ongeldige frequentie '{freq_val}' voor resampling. Check FREQ_TO_SECONDS/MINUTES.\")\n",
    "        # Potentially return None or use a default frequency\n",
    "        return None\n",
    "\n",
    "\n",
    "    if aggregate :\n",
    "        df_reset =df_f .reset_index ()\n",
    "        selected_mapping ={grp :group_typeid_mapping [grp ]for grp in chosen_groups if grp in group_typeid_mapping }\n",
    "        df_grouped =group_columns_by_typeid (df_reset ,engine ,selected_mapping )\n",
    "        df_grouped .set_index ('utcperiod',inplace =True )\n",
    "        df_interest =df_grouped\n",
    "    else :\n",
    "        selected_mapping ={grp :group_typeid_mapping [grp ]for grp in chosen_groups if grp in group_typeid_mapping }\n",
    "        df_interest =filter_columns_by_selected_groups (df_f ,engine ,selected_mapping )\n",
    "\n",
    "    if df_interest .empty :\n",
    "        logger.info(\"DataFrame is leeg na filteren/groeperen (df_interest).\")\n",
    "        return None\n",
    "\n",
    "    # df_interest index should be DatetimeIndex for distribute_consumption_across_intervals\n",
    "    if not isinstance(df_interest.index, pd.DatetimeIndex):\n",
    "        logger.warning(\"df_interest index is not a DatetimeIndex. Attempting conversion.\")\n",
    "        try:\n",
    "            df_interest.index = pd.to_datetime(df_interest.index)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Kon df_interest.index niet converteren naar DatetimeIndex: {e}\")\n",
    "            return None\n",
    "            \n",
    "    if df_interest.index.min() is pd.NaT or df_interest.index.max() is pd.NaT:\n",
    "        logger.warning(\"df_interest index contains NaT values or is empty after conversion. Cannot proceed with resampling.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    distributed_df =distribute_consumption_across_intervals (df_interest ,freq_val ) # freq_val should be Pandas compatible\n",
    "    distributed_df =distributed_df .reset_index ()\n",
    "\n",
    "    if 'index'in distributed_df .columns :\n",
    "        distributed_df .rename (columns ={'index':'UTC Period'},inplace =True )\n",
    "    elif 'utcperiod'in distributed_df .columns : # Should be 'index' from reset_index\n",
    "        distributed_df .rename (columns ={'utcperiod':'UTC Period'},inplace =True )\n",
    "\n",
    "\n",
    "    cols =distributed_df .columns .tolist ()\n",
    "    if 'UTC Period'in cols :\n",
    "        cols .insert (0 ,cols .pop (cols .index ('UTC Period')))\n",
    "    distributed_df =distributed_df [cols ]\n",
    "\n",
    "    final_cols =[]\n",
    "    col_list =distributed_df .columns .tolist ()\n",
    "    if 'UTC Period'in col_list :\n",
    "        final_cols .append ('UTC Period')\n",
    "    consumption_cols =[c for c in col_list if c not in final_cols and '(consumption)'in c .lower ()]\n",
    "    for ccol in consumption_cols :\n",
    "        final_cols .append (ccol )\n",
    "        status_candidate =ccol .replace ('(consumption)','(status)')\n",
    "        if status_candidate in col_list :\n",
    "            final_cols .append (status_candidate )\n",
    "    leftover_cols =[c for c in col_list if c not in final_cols ]\n",
    "    final_cols .extend (leftover_cols )\n",
    "    distributed_df =distributed_df [final_cols ]\n",
    "    return distributed_df\n",
    "\n",
    "def export_dataset_to_csv (df :pd .DataFrame ,filename :str )->bool :\n",
    "    if df is None or df .empty :\n",
    "        logger .warning (\"Kan niet exporteren: lege DataFrame.\")\n",
    "        return False\n",
    "    df_export =df .copy ()\n",
    "    if \"UTC Period\"in df_export .columns :\n",
    "        df_export [\"UTC Period\"]=pd .to_datetime (df_export [\"UTC Period\"],errors ='coerce').dt .strftime ('%Y-%m-%d %H:%M:%S')\n",
    "    df_export .to_csv (filename ,index =False )\n",
    "    logger .info (f\"CSV geëxporteerd: {filename}\")\n",
    "    return True\n",
    "\n",
    "# Modified function signature for export_dataset_to_excel\n",
    "def export_dataset_to_excel (df :pd .DataFrame ,filename :str, excel_format: bool, include_status: bool )->bool :\n",
    "    if df is None or df .empty :\n",
    "        logger .warning (\"Kan niet exporteren: lege DataFrame.\")\n",
    "        return False\n",
    "    try :\n",
    "        # Import necessary for xl_col_to_name if not globally available\n",
    "        from xlsxwriter.utility import xl_col_to_name\n",
    "\n",
    "        with pd .ExcelWriter (filename ,engine ='xlsxwriter',datetime_format ='yyyy-mm-dd hh:mm:ss')as writer :\n",
    "\n",
    "            df .to_excel (writer ,index =False ,sheet_name ='Dataset')\n",
    "\n",
    "            workbook =writer .book\n",
    "            worksheet =writer .sheets ['Dataset']\n",
    "\n",
    "            header_format =workbook .add_format ({\n",
    "            'bold':True ,\n",
    "            'text_wrap':True ,\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'fg_color':'#F2F2F2',\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "            data_format =workbook .add_format ({\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "\n",
    "            df_columns =df .columns .tolist ()\n",
    "            num_rows =len (df )\n",
    "            for col_num ,value in enumerate (df_columns ):\n",
    "                worksheet .write (0 ,col_num ,value ,header_format )\n",
    "                col_header =str (value ).lower ()\n",
    "                if col_header =='utc period':\n",
    "                    col_width =25\n",
    "                elif 'consumption'in col_header :\n",
    "                    col_width =15\n",
    "                elif 'status'in col_header :\n",
    "                    col_width =10\n",
    "                else :\n",
    "                    col_width =max (15 ,len (str (value ))+2 )\n",
    "                worksheet .set_column (col_num ,col_num ,col_width ,data_format )\n",
    "\n",
    "            worksheet .set_row (0 ,42 )\n",
    "            worksheet .freeze_panes (1 ,1 )\n",
    "\n",
    "            if \"UTC Period\"in df_columns :\n",
    "                col_index =df_columns .index (\"UTC Period\")\n",
    "                worksheet .set_column (col_index ,col_index ,25 ,workbook .add_format ({\n",
    "                'num_format':'yyyy-mm-dd hh:mm:ss',\n",
    "                'align':'center',\n",
    "                'valign':'middle',\n",
    "                'font_name':'Arial',\n",
    "                'font_size':10\n",
    "                }))\n",
    "\n",
    "            status_p_format =workbook .add_format ({\n",
    "            'bg_color':'#FFFFAF', # Pale Yellow\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "            status_t_format =workbook .add_format ({\n",
    "            'bg_color':'#FFDB69', # Light Orange/Gold\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "            status_empty_format =workbook .add_format ({ # For empty status cells, if needed for consumption\n",
    "            'bg_color':'#CCFFCC', # Light Green\n",
    "            'align':'center',\n",
    "            'valign':'middle',\n",
    "            'border':1 ,\n",
    "            'border_color':'#808080',\n",
    "            'font_name':'Arial',\n",
    "            'font_size':10\n",
    "            })\n",
    "\n",
    "            if excel_format : # Uses the parameter passed to the function\n",
    "\n",
    "                for col_num ,col_name in enumerate (df_columns ):\n",
    "                    if 'consumption'in str (col_name ).lower ():\n",
    "                        if include_status : # Uses the parameter passed to the function\n",
    "                            status_col_name =col_name .replace ('(consumption)','(status)')\n",
    "                            if status_col_name in df_columns :\n",
    "                                status_col_index =df_columns .index (status_col_name )\n",
    "                                status_letter =xl_col_to_name (status_col_index ) # xl_col_to_name needs import\n",
    "                                # Excel formulas are 1-indexed for rows\n",
    "                                worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                                'type':'formula',\n",
    "                                'criteria':f'=${status_letter}2=\"P\"', # Check from row 2 downwards\n",
    "                                'format':status_p_format ,\n",
    "                                'stop_if_true':True\n",
    "                                })\n",
    "                                worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                                'type':'formula',\n",
    "                                'criteria':f'=${status_letter}2=\"T\"',\n",
    "                                'format':status_t_format ,\n",
    "                                'stop_if_true':True\n",
    "                                })\n",
    "                                worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                                'type':'formula',\n",
    "                                'criteria':f'=${status_letter}2=\"\"', # Or ISBLANK(${status_letter}2)\n",
    "                                'format':status_empty_format , # Assuming you want to format consumption where status is blank\n",
    "                                'stop_if_true':True\n",
    "                                })\n",
    "                        else : # If not include_status, apply a generic format to consumption\n",
    "                            worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                            'type':'3_color_scale', # Example: a color scale\n",
    "                            'min_color':\"#FFFFFF\", # White\n",
    "                            'mid_color':\"#FFFFCC\", # Pale yellow\n",
    "                            'max_color':\"#FFCCCC\"  # Light red\n",
    "                            })\n",
    "\n",
    "                # Formatting for status columns themselves\n",
    "                for col_num ,col_name in enumerate (df_columns ):\n",
    "                    if 'status'in str (col_name ).lower ():\n",
    "                        worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                        'type':'cell',\n",
    "                        'criteria':'==',\n",
    "                        'value':'\"P\"',\n",
    "                        'format':status_p_format\n",
    "                        }) # Removed stop_if_true as it's the final rule for \"P\"\n",
    "                        worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                        'type':'cell',\n",
    "                        'criteria':'==',\n",
    "                        'value':'\"T\"',\n",
    "                        'format':status_t_format\n",
    "                        }) # Removed stop_if_true\n",
    "                        worksheet .conditional_format (1 ,col_num ,num_rows ,col_num ,{\n",
    "                        'type':'cell',\n",
    "                        'criteria':'==',\n",
    "                        'value':'\"\"', # Or 'criteria':'blanks'\n",
    "                        'format':status_empty_format # Format for blank status cells\n",
    "                        }) # Removed stop_if_true\n",
    "\n",
    "\n",
    "        logger .info (f\"Excel bestand opgeslagen: {filename}\")\n",
    "        return True\n",
    "    except Exception as e :\n",
    "        logger .error (f\"Error exporting to Excel: {e}\")\n",
    "        return False\n",
    "common_layout =widgets .Layout (width ='240px',height ='35px')\n",
    "start_datetime_input =widgets .Text (\n",
    "value ='01/01/2024 00:00',\n",
    "placeholder ='dd/mm/yyyy HH:MM',\n",
    "description ='StartDatum:',\n",
    "layout =common_layout\n",
    ")\n",
    "end_datetime_input =widgets .Text (\n",
    "value ='31/12/2024 00:00',\n",
    "placeholder ='dd/mm/yyyy HH:MM',\n",
    "description ='EindDatum:',\n",
    "layout =common_layout\n",
    ")\n",
    "freq_selector =widgets .Dropdown (\n",
    "options =[('Automatisch (standaard)','auto'),\n",
    "('Elke 5 minuten','5T'),('Elke 15 minuten','15T'),\n",
    "('Per uur','H'),('Dagelijks','D'),\n",
    "('Wekelijks','W'),\n",
    "('Maandelijks','ME'), # MODIFIED: 'M' to 'ME' for consistency with table and FREQ_TO_SECONDS\n",
    "('Jaarlijks','Y')],\n",
    "value ='auto',\n",
    "description ='Frequentie:',\n",
    "layout =common_layout\n",
    ")\n",
    "aggregate_checkbox =widgets .Checkbox (\n",
    "value =True ,\n",
    "description ='Geaggregeerd?',\n",
    "layout =widgets .Layout (margin ='2px 0 2px 0')\n",
    ")\n",
    "status_checkbox =widgets .Checkbox (\n",
    "value =False ,\n",
    "description ='Include Status? (en pas kleur op consumption aan)',\n",
    "disabled =True ,\n",
    "layout =widgets .Layout (margin ='2px 0 2px 0')\n",
    ")\n",
    "\n",
    "excel_format_checkbox =widgets .Checkbox (\n",
    "value =False , # Default to False, user can enable it\n",
    "description ='Voorwaardelijke opmaak Excel?',\n",
    "layout =widgets .Layout (margin ='2px 0 2px 0')\n",
    ")\n",
    "\n",
    "def on_aggregate_change (change ):\n",
    "\n",
    "    status_checkbox .disabled =change ['new']\n",
    "aggregate_checkbox .observe (on_aggregate_change ,names ='value')\n",
    "\n",
    "status_checkbox .disabled =aggregate_checkbox .value\n",
    "\n",
    "warning_message =widgets .HTML (\"\")\n",
    "warning_container =widgets .VBox ([]) # Initially empty\n",
    "quick_fix_freq_button =widgets .Button (\n",
    "description =\"Wijzig freq naar 1 uur\",\n",
    "button_style =\"warning\", # 'warning' is yellow\n",
    "icon =\"clock-o\",\n",
    "layout =common_layout\n",
    ")\n",
    "quick_fix_date_button =widgets .Button (\n",
    "description =\"Beperk datumbereik\",\n",
    "button_style =\"warning\",\n",
    "icon =\"calendar\",\n",
    "layout =common_layout\n",
    ")\n",
    "\n",
    "progress_bar =widgets .IntProgress (value =0 ,min =0 ,max =100 ,step =1 ,description ='Dataset:',bar_style ='info') # Options: 'success', 'info', 'warning', 'danger' or ''\n",
    "progress_bar .layout =widgets .Layout (width ='220px',height ='30px')\n",
    "status_label =widgets .Label (value =\"\",layout =widgets .Layout (width =\"auto\",margin =\"0 0 0 10px\")) # Auto width, margin for spacing\n",
    "progress_container =widgets .HBox ([progress_bar ,status_label ])\n",
    "progress_container .layout .visibility ='hidden' # Start hidden\n",
    "\n",
    "output_area =widgets .Output (layout ={'border':'1px solid black'})\n",
    "data_table_output =widgets .Output (layout ={\n",
    "'border':'1px solid #ccc', # Lighter border\n",
    "'overflow_x':'auto',\n",
    "'overflow_y':'auto',\n",
    "'max_height':'400px', # Limit height\n",
    "'width':'100%' # Take full available width\n",
    "})\n",
    "insights_output =widgets .Output (layout ={\n",
    "'border':'1px solid #ccc',\n",
    "'overflow_x':'auto',\n",
    "'overflow_y':'auto',\n",
    "'max_height':'400px',\n",
    "'width':'100%'\n",
    "})\n",
    "view_tab =widgets .Tab (children =[data_table_output ,insights_output ])\n",
    "view_tab .set_title (0 ,\"Dataset\")\n",
    "view_tab .set_title (1 ,\"Inzichten\")\n",
    "\n",
    "btn_load_filters =widgets .Button (description ='Zoeken',button_style ='info',icon ='filter',layout =common_layout )\n",
    "btn_build_dataset =widgets .Button (description ='Laad Dataset',button_style ='success',icon ='database',disabled =True ,layout =common_layout )\n",
    "btn_view_dataset =widgets .Button (description =\"Bekijk Dataset\",button_style ='primary',icon ='eye',disabled =True ,layout =common_layout )\n",
    "btn_view_insights =widgets .Button (description =\"Bekijk Inzichten\",button_style ='primary',icon ='info',disabled =True ,layout =common_layout )\n",
    "btn_download_csv =widgets .Button (description =\"Download CSV\",button_style ='primary',icon ='download',disabled =True ,layout =common_layout )\n",
    "btn_download_excel =widgets .Button (description =\"Download XLS\",button_style ='primary',icon ='file-excel-o',disabled =True ,layout =common_layout )\n",
    "btn_reset_filters =widgets .Button (description ='Reset Filters',button_style ='warning',icon ='refresh',layout =common_layout )\n",
    "\n",
    "ean_input = widgets.Text(\n",
    "    description='EAN:',\n",
    "    placeholder='Vul ID/EAN in',\n",
    "    value='', # Default empty or provide a test EAN\n",
    "    layout=common_layout\n",
    ")\n",
    "\n",
    "options_container =widgets .VBox ([aggregate_checkbox ,status_checkbox ,excel_format_checkbox ])\n",
    "options_accordion =widgets .Accordion (children =[options_container ])\n",
    "options_accordion .set_title (0 ,\"Opties\")\n",
    "options_accordion .selected_index =None # Collapsed by default\n",
    "\n",
    "group_checkbox_container =widgets .VBox ([]) # Checkboxes will be added here dynamically\n",
    "group_accordion =widgets .Accordion (children =[group_checkbox_container ])\n",
    "group_accordion .set_title (0 ,\"Beschikbare groepen\")\n",
    "group_accordion .selected_index =None # Collapsed by default\n",
    "\n",
    "row_top =widgets .HBox (\n",
    "[ean_input ,search_method_dropdown ,btn_load_filters ,btn_reset_filters ],\n",
    "layout =widgets .Layout (gap =\"5px\",flex_flow ='row wrap') # Added gap and wrap\n",
    ")\n",
    "row_dates =widgets .HBox ([start_datetime_input ,end_datetime_input ,freq_selector ],\n",
    "layout =widgets .Layout (gap =\"10px\",flex_flow ='row wrap')) # Added gap and wrap\n",
    "\n",
    "action_buttons_row =widgets .HBox (\n",
    "[btn_build_dataset ,btn_view_dataset ,btn_view_insights ,btn_download_csv ,btn_download_excel ],\n",
    "layout =widgets .Layout (justify_content ='flex-start',flex_flow ='row wrap') # Wrap buttons\n",
    ")\n",
    "\n",
    "toggle_filters_button =widgets .Button (\n",
    "description =\"Verberg filters\", # Initial text\n",
    "icon ='chevron-up', # Initial icon\n",
    "button_style ='info',\n",
    "layout =widgets .Layout (width ='150px',height ='35px')\n",
    ")\n",
    "\n",
    "filters_container =widgets .VBox ([\n",
    "widgets .HTML (\"<h3>Filters</h3>\"), # Title for the filter section\n",
    "row_top ,\n",
    "row_dates ,\n",
    "warning_container , # For displaying validation messages\n",
    "options_accordion ,\n",
    "group_accordion ,\n",
    "action_buttons_row ,\n",
    "progress_container , # Progress bar and status\n",
    "output_area , # For general messages / logs\n",
    "view_tab # Tabs for dataset and insights\n",
    "],layout =widgets .Layout (display ='block',border ='1px solid #ccc',padding ='5px')) # Initial display state and styling\n",
    "\n",
    "final_ui =widgets .VBox ([\n",
    "toggle_filters_button ,\n",
    "filters_container\n",
    "])\n",
    "display (final_ui )\n",
    "\n",
    "current_df =None # Stores the latest generated DataFrame\n",
    "progress_start_time =None\n",
    "progress_running =False\n",
    "current_progress =0\n",
    "current_status =\"\"\n",
    "\n",
    "def progress_timer ():\n",
    "    global progress_running ,progress_start_time ,current_progress ,current_status\n",
    "    while progress_running :\n",
    "        if current_progress >0 and progress_start_time is not None: # Check progress_start_time\n",
    "            elapsed =time .time ()-progress_start_time\n",
    "            if current_progress >0 and current_progress < 100 : # Avoid division by zero or stale estimates\n",
    "                fraction_done =current_progress /100\n",
    "                if fraction_done >0 : # Should always be true here\n",
    "                    estimated_total =elapsed /fraction_done\n",
    "                    remaining =max (0 ,estimated_total -elapsed )\n",
    "                    status_label .value =f\"{current_status} - {current_progress}% - Resterende tijd: {int(remaining)} sec\"\n",
    "        time .sleep (1 ) # Update every second\n",
    "\n",
    "def update_progress (progress ,status =\"\",error =False ):\n",
    "    global progress_start_time ,progress_running ,current_progress ,current_status\n",
    "    if not progress_running and progress > 0 and progress < 100: # Start of a new task\n",
    "        progress_start_time =time .time ()\n",
    "        progress_running =True\n",
    "        progress_bar.value = 0 # Reset progress bar for new task\n",
    "        if not hasattr (update_progress ,'timer_thread')or not update_progress .timer_thread .is_alive ():\n",
    "            update_progress .timer_thread =threading .Thread (target =progress_timer ,daemon =True )\n",
    "            update_progress .timer_thread .start ()\n",
    "        progress_bar .bar_style =\"info\"\n",
    "        progress_container .layout .visibility ='visible'\n",
    "    \n",
    "    current_progress =progress\n",
    "    current_status =status\n",
    "    progress_bar .value =progress\n",
    "    status_label .value =f\"{status} - {progress}%\"\n",
    "\n",
    "    if error :\n",
    "        progress_bar .bar_style =\"danger\"\n",
    "        progress_running = False # Stop timer on error\n",
    "    elif progress >=100 :\n",
    "        progress_bar .bar_style =\"success\"\n",
    "        status_label.value = f\"{status} - {progress}% - Voltooid!\"\n",
    "        # progress_running = False # Timer will stop naturally or can be stopped in finish_progress\n",
    "    else :\n",
    "        progress_bar .bar_style =\"info\"\n",
    "\n",
    "def finish_progress ():\n",
    "    global progress_running ,current_progress ,current_status, progress_start_time\n",
    "    # Give a brief moment for the 100% status to be visible\n",
    "    if current_progress >= 100 and not progress_bar.bar_style == 'danger':\n",
    "        time.sleep(2) # Show success message briefly\n",
    "    \n",
    "    progress_running =False\n",
    "    progress_container .layout .visibility ='hidden'\n",
    "    progress_bar .value =0\n",
    "    status_label .value =\"\"\n",
    "    current_progress =0\n",
    "    current_status =\"\"\n",
    "    progress_start_time = None\n",
    "\n",
    "\n",
    "# --- New Function: adjust_dates_on_freq_change ---\n",
    "def adjust_dates_on_freq_change(change): # ipywidgets observe passes a change dictionary\n",
    "    freq_value = change['new'] if isinstance(change, dict) else change # Accommodate direct call if needed\n",
    "\n",
    "    if freq_value == 'auto':\n",
    "        # Laat beide waarden ongemoeid.\n",
    "        return\n",
    "\n",
    "    start_dt_str = start_datetime_input.value\n",
    "    end_dt_str = end_datetime_input.value\n",
    "\n",
    "    start_dt_parsed = parse_user_datetime(start_dt_str)\n",
    "    end_dt_parsed = parse_user_datetime(end_dt_str)\n",
    "\n",
    "    # It's crucial that parse_user_datetime returns naive datetimes\n",
    "    if start_dt_parsed is None:\n",
    "        logger.warning(f\"Ongeldige startdatum '{start_dt_str}' bij aanpassen frequentie. Formaat moet '%d/%m/%Y %H:%M' zijn.\")\n",
    "        # Optionally clear/flag input, but for now, just log and don't adjust.\n",
    "        return\n",
    "    if end_dt_parsed is None:\n",
    "        logger.warning(f\"Ongeldige einddatum '{end_dt_str}' bij aanpassen frequentie. Formaat moet '%d/%m/%Y %H:%M' zijn.\")\n",
    "        return\n",
    "\n",
    "    # Adjust start date\n",
    "    adjusted_start_dt = DateAdjustmentUtils.round_datetime(start_dt_parsed, freq_value, is_start_date=True)\n",
    "    \n",
    "    # Adjust end date\n",
    "    adjusted_end_dt = DateAdjustmentUtils.round_datetime(end_dt_parsed, freq_value, is_start_date=False)\n",
    "\n",
    "    # Format back to string and update widgets\n",
    "    # The datetime objects returned by round_datetime are timezone-aware (Europe/Amsterdam)\n",
    "    # strftime on a timezone-aware datetime object will format it in that timezone.\n",
    "    if adjusted_start_dt:\n",
    "        start_datetime_input.value = adjusted_start_dt.strftime('%d/%m/%Y %H:%M')\n",
    "    if adjusted_end_dt:\n",
    "        end_datetime_input.value = adjusted_end_dt.strftime('%d/%m/%Y %H:%M')\n",
    "\n",
    "\n",
    "def validate_data_request (change =None ): # change can be None if called directly\n",
    "    start_dt =parse_user_datetime (start_datetime_input .value )\n",
    "    end_dt =parse_user_datetime (end_datetime_input .value )\n",
    "    \n",
    "    current_warnings = []\n",
    "\n",
    "    if not start_dt:\n",
    "        current_warnings.append(\"Ongeldige startdatum/tijd (formaat dd/mm/yyyy HH:MM)!\")\n",
    "    if not end_dt:\n",
    "        current_warnings.append(\"Ongeldige einddatum/tijd (formaat dd/mm/yyyy HH:MM)!\")\n",
    "    \n",
    "    if start_dt and end_dt and end_dt < start_dt :\n",
    "        current_warnings.append(\"Einddatum mag niet vóór de startdatum liggen.\")\n",
    "\n",
    "    freq_val =freq_selector .value\n",
    "    if freq_val.lower() != 'auto' and start_dt and end_dt and end_dt >= start_dt:\n",
    "        if freq_val in FREQ_TO_SECONDS :\n",
    "            seconds_per_interval =FREQ_TO_SECONDS [freq_val ]\n",
    "            duration_seconds =(end_dt -start_dt ).total_seconds ()\n",
    "            if duration_seconds <0 : # Should be caught by end_dt < start_dt\n",
    "                duration_seconds =0\n",
    "\n",
    "            # Ensure seconds_per_interval is not zero\n",
    "            if seconds_per_interval > 0:\n",
    "                expected_rows =duration_seconds /seconds_per_interval +1\n",
    "                if expected_rows >MAX_ROWS :\n",
    "                    warning_text = (\n",
    "                        f\"U probeert te veel data op te vragen ({int(expected_rows)} rijen bij freq '{freq_val}'). \"\n",
    "                        \"Verklein het datumbereik of verhoog de resolutie (bijv. naar 'Per uur').\"\n",
    "                    )\n",
    "                    current_warnings.append(warning_text)\n",
    "                    warning_container.children = [\n",
    "                        widgets.HTML(f\"<span style='color:red; font-weight:bold;'>{'; '.join(current_warnings)}</span>\"),\n",
    "                        widgets.HBox([quick_fix_freq_button, quick_fix_date_button], layout=widgets.Layout(justify_content='center'))\n",
    "                    ]\n",
    "                    return # Stop further processing if too many rows\n",
    "            else:\n",
    "                current_warnings.append(f\"Interval voor frequentie '{freq_val}' is nul of ongeldig.\")\n",
    "        else:\n",
    "            current_warnings.append(f\"Frequentie '{freq_val}' niet herkend voor rij-estimatie.\")\n",
    "\n",
    "\n",
    "    if current_warnings:\n",
    "        warning_message.value = f\"<span style='color:red; font-weight:bold;'>{'; '.join(current_warnings)}</span>\"\n",
    "        quick_fix_buttons = []\n",
    "        # Only show quick fix if the specific warning about MAX_ROWS is present\n",
    "        if any(\"te veel data\" in warn_msg for warn_msg in current_warnings):\n",
    "             quick_fix_buttons = [widgets.HBox([quick_fix_freq_button, quick_fix_date_button], layout=widgets.Layout(justify_content='center'))]\n",
    "        warning_container.children = [warning_message] + quick_fix_buttons\n",
    "    else:\n",
    "        warning_message.value = \"\"\n",
    "        warning_container.children = []\n",
    "\n",
    "\n",
    "# --- Combined Callback ---\n",
    "def on_freq_change_and_validate(change):\n",
    "    # `change` is a dictionary like {'name': 'value', 'old': 'auto', 'new': '5T', 'owner': Dropdown(...), 'type': 'change'}\n",
    "    adjust_dates_on_freq_change(change) # Pass the whole change object which contains 'new' value\n",
    "    validate_data_request(change)       # Pass the whole change object\n",
    "\n",
    "\n",
    "start_datetime_input .observe (validate_data_request ,names =\"value\")\n",
    "end_datetime_input .observe (validate_data_request ,names =\"value\")\n",
    "# MODIFIED: Old observer removed, new combined observer added\n",
    "# freq_selector .observe (validate_data_request ,names =\"value\") # OLD\n",
    "freq_selector.observe(on_freq_change_and_validate, names='value') # NEW\n",
    "\n",
    "\n",
    "def quick_fix_freq_action (b ):\n",
    "    freq_selector .value ='H' # This will trigger on_freq_change_and_validate\n",
    "    # validate_data_request () # No longer needed here, will be called by the observer\n",
    "quick_fix_freq_button .on_click (quick_fix_freq_action )\n",
    "\n",
    "def quick_fix_date_action (b ):\n",
    "    start_dt =parse_user_datetime (start_datetime_input .value )\n",
    "    if not start_dt :\n",
    "        return # Or handle error: e.g., set a default start_dt\n",
    "    \n",
    "    freq_val = freq_selector.value\n",
    "    if freq_val == 'auto': # If auto, maybe default to 'H' for this calculation or warn user\n",
    "        logger.info(\"Quick fix date: Freq is 'auto', using 'H' for calculation.\")\n",
    "        freq_val = 'H' \n",
    "\n",
    "    seconds_per_interval =FREQ_TO_SECONDS .get (freq_val ,3600 ) # Default to 1 hour if freq_val is somehow unknown\n",
    "    if seconds_per_interval <= 0: seconds_per_interval = 3600 # Safety net\n",
    "\n",
    "    max_duration = (MAX_ROWS -1) * seconds_per_interval # Max duration for MAX_ROWS items\n",
    "    \n",
    "    # Localize start_dt to ensure timedelta arithmetic is consistent if start_dt was naive\n",
    "    # However, parse_user_datetime returns naive. For consistency with adjust_dates, we'd localize.\n",
    "    # For simplicity here, assuming naive arithmetic is sufficient for timedelta.\n",
    "    new_end_dt = start_dt + timedelta(seconds=max_duration)\n",
    "    \n",
    "    # If original start_dt was localized, new_end_dt would be too.\n",
    "    # Since start_dt is naive, new_end_dt is naive. strftime is fine.\n",
    "    end_datetime_input .value =new_end_dt .strftime ('%d/%m/%Y %H:%M')\n",
    "    # validate_data_request () # No longer needed here, will be called by end_datetime_input observer\n",
    "quick_fix_date_button .on_click (quick_fix_date_action )\n",
    "\n",
    "def toggle_filters_display (b ):\n",
    "    if filters_container .layout .display =='none':\n",
    "        filters_container .layout .display ='block'\n",
    "        toggle_filters_button .description =\"Verberg filters\"\n",
    "        toggle_filters_button .icon =\"chevron-up\"\n",
    "    else :\n",
    "        filters_container .layout .display ='none'\n",
    "        toggle_filters_button .description =\"Toon filters\"\n",
    "        toggle_filters_button .icon =\"chevron-down\"\n",
    "toggle_filters_button .on_click (toggle_filters_display )\n",
    "\n",
    "def load_filters_thread (ean_val :str ):\n",
    "    btn_build_dataset .disabled =True\n",
    "    btn_view_dataset .disabled =True\n",
    "    btn_view_insights .disabled =True\n",
    "    btn_download_csv .disabled =True\n",
    "    btn_download_excel .disabled =True\n",
    "    with output_area :\n",
    "        clear_output ()\n",
    "        print (\"Filters worden geladen...\")\n",
    "\n",
    "    typeids =fetch_typeids_for_ean (ean_val )\n",
    "    if not typeids :\n",
    "        with output_area :\n",
    "            clear_output ()\n",
    "            print (\"Geen TypeIDs gevonden voor deze invoer.\")\n",
    "        group_checkbox_container .children =[]\n",
    "        group_accordion.selected_index = None # Collapse if no groups\n",
    "        return\n",
    "\n",
    "    relevant_groups =[]\n",
    "    for grp ,tlist in group_typeid_mapping .items ():\n",
    "        if set (tlist ).intersection (typeids ):\n",
    "            relevant_groups .append (grp )\n",
    "\n",
    "    if not relevant_groups:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(\"Geen relevante groepen gevonden voor de TypeIDs.\")\n",
    "        group_checkbox_container.children = []\n",
    "        group_accordion.selected_index = None\n",
    "        return\n",
    "        \n",
    "    checkboxes =[]\n",
    "    for grp in sorted (relevant_groups ): # Sort for consistent order\n",
    "        cb =widgets .Checkbox (value =True ,description =grp ,indent =False )\n",
    "        checkboxes .append (cb )\n",
    "    group_checkbox_container .children =checkboxes\n",
    "    group_accordion .selected_index =0 # Expand to show groups\n",
    "\n",
    "    btn_build_dataset .disabled =False\n",
    "    # Other buttons remain disabled until dataset is built\n",
    "\n",
    "    with output_area :\n",
    "        clear_output ()\n",
    "        print (f\"Filters geladen. Beschikbare groepen: {', '.join(sorted(relevant_groups))}\")\n",
    "\n",
    "def on_load_filters_clicked(b):\n",
    "    ean_val = ean_input.value.strip()\n",
    "    if not ean_val:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(\"Vul een EAN of ID in.\")\n",
    "        return\n",
    "    # Use threading to avoid blocking UI, though this function is mostly quick DB calls\n",
    "    threading.Thread(target=load_filters_thread, args=(ean_val,)).start()\n",
    "\n",
    "\n",
    "def on_reset_filters_clicked (b ):\n",
    "    if group_checkbox_container .children :\n",
    "        for cb in group_checkbox_container .children :\n",
    "            cb .value =True\n",
    "    ean_input .value ='871692160011845654' # Example EAN\n",
    "    start_datetime_input .value ='01/01/2024 00:00'\n",
    "    end_datetime_input .value ='31/12/2024 00:00' # Corrected to a valid future or same year date\n",
    "    freq_selector .value ='auto' # This will trigger adjust_dates and validate\n",
    "    aggregate_checkbox .value =True\n",
    "    status_checkbox .value =False\n",
    "    excel_format_checkbox.value = False\n",
    "\n",
    "\n",
    "    status_checkbox .disabled =aggregate_checkbox .value # This is already handled by observe\n",
    "    with output_area :\n",
    "        clear_output ()\n",
    "        print (\"Filters zijn gereset.\")\n",
    "    # Explicitly call validate after reset, as freq might not change if it was already 'auto'\n",
    "    validate_data_request()\n",
    "    # If freq was 'auto', adjust_dates was not called. If it was something else, it was.\n",
    "    # To be sure, one might call adjust_dates manually if needed, or ensure freq change fires it.\n",
    "    # If freq_selector.value was already 'auto', its observer wouldn't fire.\n",
    "    # However, changing start/end dates will trigger their observers for validation.\n",
    "    # The date rounding from freq change is only for non-'auto' frequencies.\n",
    "\n",
    "def get_selected_groups ()->List [str ]:\n",
    "    return [cb .description for cb in group_checkbox_container .children if cb .value ]\n",
    "\n",
    "def build_dataset_thread ():\n",
    "    global current_df\n",
    "    # Disable buttons during build\n",
    "    btn_build_dataset.disabled = True\n",
    "    btn_view_dataset.disabled = True\n",
    "    btn_view_insights.disabled = True\n",
    "    btn_download_csv.disabled = True\n",
    "    btn_download_excel.disabled = True\n",
    "\n",
    "    update_progress (0 ,\"Dataset wordt opgebouwd...\") # Reset and start progress\n",
    "\n",
    "    with output_area : # Clear previous messages from output_area\n",
    "        clear_output (wait=True) # wait=True to avoid flickering if new print comes fast\n",
    "\n",
    "    ean_val =ean_input .value .strip ()\n",
    "    if not ean_val :\n",
    "        with output_area : print (\"Vul een EAN/ID in.\")\n",
    "        update_progress(100, \"Fout: EAN/ID ontbreekt\", error=True)\n",
    "        finish_progress ()\n",
    "        btn_build_dataset.disabled = False # Re-enable build button\n",
    "        return\n",
    "\n",
    "    # Perform validation again before building, using the validation function\n",
    "    validate_data_request() # This will update warning_container\n",
    "    if warning_container.children: # If there are validation warnings\n",
    "        with output_area:\n",
    "             display(HTML(\"<span style='color:red; font-weight:bold;'>Los de validatiefouten op voordat u de dataset bouwt.</span>\"))\n",
    "        update_progress(100, \"Validatiefout\", error=True)\n",
    "        finish_progress()\n",
    "        btn_build_dataset.disabled = False # Re-enable build button\n",
    "        return\n",
    "\n",
    "    start_dt =parse_user_datetime (start_datetime_input .value )\n",
    "    end_dt =parse_user_datetime (end_datetime_input .value )\n",
    "    # These should be valid due to the check above, but defensive check is okay\n",
    "    if not start_dt or not end_dt:\n",
    "        with output_area: print(\"Interne fout: Ongeldige datums ondanks validatie.\")\n",
    "        update_progress(100, \"Fout: Interne datumfout\", error=True)\n",
    "        finish_progress()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "\n",
    "\n",
    "    freq_val =freq_selector .value\n",
    "    agg_val =aggregate_checkbox .value\n",
    "    status_val =status_checkbox .value\n",
    "    chosen =get_selected_groups ()\n",
    "    if not chosen :\n",
    "        with output_area : print (\"Geen groepen geselecteerd.\")\n",
    "        update_progress(100, \"Fout: Geen groepen\", error=True)\n",
    "        finish_progress ()\n",
    "        btn_build_dataset.disabled = False\n",
    "        return\n",
    "\n",
    "    update_progress (30 ,\"TypeIDs en min/max periode ophalen...\")\n",
    "    \n",
    "    # For build_dataset, datetimes should ideally be localized if SP expects specific timezone or for internal consistency\n",
    "    # The current `build_dataset` takes naive datetimes as per `parse_user_datetime`\n",
    "    # This part remains as per original logic unless specified to change.\n",
    "\n",
    "    df_resampled =build_dataset (\n",
    "    ean_val ,\n",
    "    chosen ,\n",
    "    start_dt , # Naive datetime\n",
    "    end_dt ,   # Naive datetime\n",
    "    freq_val ,\n",
    "    agg_val ,\n",
    "    include_status_flag =status_val\n",
    "    )\n",
    "    \n",
    "    update_progress (80 ,\"Dataset verwerken...\")\n",
    "\n",
    "    if df_resampled is None or df_resampled .empty :\n",
    "        update_progress (100 ,\"Geen dataset opgehaald.\",error =True )\n",
    "        with output_area :\n",
    "            print (\"Geen dataset opgehaald. Controleer filters of logs voor details.\")\n",
    "        finish_progress ()\n",
    "        btn_build_dataset.disabled = False # Re-enable build button\n",
    "        return\n",
    "\n",
    "    current_df =df_resampled .copy ()\n",
    "    update_progress (100 ,f\"Dataset geladen met {len(current_df)} rijen.\")\n",
    "\n",
    "    with output_area : # Clear previous messages and show success\n",
    "        clear_output(wait=True)\n",
    "        print (f\"Dataset succesvol geladen met {len(current_df)} rijen.\\nU kunt nu de dataset bekijken, inzichten genereren of downloaden.\")\n",
    "\n",
    "    # Enable action buttons for the loaded dataset\n",
    "    btn_view_dataset .disabled =False\n",
    "    btn_view_insights .disabled =False\n",
    "    btn_download_csv .disabled =False\n",
    "    btn_download_excel .disabled =False\n",
    "    finish_progress ()\n",
    "    btn_build_dataset.disabled = False # Re-enable build button for another run\n",
    "\n",
    "\n",
    "def on_build_dataset_clicked (b ):\n",
    "    # Clear previous views\n",
    "    with data_table_output: clear_output()\n",
    "    with insights_output: clear_output()\n",
    "    threading .Thread (target =build_dataset_thread ).start ()\n",
    "\n",
    "def show_dataset_table ():\n",
    "    with data_table_output :\n",
    "        clear_output (wait =True )\n",
    "        if current_df is None or current_df .empty :\n",
    "            print (\"Nog geen dataset geladen of de dataset is leeg.\")\n",
    "        else :\n",
    "            limit =50 # Show head(50) for performance\n",
    "            html_table =current_df .head (limit ).to_html (classes =\"dataframe\",index =False ,escape=True)\n",
    "            # Info about partial display\n",
    "            info_message = \"\"\n",
    "            if len(current_df) > limit:\n",
    "                info_message = f\"<p><i>Toont de eerste {limit} rijen van {len(current_df)} totale rijen. Download voor de volledige dataset.</i></p>\"\n",
    "            \n",
    "            scrollable_html =f\"\"\"\n",
    "            <div style=\"overflow-x: auto; overflow-y: auto; max-height: 380px; width: 100%;\">\n",
    "                {html_table}\n",
    "            </div>\n",
    "            {info_message}\n",
    "            \"\"\"\n",
    "            display (HTML (scrollable_html ))\n",
    "    view_tab .selected_index =0\n",
    "\n",
    "def show_insights ():\n",
    "    with insights_output :\n",
    "        clear_output (wait =True )\n",
    "        if current_df is None or current_df .empty :\n",
    "            print (\"Nog geen dataset geladen of de dataset is leeg om inzichten te genereren.\")\n",
    "        else :\n",
    "            # Potentially long operation, consider threading or async if generate_insights is slow\n",
    "            insights_html =generate_insights (current_df ) # Assumes current_df is appropriately formatted\n",
    "            display (HTML (f\"<div style='font-family: Roboto, sans-serif; font-size:14px;'>{insights_html}</div>\"))\n",
    "    view_tab .selected_index =1\n",
    "\n",
    "def on_view_dataset_clicked (b ):\n",
    "    show_dataset_table ()\n",
    "\n",
    "def on_view_insights_clicked (b ):\n",
    "    show_insights ()\n",
    "\n",
    "def on_download_csv_clicked (b ):\n",
    "    if current_df is None or current_df .empty :\n",
    "        with output_area :\n",
    "            clear_output (wait=True)\n",
    "            print (\"Geen dataset om te downloaden.\")\n",
    "        return\n",
    "\n",
    "    ean_val =ean_input .value .strip ().replace (\" \",\"_\").replace(\"/\",\"_\") # Sanitize filename\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename_base = f\"dataset_{ean_val}_{ts}.csv\"\n",
    "\n",
    "    downloads_folder =os .path .join (os .path .expanduser (\"~\"),\"Downloads\")\n",
    "    if not os .path .isdir (downloads_folder ):\n",
    "        try:\n",
    "            os.makedirs(downloads_folder) # Create if not exists\n",
    "        except OSError: # Fallback to current working directory if creation fails\n",
    "            logger.warning(f\"Kon map {downloads_folder} niet aanmaken. CSV wordt opgeslagen in huidige werkmap.\")\n",
    "            downloads_folder =os .getcwd ()\n",
    "\n",
    "\n",
    "    filename =os .path .join (downloads_folder ,filename_base)\n",
    "    if export_dataset_to_csv (current_df ,filename ):\n",
    "        with output_area :\n",
    "            clear_output (wait=True)\n",
    "            # Create a downloadable link (Jupyter specific)\n",
    "            # For local Jupyter, direct file path is more informative. For Hub/Lab, link might be better.\n",
    "            display (HTML (f\"<p>CSV bestand opgeslagen in uw Downloads map: <code>{filename}</code></p>\"\n",
    "                           f\"<p>Als de download niet automatisch start, kunt u het bestand hier vinden.</p>\"))\n",
    "    else:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Fout bij exporteren naar CSV.\")\n",
    "\n",
    "\n",
    "def on_download_excel_clicked (b ):\n",
    "    if current_df is None or current_df .empty :\n",
    "        with output_area :\n",
    "            clear_output (wait=True)\n",
    "            print (\"Geen dataset om te downloaden.\")\n",
    "        return\n",
    "\n",
    "    ean_val =ean_input .value .strip ().replace (\" \",\"_\").replace(\"/\",\"_\") # Sanitize filename\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename_base = f\"dataset_{ean_val}_{ts}.xlsx\"\n",
    "    \n",
    "    downloads_folder =os .path .join (os .path .expanduser (\"~\"),\"Downloads\")\n",
    "    if not os .path .isdir (downloads_folder ):\n",
    "        try:\n",
    "            os.makedirs(downloads_folder)\n",
    "        except OSError:\n",
    "            logger.warning(f\"Kon map {downloads_folder} niet aanmaken. Excel wordt opgeslagen in huidige werkmap.\")\n",
    "            downloads_folder =os .getcwd ()\n",
    "\n",
    "    filename =os .path .join (downloads_folder ,filename_base)\n",
    "    \n",
    "    # Get formatting options from checkboxes\n",
    "    apply_excel_format = excel_format_checkbox.value\n",
    "    include_status_for_formatting = status_checkbox.value and not aggregate_checkbox.value # Status only relevant if not aggregated\n",
    "\n",
    "    if export_dataset_to_excel(current_df, filename, apply_excel_format, include_status_for_formatting):\n",
    "        with output_area :\n",
    "            clear_output (wait=True)\n",
    "            display (HTML (f\"<p>Excel bestand opgeslagen in uw Downloads map: <code>{filename}</code></p>\"\n",
    "                           f\"<p>Als de download niet automatisch start, kunt u het bestand hier vinden.</p>\"))\n",
    "    else:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Fout bij exporteren naar Excel.\")\n",
    "\n",
    "\n",
    "btn_load_filters.on_click(on_load_filters_clicked)\n",
    "btn_reset_filters .on_click (on_reset_filters_clicked )\n",
    "btn_build_dataset .on_click (on_build_dataset_clicked )\n",
    "btn_view_dataset .on_click (on_view_dataset_clicked )\n",
    "btn_view_insights .on_click (on_view_insights_clicked )\n",
    "btn_download_csv .on_click (on_download_csv_clicked )\n",
    "btn_download_excel .on_click (on_download_excel_clicked )\n",
    "\n",
    "# Initial validation call to check default dates\n",
    "validate_data_request()\n",
    "# Initial call to adjust dates based on default frequency (if not 'auto')\n",
    "# This ensures that if the initial freq is e.g. '5T', dates are rounded on load.\n",
    "adjust_dates_on_freq_change({'new': freq_selector.value}) # Pass a mock change object\n",
    "validate_data_request() # And re-validate after potential adjustment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energymonitor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> Stashed changes
